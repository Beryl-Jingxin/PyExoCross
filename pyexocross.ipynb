{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all what we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding: utf-8\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numexpr as ne\n",
    "from io import StringIO\n",
    "import astropy.units as au\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import voigt_profile, wofz, erf, roots_hermite\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", np.ComplexWarning)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Input File Path\n",
    "\n",
    "\n",
    "<table><tr><td bgcolor=skyblue><font size=24> Could be changed ! </font></td></tr></table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################\n",
    "inp_filepath = '/home/jingxin/PyExoCross/input/MgH_exomol.inp'\n",
    "#########################################################"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Timer:    \n",
    "    def start(self):\n",
    "        self.start_CPU = time.process_time()\n",
    "        self.start_sys = time.time()\n",
    "        return self\n",
    "\n",
    "    def end(self, *args):\n",
    "        self.end_CPU = time.process_time()\n",
    "        self.end_sys = time.time()\n",
    "        self.interval_CPU = self.end_CPU - self.start_CPU\n",
    "        self.interval_sys = self.end_sys - self.start_sys\n",
    "        print('{:25s} : {}'.format('Running time on CPU', self.interval_CPU), 's')\n",
    "        print('{:25s} : {}'.format('Running time on system', self.interval_sys), 's')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Information from Input File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inp_para(inp_filepath):\n",
    "    \n",
    "    # Find the maximum column for all the rows.\n",
    "    with open(inp_filepath, 'r') as temp_f:\n",
    "        col_count = max([len([x for x in l.split(\" \") if x.strip()]) for l in temp_f.readlines()])\n",
    "    # Generate column names  (names will be 0, 1, 2, ..., maximum columns - 1).\n",
    "    column_names = [i for i in range(col_count)] \n",
    "    inp_df = pd.read_csv(inp_filepath, sep='\\\\s+', header = None, names=column_names, usecols=column_names)\n",
    "    col0 = inp_df[0]\n",
    "    \n",
    "    # Database\n",
    "    database = inp_df[col0.isin(['Database'])][1].values[0].upper()\n",
    "    \n",
    "    # Basic information\n",
    "    molecule = inp_df[col0.isin(['Molecule'])][1].values[0]\n",
    "    isotopologue = inp_df[col0.isin(['Isotopologue'])][1].values[0]\n",
    "    dataset = inp_df[col0.isin(['Dataset'])][1].values[0]\n",
    "    mol_iso_id = int(inp_df[col0.isin(['MolIsoID'])][1])\n",
    "    \n",
    "    # File path\n",
    "    read_path = inp_df[col0.isin(['ReadPath'])][1].values[0]\n",
    "    save_path = inp_df[col0.isin(['SavePath'])][1].values[0]\n",
    "    if os.path.exists(save_path):\n",
    "        pass\n",
    "    else:\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        \n",
    "    # Functions \n",
    "    Conversion = int(inp_df[col0.isin(['Conversion'])][1])\n",
    "    PartitionFunctions = int(inp_df[col0.isin(['PartitionFunctions'])][1])\n",
    "    CoolingFunctions = int(inp_df[col0.isin(['CoolingFunctions'])][1])\n",
    "    Lifetimes = int(inp_df[col0.isin(['Lifetimes'])][1])\n",
    "    SpecificHeats = int(inp_df[col0.isin(['SpecificHeats'])][1])\n",
    "    StickSpectra = int(inp_df[col0.isin(['StickSpectra'])][1])\n",
    "    CrossSections = int(inp_df[col0.isin(['CrossSections'])][1])\n",
    "    \n",
    "    # Quantum numbers\n",
    "    NeedQNs = Conversion + StickSpectra + CrossSections\n",
    "    if NeedQNs != 0:\n",
    "        QNslabel_list = list(inp_df[col0.isin(['QNslabel'])].iloc[0])[1:]\n",
    "        QNsformat_list = list(inp_df[col0.isin(['QNsformat'])].iloc[0])[1:]\n",
    "        QNslabel_list = [x for x in QNslabel_list if x == x]\n",
    "        QNsformat_list = [x for x in QNsformat_list if x == x]\n",
    "    else:\n",
    "        QNslabel_list = []\n",
    "        QNsformat_list = []  \n",
    "    \n",
    "    # Convert from one format to another\n",
    "    if Conversion != 0:\n",
    "        ConversionFormat = int(inp_df[col0.isin(['ConversionFormat'])][1])\n",
    "        ConversionMinFreq = float(inp_df[col0.isin(['ConversionFrequncyRange'])][1])\n",
    "        ConversionMaxFreq = float(inp_df[col0.isin(['ConversionFrequncyRange'])][2])\n",
    "        GlobalQNLabel_list = list(inp_df[col0.isin(['GlobalQNLabel'])].iloc[0].dropna())[1:]\n",
    "        GlobalQNFormat_list = list(inp_df[col0.isin(['GlobalQNFormat'])].iloc[0].dropna())[1:]\n",
    "        LocalQNLabel_list = list(inp_df[col0.isin(['LocalQNLabel'])].iloc[0].dropna())[1:]\n",
    "        LocalQNFormat_list = list(inp_df[col0.isin(['LocalQNFormat'])].iloc[0].dropna())[1:]\n",
    "        \n",
    "        ConversionUncYN = inp_df[col0.isin(['ConvUncFilter(Y/N)'])][1].values[0].upper()[0]\n",
    "        if ConversionUncYN == 'Y':\n",
    "            ConversionUnc = float(inp_df[col0.isin(['ConvUncFilter(Y/N)'])][2])\n",
    "        elif ConversionUncYN == 'N':\n",
    "            ConversionUnc = 'None'\n",
    "        else:\n",
    "            raise ImportError(\"Please type the correct uncertainty filter choice 'Y' or 'N' into the input file.\")  \n",
    "        \n",
    "        ConversionThresholdYN = inp_df[col0.isin(['ConvThreshold(Y/N)'])][1].values[0].upper()[0]\n",
    "        if ConversionThresholdYN == 'Y':\n",
    "            ConversionThreshold = float(inp_df[col0.isin(['ConvThreshold(Y/N)'])][2])\n",
    "        elif ConversionThresholdYN == 'N':\n",
    "            ConversionThreshold = 'None'\n",
    "        else:\n",
    "            raise ImportError(\"Please type the correct threshold choice 'Y' or 'N' into the input file.\")    \n",
    "        \n",
    "    else:\n",
    "        ConversionFormat = 0\n",
    "        ConversionMinFreq = 0\n",
    "        ConversionMaxFreq = 0\n",
    "        GlobalQNLabel_list = []\n",
    "        GlobalQNFormat_list = []\n",
    "        LocalQNLabel_list = []\n",
    "        LocalQNFormat_list = []\n",
    "        ConversionUnc = 'None'\n",
    "        ConversionThreshold = 'None'\n",
    "        \n",
    "    # Calculate partition, cooling functions or specific heats \n",
    "    if PartitionFunctions + CoolingFunctions + SpecificHeats != 0:\n",
    "        Ntemp = int(inp_df[col0.isin(['Ntemp'])][1])    # The number of temperature steps\n",
    "        Tmax = int(inp_df[col0.isin(['Tmax'])][1])      # Maximal temperature in K (minimal T = 1 K )\n",
    "    else:\n",
    "        Ntemp = 0\n",
    "        Tmax = 0  \n",
    "     \n",
    "    # Calculate lifetimes \n",
    "    # None\n",
    "    \n",
    "    # Calculate stick spectra or cross sections \n",
    "    if StickSpectra + CrossSections != 0:\n",
    "        T = int(inp_df[col0.isin(['Temperature'])][1])\n",
    "        min_wn = float(inp_df[col0.isin(['Range'])][1])\n",
    "        max_wn = float(inp_df[col0.isin(['Range'])][2])\n",
    "        abs_emi = inp_df[col0.isin(['Absorption/Emission'])][1].values[0].upper()[0]\n",
    "        \n",
    "        UncFilterYN = inp_df[col0.isin(['UncFilter(Y/N)'])][1].values[0].upper()[0]\n",
    "        if UncFilterYN == 'Y':\n",
    "            UncFilter = float(inp_df[col0.isin(['UncFilter(Y/N)'])][2])\n",
    "        elif UncFilterYN == 'N':\n",
    "            UncFilter = 'None'\n",
    "        else:\n",
    "            raise ImportError(\"Please type the correct uncertainty filter choice 'Y' or 'N' into the input file.\")  \n",
    "        \n",
    "        thresholdYN = inp_df[col0.isin(['Threshold(Y/N)'])][1].values[0].upper()[0]\n",
    "        if thresholdYN == 'Y':\n",
    "            threshold = float(inp_df[col0.isin(['Threshold(Y/N)'])][2])\n",
    "        elif thresholdYN == 'N':\n",
    "            threshold = 'None'\n",
    "        else:\n",
    "            raise ImportError(\"Please type the correct threshold choice 'Y' or 'N' into the input file.\") \n",
    "\n",
    "        QNsFilterYN = inp_df[col0.isin(['QNsFilter(Y/N)'])][1].values[0].upper()[0]\n",
    "        if QNsFilterYN == 'Y':\n",
    "            QNsFilter = list(inp_df[col0.isin(['QNsFilter(Y/N)'])].iloc[0].dropna())[2:]\n",
    "            QNs_label = []\n",
    "            QNs_value = []\n",
    "            for i in range(len(QNsFilter)):\n",
    "                QNs_label.append(QNsFilter[i].split('[')[0])\n",
    "                QNs_value.append(QNsFilter[i].split('[')[1].split(']')[0].split(','))\n",
    "            QNs_format = [QNsformat_list[j] for j in [QNslabel_list.index(i) for i in QNs_label]]\n",
    "        elif QNsFilterYN == 'N':\n",
    "            QNsFilter = []\n",
    "            QNs_label = []\n",
    "            QNs_value = []\n",
    "            QNs_format = []\n",
    "        else:\n",
    "            raise ImportError(\"Please type the correct quantum number filter choice 'Y' or 'N' into the input file.\")\n",
    "    else:\n",
    "        T = 0\n",
    "        min_wn = 0\n",
    "        max_wn = 0\n",
    "        abs_emi = 'None'\n",
    "        UncFilter = 'None'\n",
    "        threshold = 'None'\n",
    "        QNsFilter = []\n",
    "        QNs_label = []\n",
    "        QNs_value = []  \n",
    "        QNs_format = []\n",
    "        \n",
    "    # Stick spectra\n",
    "    if StickSpectra != 0:\n",
    "        PlotStickSpectraYN = inp_df[col0.isin(['PlotStickSpectra(Y/N)'])][1].values[0].upper()[0]\n",
    "    else:\n",
    "        PlotStickSpectraYN = 'None'\n",
    "\n",
    "    # Cross sections\n",
    "    if CrossSections != 0:\n",
    "        NpointsORBinSize = inp_df[col0.isin(['Npoints/BinSize'])][1].values[0].upper()\n",
    "        if 'POI' in NpointsORBinSize:\n",
    "            N_point = int(inp_df[col0.isin(['Npoints/BinSize'])][2])\n",
    "            bin_size = float((max_wn - min_wn)/(N_point-1))\n",
    "        elif 'BIN' in NpointsORBinSize or 'SIZ' in NpointsORBinSize:\n",
    "            bin_size = float(inp_df[col0.isin(['Npoints/BinSize'])][2])\n",
    "            N_point = int((max_wn - min_wn)/bin_size+1)\n",
    "        else:\n",
    "            raise ImportError(\"Please type the correct grid choice 'Npoints' or 'BinSize' into the input file.\")\n",
    "\n",
    "        cutoffYN = inp_df[col0.isin(['Cutoff(Y/N)'])][1].values[0].upper()[0]\n",
    "        if cutoffYN == 'Y':\n",
    "            cutoff = float(inp_df[col0.isin(['Cutoff(Y/N)'])][2])\n",
    "        elif cutoffYN == 'N':\n",
    "            cutoff = 'None'\n",
    "        else:\n",
    "            raise ImportError(\"Please type the correct cutoff choice 'Y' or 'N' into the input file.\")\n",
    "\n",
    "        P = float(inp_df[col0.isin(['Pressure'])][1])\n",
    "        broadeners = list(inp_df[col0.isin(['Broadeners'])].iloc[0])[1:]\n",
    "        broadeners = [i for i in broadeners if i is not np.nan]\n",
    "        ratios = np.array(list(inp_df[col0.isin(['Ratios'])].iloc[0])[1:], dtype=float)\n",
    "        ratios = ratios[~np.isnan(ratios)]\n",
    "        wn_grid = np.linspace(min_wn, max_wn, N_point)\n",
    "        wn_wl = inp_df[col0.isin(['Wavenumber(wn)/wavelength(wl)'])][1].values[0].upper()\n",
    "        profile = inp_df[col0.isin(['Profile'])][1].values[0].upper().replace('PRO','')\n",
    "        \n",
    "        DopplerHWHMYN = inp_df[col0.isin(['DopplerHWHM(Y/N)'])][1].values[0].upper()[0]        \n",
    "        if 'DOP' in profile: \n",
    "            alpha_HWHM = 'None'\n",
    "        elif 'GAU' in profile:\n",
    "            if DopplerHWHMYN == 'Y':\n",
    "                alpha_HWHM = float(inp_df[col0.isin(['DopplerHWHM(Y/N)'])][2])\n",
    "            else:\n",
    "                raise ImportError(\"Gaussian line profile requires a HWHM. \" \n",
    "                                  + \"Please choose 'Y' and give a value for Doppler HWHM in the input file. \" \n",
    "                                  + \"Otherwise, please choose Doppler line profile \" \n",
    "                                  + \"(with calculated temperature-dependent Doppler HWHM).\")\n",
    "        elif 'VOI' in profile:\n",
    "            if DopplerHWHMYN == 'Y':\n",
    "                alpha_HWHM = float(inp_df[col0.isin(['DopplerHWHM(Y/N)'])][2])\n",
    "            elif DopplerHWHMYN == 'N':\n",
    "                alpha_HWHM = 'None'\n",
    "            else:\n",
    "                raise ImportError(\"Please type the correct Doppler HWHM choice 'Y' or 'N' into the input file.\")\n",
    "        else:\n",
    "            raise ImportError(\"Please type the correct line profile.\")\n",
    "            \n",
    "        LorentzianHWHMYN = inp_df[col0.isin(['LorentzianHWHM(Y/N)'])][1].values[0].upper()[0]  \n",
    "        if LorentzianHWHMYN == 'Y':\n",
    "            gamma_HWHM = float(inp_df[col0.isin(['LorentzianHWHM(Y/N)'])][2])\n",
    "        elif LorentzianHWHMYN == 'N':\n",
    "            gamma_HWHM = 'None'\n",
    "        else:\n",
    "            raise ImportError(\"Please type the correct Lorentzian HWHM choice 'Y' or 'N' into the input file.\")\n",
    "        \n",
    "        PlotCrossSectionYN = inp_df[col0.isin(['PlotCrossSection(Y/N)'])][1].values[0].upper()[0]\n",
    "        \n",
    "    else:\n",
    "        bin_size = 'None'\n",
    "        N_point = 'None'\n",
    "        cutoff = 'None'         \n",
    "        alpha_HWHM = 'None'        \n",
    "        gamma_HWHM = 'None'\n",
    "        broadeners = []\n",
    "        ratios = np.array([])\n",
    "        P = 0\n",
    "        wn_grid = np.linspace(0,1,1)\n",
    "        profile = 'None'\n",
    "        wn_wl = 'None'\n",
    "        PlotCrossSectionYN = 'None'\n",
    "                   \n",
    "    molecule_id = int(mol_iso_id/10)\n",
    "    isotopologue_id = mol_iso_id - molecule_id * 10\n",
    "        \n",
    "    if database == 'EXOMOL':\n",
    "        # Read ExoMol definition file (.def) to get the mass.\n",
    "        deffile_path = (read_path+'/'+molecule+'/'+isotopologue+'/'+dataset+'/'+isotopologue+'__'+dataset+'.def')\n",
    "        def_df = pd.read_csv(deffile_path,sep='\\\\s+',usecols=[0,1,2,3,4],names=['0','1','2','3','4'],header=None)\n",
    "        abundance = 1\n",
    "        mass = float(def_df[def_df['4'].isin(['mass'])]['0'].values[0])     # ExoMol mass (Dalton)\n",
    "        if def_df.to_string().find('Uncertainty') != -1:\n",
    "            check_uncertainty = int(def_df[def_df['2'].isin(['Uncertainty'])]['0'].values[0])\n",
    "        else:\n",
    "            check_uncertainty = 0\n",
    "        check_lifetime = int(def_df[def_df['2'].isin(['Lifetime'])]['0'].values[0])\n",
    "        check_gfactor = int(def_df[def_df['3'].isin(['g-factor'])]['0'].values[0])\n",
    "    elif database == 'HITRAN':\n",
    "        isometa_url = 'https://hitran.org/docs/iso-meta/'\n",
    "        iso_meta_table = pd.read_html(isometa_url)[molecule_id - 1]\n",
    "        iso_meta_row = iso_meta_table[iso_meta_table['local ID'].isin([isotopologue_id])]\n",
    "        abundance = float(iso_meta_row['Abundance'][0].replace('\\xa0×\\xa010','E'))\n",
    "        mass = float(iso_meta_row['Molar Mass /g·mol-1'])                   # HITRAN molar mass (g/mol)\n",
    "        check_uncertainty = 0\n",
    "        check_lifetime = 0\n",
    "        check_gfactor = 0\n",
    "    else:\n",
    "        raise ImportError(\"Please add the name of the database 'ExoMol' or 'HITRAN' into the input file.\")\n",
    "    \n",
    "\n",
    "    return (database, molecule, isotopologue, dataset, read_path, save_path, \n",
    "            Conversion, PartitionFunctions, CoolingFunctions, Lifetimes, SpecificHeats, StickSpectra, CrossSections,\n",
    "            ConversionFormat, ConversionMinFreq, ConversionMaxFreq, ConversionUnc, ConversionThreshold, \n",
    "            GlobalQNLabel_list, GlobalQNFormat_list, LocalQNLabel_list, LocalQNFormat_list,\n",
    "            Ntemp, Tmax, broadeners, ratios, T, P, min_wn, max_wn, N_point, bin_size, wn_grid, \n",
    "            cutoff, threshold, UncFilter, QNslabel_list, QNsformat_list, QNs_label, QNs_value, QNs_format, QNsFilter, \n",
    "            alpha_HWHM, gamma_HWHM, abs_emi, profile, wn_wl, molecule_id, isotopologue_id, abundance, mass,\n",
    "            check_uncertainty, check_lifetime, check_gfactor, PlotStickSpectraYN, PlotCrossSectionYN)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for calculating\n",
    "import astropy.constants as ac\n",
    "#from astropy import constants, units as ac, au\n",
    "Tref = 296.0                        # Reference temperature is 296 K\n",
    "Pref = 1.0                          # Reference pressure is 1 bar\n",
    "N_A = ac.N_A.value                  # Avogadro number (1/mol)\n",
    "h = ac.h.to('erg s').value          # Planck's const (erg s)\n",
    "c = ac.c.to('cm/s').value           # Velocity of light (cm/s)\n",
    "kB = ac.k_B.to('erg/K').value       # Boltzmann's const (erg/K)\n",
    "R = ac.R.to('J / (K mol)').value    # Molar gas constant (J/(K mol))\n",
    "c2 = h * c / kB                     # Second radiation constant (cm K)\n",
    "\n",
    "(database, molecule, isotopologue, dataset, read_path, save_path, \n",
    " Conversion, PartitionFunctions, CoolingFunctions, Lifetimes, SpecificHeats, StickSpectra, CrossSections,\n",
    " ConversionFormat, ConversionMinFreq, ConversionMaxFreq, ConversionUnc, ConversionThreshold, \n",
    " GlobalQNLabel_list, GlobalQNFormat_list, LocalQNLabel_list, LocalQNFormat_list,\n",
    " Ntemp, Tmax, broadeners, ratios, T, P, min_wn, max_wn, N_point, bin_size, wn_grid, \n",
    " cutoff, threshold, UncFilter, QNslabel_list, QNsformat_list, QNs_label, QNs_value, QNs_format, QNsFilter, \n",
    " alpha_HWHM, gamma_HWHM, abs_emi, profile, wn_wl, molecule_id, isotopologue_id, abundance, mass, \n",
    " check_uncertainty, check_lifetime, check_gfactor, PlotStickSpectraYN, PlotCrossSectionYN) = inp_para(inp_filepath)\n",
    "\n",
    "# Constants\n",
    "c2InvTref = c2 / Tref                 # c2 / T_ref (cm)\n",
    "PI = np.pi\n",
    "ln22 = np.log(2)*2\n",
    "sinPI = np.sin(np.pi)\n",
    "SqrtPI = np.sqrt(np.pi)\n",
    "Sqrtln2 = np.sqrt(np.log(2))\n",
    "OneminSqrtPIln2 = 1 - np.sqrt(np.pi * np.log(2))\n",
    "Negln2 = -np.log(2)\n",
    "Inv8Pic = 1 / (8 * np.pi * c)         # 8 * pi * c (s/cm)\n",
    "Inv4Pi = 1 / (4 * np.pi)\n",
    "Inv2ln2 = 1 / (2 * np.log(2))\n",
    "InvSqrt2 = 1 / np.sqrt(2)\n",
    "InvSqrtPi= 1 / np.sqrt(np.pi)\n",
    "InvSprtln2 = 1 / np.sqrt(np.log(2))\n",
    "InvSqrt2Pi = 1 / np.sqrt(2 * np.pi)\n",
    "InvSqrt2ln2 = 1 / np.sqrt(2 * np.log(2))\n",
    "TwoSqrt2ln2 = 2 * np.sqrt(2 * np.log(2))\n",
    "Sqrtln2InvPi = np.sqrt(np.log(2) / np.pi)\n",
    "Sqrt2NAkBln2mInvc = np.sqrt(2 * N_A * kB * np.log(2) / mass) / c\n",
    "if bin_size != 'None':\n",
    "    binSize2 = bin_size * 2\n",
    "    binSizePI = bin_size * np.pi\n",
    "    binSizeHalf = bin_size / 2 \n",
    "    InvbinSizePIhalf = 1 / (bin_size * np.pi**0.5)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Input Files\n",
    "\n",
    "Read the parameters of the linelist in ExoMol or HITRAN format text file. Return the dataframe of the data for the following calculations.\n",
    "\n",
    "## Read ExoMol Database Files\n",
    "\n",
    "### Read States File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all_states(read_path):\n",
    "    s_df = dict()\n",
    "    states_df = pd.DataFrame()\n",
    "    states_filenames = glob.glob(read_path + molecule + '/' + isotopologue + '/' + dataset \n",
    "                                 + '/' + isotopologue + '__' + dataset + '.states.bz2')\n",
    "    for states_filename in states_filenames:\n",
    "        s_df[states_filename] = pd.read_csv(states_filename, compression='bz2', sep='\\s+', header=None,\n",
    "                                            chunksize=1_000_000, iterator=True, low_memory=False, dtype=object)\n",
    "        for chunk in s_df[states_filename]:\n",
    "            states_df = pd.concat([states_df, chunk])\n",
    "    if check_uncertainty == 1:\n",
    "        states_df = states_df.rename(columns={0:'id',1:'E',2:'g',3:'J',4:'unc'})\n",
    "    else:      \n",
    "        states_df = states_df.rename(columns={0:'id',1:'E',2:'g',3:'J'})                      \n",
    "    return(states_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#states_df = read_all_states(read_path)\n",
    "#states_df "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read transitions File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transfiles(read_path):\n",
    "    # Get all the transitions files from the folder including the older version files which are named by vn(version number).\n",
    "    trans_filepaths_all = glob.glob(read_path + molecule + '/' + isotopologue + '/' + dataset + '/' + '*trans.bz2')\n",
    "    num_transfiles_all = len(trans_filepaths_all)    # The number of all transitions files including the older version files.\n",
    "    trans_filepaths = []    # The list of the lastest transitions files.\n",
    "    for i in range(num_transfiles_all):\n",
    "        split_version = trans_filepaths_all[i].split('__')[-1].split('.')[0].split('_')    # Split the filenames.\n",
    "        num = len(split_version)\n",
    "        # There are four format filenames.\n",
    "        # The lastest transitions files named in two formats:\n",
    "        # 1. Filenames are named with the name of isotopologue and dataset. \n",
    "        #    End with .trans.bz2.\n",
    "        #    e.g. 14N-16O__XABC.trans.bz2'\n",
    "        # 2. Filenames are named with the name of isotopologue and dataset. \n",
    "        #    Also have the range of wavenumbers xxxxx-yyyyy.\n",
    "        #    End with .trans.bz2.\n",
    "        #    e.g. 1H2-16O__POKAZATEL__00000-00100.trans.bz2\n",
    "        # 3. The older version transitions files are named with vn(version number) based on the first format of the lastest files.\n",
    "        #    e.g. 14N-16O__XABC_v2.trans.bz2\n",
    "        # 4. The older version transitions files are named with updated date (yyyymmdd).\n",
    "        #    e.g. 1H3_p__MiZATeP__20170330.trans.bz2\n",
    "        # After split the filenames:\n",
    "        # The first format filenames only leave the dataset name, e.g. XABC.\n",
    "        # The second format filenames only leave the range of the wavenumber, e.g. 00000-00100.\n",
    "        # The third format filenames leave two parts(dataset name and version number), e.g. XABC and v2.\n",
    "        # The fourth format filenames only leave the updated date, e.g. 20170330.\n",
    "        # This program only process the lastest data, so extract the filenames named by the first two format.\n",
    "        if num == 1:     \n",
    "            if split_version[0] == dataset:        \n",
    "                trans_filepaths.append(trans_filepaths_all[i])\n",
    "            if len(split_version[0].split('-')) == 2:\n",
    "                trans_filepaths.append(trans_filepaths_all[i])\n",
    "    return(trans_filepaths)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all_trans(read_path):\n",
    "    t_df = dict()\n",
    "    trans_df = pd.DataFrame()\n",
    "    trans_filepaths = get_transfiles(read_path)\n",
    "    print('Reading the transitions ...')\n",
    "    for trans_filename in tqdm(trans_filepaths, position=0, leave=True, ascii=True):\n",
    "        t_df[trans_filename] = pd.read_csv(trans_filename, compression='bz2', sep='\\s+', header=None,\n",
    "                                           chunksize=1_000_000, iterator=True, low_memory=False)\n",
    "        for chunk in t_df[trans_filename]:\n",
    "            trans_df = pd.concat([trans_df,chunk])\n",
    "    ncolumn = len(trans_df.columns)\n",
    "    if ncolumn == 3: \n",
    "        trans_col_name={0:'u', 1:'l', 2:'A'}\n",
    "    else:\n",
    "        trans_col_name={0:'u', 1:'l', 2:'A', 3:'v'}\n",
    "    trans_df = trans_df.rename(columns=trans_col_name)                         \n",
    "    return(trans_df, ncolumn)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(all_trans_df, ncolumn) = read_all_trans(read_path)\n",
    "#all_trans_df, ncolumn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert among the frequency, upper and lower state energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_v(Ep, Epp):\n",
    "    v = ne.evaluate('abs(Ep - Epp)')\n",
    "    return(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_Ep(Epp, v):\n",
    "    Ep = ne.evaluate('abs(Epp + v)')\n",
    "    return(Ep)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Partition Function File From ExoMol Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_exomolweb_pf(T):\n",
    "    pf_url = ('http://www.exomol.com/db/' + molecule + '/' + isotopologue + '/' + dataset \n",
    "              + '/' + isotopologue + '__' + dataset + '.pf')\n",
    "    pf_content = requests.get(pf_url).text\n",
    "    pf_col_name = ['T', 'Q']\n",
    "    pf_df = pd.read_csv(StringIO(pf_content), sep='\\\\s+', names=pf_col_name, header=None)\n",
    "    Q = pf_df['Q'][T-1]\n",
    "    return(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_exomol_pf(read_path, T):\n",
    "    pf_filename = (read_path + molecule + '/' + isotopologue + '/' + dataset \n",
    "                   + '/' + isotopologue + '__' + dataset + '.pf')\n",
    "    pf_col_name = ['T', 'Q']\n",
    "    pf_df = pd.read_csv(pf_filename, sep='\\\\s+', names=pf_col_name, header=None)\n",
    "    Q = pf_df['Q'][T-1]\n",
    "    return(Q)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Broadening File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_broad(read_path):\n",
    "    broad_df = pd.DataFrame()\n",
    "    broad_dfs = []\n",
    "    broad = []\n",
    "    ratio = []\n",
    "    for i in range(len(ratios)):\n",
    "        if ratios[i] != 0.0:\n",
    "            if broadeners[i].upper()[0:3] == 'DEF':\n",
    "                default_gamma_L = 0.07\n",
    "                default_n_air = 0.5\n",
    "                broad_df = pd.DataFrame([['code', default_gamma_L, default_n_air,'Jpp']])\n",
    "                broad_df = broad_df.rename(columns={0:'code', 1:'gamma_L', 2:'n_air', 3:'Jpp'})\n",
    "                broad_dfs.append(broad_df)\n",
    "            else:\n",
    "                broadener_name = str(broadeners[i])\n",
    "                pattern_broadener = read_path + molecule + '/**/*' + broadener_name + '.broad'\n",
    "                if glob.glob(pattern_broadener, recursive=True) != []:\n",
    "                    for fname_broadener in glob.glob(pattern_broadener, recursive=True):\n",
    "                        broad_df = pd.read_csv(fname_broadener, sep='\\s+', header=None, engine='python')\n",
    "                        broad_df = broad_df.rename(columns={0:'code', 1:'gamma_L', 2:'n_air', 3:'Jpp'})\n",
    "                        broad_dfs.append(broad_df)\n",
    "                else:\n",
    "                    raise ImportError('The ' + broadener_name + ' boradening file does not exist.') \n",
    "            broad.append(broadeners[i])\n",
    "            ratio.append(ratios[i])\n",
    "    nbroad = len(broad)\n",
    "    broad = list(i for i in broad if i==i)\n",
    "    ratio = list(i for i in ratio if i==i)\n",
    "    print('Broadeners \\t: ', str(broad).replace('[','').replace(']','').replace(\"'\",''))\n",
    "    print('Ratios \\t\\t: ', str(ratio).replace('[','').replace(']',''))\n",
    "    return(broad, ratio, nbroad, broad_dfs)        \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read HITRAN Database Files\n",
    "\n",
    "### Read HITRAN Linelist File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_hitran_parfile (read_path, parfile_df):\n",
    "    '''\n",
    "    Read the parameters of the molecular absorption features\n",
    "    of HITRAN2020 format text file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    par_filepath : str\n",
    "        Input file path for reading.\n",
    "    Return\n",
    "    ------\n",
    "    hitran_df : DataFrame\n",
    "        The DataFrame of HITRAN data for the molecule.\n",
    "    '''    \n",
    "    par_filename = read_path.split('/')[-1]\n",
    "    if (len(str(parfile_df[0][0])) < 160):\n",
    "        raise ImportError('The file ' + par_filename + ' is not a HITRAN2020 format data file.')\n",
    "    #hitran_column_name = ['M','I','v','S','Acoeff','gamma_air','gamma_self',\n",
    "    #                     'Epp','n_air','delta_air','Vp','Vpp','Qp','Qpp',\n",
    "    #                     'Ierr','Iref','flag','gp','gpp']\n",
    "\n",
    "    hitran_df = pd.DataFrame()\n",
    "    hitran_df['M'] = pd.to_numeric(parfile_df[0].map(lambda x: x[0:2]), errors='coerce').astype('int32')                 # Molecule identification number\n",
    "    hitran_df['I'] = pd.to_numeric(parfile_df[0].map(lambda x: x[2:3]), errors='coerce').astype('int32')                 # Isotopologue number\n",
    "    hitran_df['v'] = pd.to_numeric(parfile_df[0].map(lambda x: x[3:15]), errors='coerce').astype('float64')              # Transition wavenumber (in cm^{-1})\n",
    "    hitran_df['S'] = pd.to_numeric(parfile_df[0].map(lambda x: x[15:25]), errors='coerce').astype('float64')             # Intensity (cm^{-1} / (molecule cm^{-2}))\n",
    "    hitran_df['A'] = pd.to_numeric(parfile_df[0].map(lambda x: x[25:35]), errors='coerce').astype('float64')             # The Einstein-A coefficient (s^{-1}) of a transition\n",
    "    hitran_df['gamma_air'] = pd.to_numeric(parfile_df[0].map(lambda x: x[35:40]), errors='coerce').astype('float64')     # Air-broadened half-width at half maximum (HWHM) coefficient (cm^{-1} atm^{-1})\n",
    "    hitran_df['gamma_self'] = pd.to_numeric(parfile_df[0].map(lambda x: x[40:45]), errors='coerce').astype('float64')    # Self-broadened half-width at half maximum (HWHM) coefficient (cm^{-1} atm^{-1})\n",
    "    hitran_df['Epp'] = pd.to_numeric(parfile_df[0].map(lambda x: x[45:55]), errors='coerce').astype('float64')           # Lower state energy (cm^{-1})\n",
    "    hitran_df['n_air'] = pd.to_numeric(parfile_df[0].map(lambda x: x[55:59]), errors='coerce').astype('float64')         # Temperature-dependent exponent for gamma_air\n",
    "    hitran_df['delta_air'] = pd.to_numeric(parfile_df[0].map(lambda x: x[59:67]), errors='coerce').astype('float64')     # Air pressure_include line shift (cm^{-1} atm^{-1})\n",
    "    hitran_df['Vp'] = parfile_df[0].map(lambda x: x[67:82])                                                              # Upper-state \"global\" quanta\n",
    "    hitran_df['Vpp'] = parfile_df[0].map(lambda x: x[82:97])                                                             # Lower-state \"global\" quanta\n",
    "    hitran_df['Qp'] = parfile_df[0].map(lambda x: x[97:112])                                                             # Upper-state \"local\" quanta\n",
    "    hitran_df['Qpp'] = parfile_df[0].map(lambda x: x[112:127])                                                           # Lower-state \"local\" quanta\n",
    "    hitran_df['Unc'] = parfile_df[0].map(lambda x: x[127:128])                                                          # Uncertainty code, first integer in the error code\n",
    "    hitran_df['gp'] = pd.to_numeric(parfile_df[0].map(lambda x: x[146:153]), errors='coerce').astype('float64')          # Statistical weight of the upper state\n",
    "    hitran_df['gpp'] = pd.to_numeric(parfile_df[0].map(lambda x: x[153:160]), errors='coerce').astype('float64')         # Statistical weight of the upper state\n",
    "    \n",
    "    hitran_df = hitran_df[hitran_df['M'].isin([molecule_id])]\n",
    "    hitran_df = hitran_df[hitran_df['I'].isin([isotopologue_id])]\n",
    "    hitran_df = hitran_df[hitran_df['v'].between(min_wn, max_wn)]\n",
    "    if threshold != 'None':\n",
    "        hitran_df = hitran_df[hitran_df['S'] >= threshold]\n",
    "    return hitran_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_parfile(read_path):\n",
    "    if not os.path.exists(read_path):\n",
    "        raise ImportError('The input file ' + read_path + ' does not exist.')\n",
    "\n",
    "    # Initialise the iterator object.\n",
    "    read_par = pd.read_csv(read_path, chunksize=10000, iterator=True, header=None, encoding='utf-8')\n",
    "    par_df = pd.DataFrame()\n",
    "    for chunk in read_par:\n",
    "        par_df = pd.concat([par_df, chunk])\n",
    "    return(par_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Partition Function File From HITRANOnline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_hitran_pf(T):\n",
    "    isometa_url = 'https://hitran.org/docs/iso-meta/'\n",
    "    iso_meta_table = pd.read_html(isometa_url)[molecule_id - 1]\n",
    "    iso_meta_row = iso_meta_table[iso_meta_table['local ID'].isin([isotopologue_id])]\n",
    "    #Q_ref = float(iso_meta_row.loc[0][6].replace('\\xa0×\\xa010','E'))\n",
    "    Q_url = 'https://hitran.org/data/Q/' + iso_meta_row.loc[0][7]\n",
    "    Q_content = requests.get(Q_url).text\n",
    "    Q_col_name = ['T', 'Q']\n",
    "    Q_df = pd.read_csv(StringIO(Q_content), sep='\\\\s+', names=Q_col_name, header=None)\n",
    "    Q = Q_df['Q'][T - 1]   \n",
    "    return(Q)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Parition Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_partition(En, gn, T):\n",
    "    partition_func = ne.evaluate('sum(gn * exp(-c2 * En / T))') \n",
    "    return(partition_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partition function\n",
    "def exomol_partition_func(states_df, Ntemp, Tmax):\n",
    "    \n",
    "    print('Calculate partition functions.')  \n",
    "    t = Timer()\n",
    "    t.start()\n",
    "    \n",
    "    #states_df = read_all_states(read_path)\n",
    "    En = states_df['E'].astype('float').values\n",
    "    gn = states_df['g'].astype('int').values\n",
    "    Ts = np.array(range(Ntemp, Tmax+1, Ntemp)) \n",
    "    \n",
    "    partition_func = [calculate_partition(En, gn, T) for T in Ts]\n",
    "    \n",
    "    partition_func_df = pd.DataFrame()\n",
    "    partition_func_df['T'] = Ts\n",
    "    partition_func_df['partition function'] = partition_func\n",
    "        \n",
    "    pf_folder = save_path + '/partition/'\n",
    "    if os.path.exists(pf_folder):\n",
    "        pass\n",
    "    else:\n",
    "        os.makedirs(pf_folder, exist_ok=True)\n",
    "    pf_path = pf_folder + isotopologue + '__' + dataset + '.pf'\n",
    "    np.savetxt(pf_path, partition_func_df, fmt=\"%8.1f %15.4f\")\n",
    "    \n",
    "    t.end()\n",
    "    print('Partition functions has been saved!\\n')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ntemp = 1\n",
    "#max = int(5000.00)\n",
    "\n",
    "#exomol_partition_func(states_df, Ntemp, Tmax)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specific Heat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_specific_heats(En, gn, T):\n",
    "    pf = ne.evaluate('sum(gn * exp(-c2 * En / T)) ')  \n",
    "    pfp = ne.evaluate('sum(gn * exp(-c2 * En / T) * (c2 * En / T))')\n",
    "    pfpp = ne.evaluate('sum(gn * exp(-c2 * En / T) * (c2 * En / T) ** 2)')\n",
    "    specificheat_func = ne.evaluate('R * (pfpp / pf - (pfp / pf)**2) + 2.5 * R') \n",
    "    return(specificheat_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specific heat\n",
    "def exomol_specificheat(states_df, Ntemp, Tmax):\n",
    "    print('Calculate specific heats.')  \n",
    "    t = Timer()\n",
    "    t.start()\n",
    "    \n",
    "    #states_df = read_all_states(read_path)\n",
    "    En = states_df['E'].astype('float').values\n",
    "    gn = states_df['g'].astype('int').values\n",
    "    Ts = np.array(range(200, Tmax+1, Ntemp)) \n",
    "    \n",
    "    specificheat_func = [calculate_specific_heats(En, gn, T) for T in Ts]\n",
    "    \n",
    "    specificheat_func_df = pd.DataFrame()\n",
    "    specificheat_func_df['T'] = Ts\n",
    "    specificheat_func_df['specific heat'] = specificheat_func\n",
    "        \n",
    "    cp_folder = save_path + '/specific_heat/'\n",
    "    if os.path.exists(cp_folder):\n",
    "        pass\n",
    "    else:\n",
    "        os.makedirs(cp_folder, exist_ok=True)  \n",
    "    cp_path = cp_folder + isotopologue + '__' + dataset + '.cp'\n",
    "    np.savetxt(cp_path, specificheat_func_df, fmt=\"%8.1f %15.4f\")\n",
    "\n",
    "    t.end()\n",
    "    print('Specific heats has been saved!\\n')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ntemp = 1\n",
    "#Tmax = int(5000.0)\n",
    "\n",
    "#exomol_specificheat(states_df, Ntemp, Tmax)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lifetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lifetime\n",
    "def exomol_lifetime(read_path, states_df, all_trans_df):\n",
    "    \n",
    "    print('Calculate lifetimes.')  \n",
    "    t = Timer()\n",
    "    t.start()\n",
    "    \n",
    "    #states_df = read_all_states(read_path)\n",
    "    #(all_trans_df, ncolumn) = read_all_trans(read_path)\n",
    "    sum_A = all_trans_df.groupby('u')['A'].sum()\n",
    "    lifetime = ne.evaluate('1 / sum_A') \n",
    "    lt_df = pd.Series(lifetime).map('{: >12.4E}'.format).reset_index()\n",
    "    lt_df.columns=['u','lt']\n",
    "    uid = lt_df['u']\n",
    "    add_u = pd.DataFrame()\n",
    "    add_u['u'] = pd.concat([states_df['id'].astype('int'), uid]).drop_duplicates(keep=False)\n",
    "    add_u['lt'] = '         inf'\n",
    "    lifetime_df = pd.concat([lt_df, add_u], ignore_index=True)\n",
    "    lifetime_df.sort_values('u',inplace=True)\n",
    "    \n",
    "    states_filenames = glob.glob(read_path + molecule + '/' + isotopologue + '/' + dataset \n",
    "                                 + '/' + isotopologue + '__' + dataset + '.states.bz2')\n",
    "    s_df = pd.read_csv(states_filenames[0], compression='bz2', header=None, dtype=object)\n",
    "    lifetime_list = list(lifetime_df['lt'])\n",
    "    nrows = len(s_df)\n",
    "    new_rows = []\n",
    "    if check_uncertainty == 0:\n",
    "        for i in range(nrows):\n",
    "            new_rows.append(s_df[0][i][:41]+lifetime_list[i]+s_df[0][i][53:]+'\\n')\n",
    "    if check_uncertainty == 1:\n",
    "        for i in range(nrows):\n",
    "            new_rows.append(s_df[0][i][:53]+lifetime_list[i]+s_df[0][i][65:]+'\\n')\n",
    "\n",
    "    lf_folder = save_path + '/lifetime/'\n",
    "    if os.path.exists(lf_folder):\n",
    "        pass\n",
    "    else:\n",
    "        os.makedirs(lf_folder, exist_ok=True)  \n",
    "        \n",
    "    ###### bz2 #######\n",
    "    lf_path = lf_folder + isotopologue + '__' + dataset + '.states.bz2'\n",
    "\n",
    "    with bz2.open(lf_path, 'wt') as f:\n",
    "        for i in range(nrows):\n",
    "            f.write(new_rows[i])\n",
    "        f.close\n",
    "    ##################\n",
    "    \n",
    "    ##### states #####\n",
    "    '''\n",
    "    lf_path = lf_folder + isotopologue + '__' + dataset + '.states'\n",
    "\n",
    "    with open(lf_path, 'wt') as f:\n",
    "        for i in range(nrows):\n",
    "            f.write(new_rows[i])\n",
    "        f.close\n",
    "    '''\n",
    "    ##################\n",
    "\n",
    "    t.end()\n",
    "    print('Lifetimes has been saved!\\n')   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exomol_lifetime(read_path, states_df, all_trans_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cooling Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linelist_coolingfunc(states_df, all_trans_df, ncolumn):\n",
    "    #states_df = read_all_states(read_path)\n",
    "    #(all_trans_df, ncolumn) = read_all_trans(read_path)\n",
    "    id_u = all_trans_df['u'].values\n",
    "    id_l = all_trans_df['l'].values\n",
    "    states_df['id'] = pd.to_numeric(states_df['id'])\n",
    "    states_df.set_index(['id'], inplace=True, drop=False)\n",
    "    id_s = states_df['id']\n",
    "    all_trans_df.set_index(['u'], inplace=True, drop=False)\n",
    "    id_us = list(set(id_u).intersection(set(id_s)))\n",
    "    trans_us_df = all_trans_df.loc[id_us]\n",
    "    id_l = trans_us_df['l'].values\n",
    "    id_ls = list(set(id_l).intersection(set(id_s)))\n",
    "    trans_us_df.set_index(['l'], inplace=True, drop=False)\n",
    "    trans_s_df = trans_us_df.loc[id_ls]\n",
    "    id_su = trans_s_df['u'].values\n",
    "    id_sl = trans_s_df['l'].values\n",
    "    states_u_df = states_df.loc[id_su]\n",
    "    states_l_df = states_df.loc[id_sl]\n",
    "\n",
    "    Ep = states_u_df['E'].values.astype('float')\n",
    "    gp = states_u_df['g'].values.astype('int')\n",
    "    A = trans_s_df['A'].values.astype('float')\n",
    "\n",
    "    if ncolumn == 4:\n",
    "        v = trans_s_df['v'].values.astype('float')\n",
    "    else:\n",
    "        Epp = states_l_df['E'].astype('float') # Upper state energy\n",
    "        v = cal_v(Ep, Epp) \n",
    "    return (A, v, Ep, gp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cooling(A, v, Ep, gp, T, Q):\n",
    "    # cooling_func = np.sum(A * h * c * v * gp * np.exp(-c2 * Ep / T)) / (4 * PI * Q) \n",
    "    _sum = ne.evaluate('sum(A * h * c * v * gp * exp(-c2 * Ep / T))')  \n",
    "    cooling_func = ne.evaluate('_sum / (4 * PI * Q)')\n",
    "    return(cooling_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cooling function\n",
    "def exomol_cooling_func(read_path, states_df, all_trans_df, Ntemp, Tmax, ncolumn):\n",
    "    \n",
    "    print('Calculate cooling functions.')  \n",
    "    t = Timer()\n",
    "    t.start()\n",
    "    \n",
    "    A, v, Ep, gp = linelist_coolingfunc(states_df, all_trans_df, ncolumn)\n",
    "    Ts = np.array(range(Ntemp, Tmax+1, Ntemp)) \n",
    "    Qs = [read_exomol_pf(read_path, T) for T in Ts]\n",
    "    \n",
    "    cooling_func = [calculate_cooling(A, v, Ep, gp, T, Q) for T,Q in zip(Ts,Qs)]\n",
    "    \n",
    "    cooling_func_df = pd.DataFrame()\n",
    "    cooling_func_df['T'] = Ts\n",
    "    cooling_func_df['cooling function'] = cooling_func\n",
    "\n",
    "    cf_folder = save_path + '/cooling/'\n",
    "    if os.path.exists(cf_folder):\n",
    "        pass\n",
    "    else:\n",
    "        os.makedirs(cf_folder, exist_ok=True)  \n",
    "    cf_path = cf_folder + isotopologue + '__' + dataset + '.cf' \n",
    "    np.savetxt(cf_path, cooling_func_df, fmt=\"%8.1f %20.8E\")\n",
    "    \n",
    "    t.end()\n",
    "    print('Cooling functions has been saved!\\n')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ntemp = 1\n",
    "#Tmax = int(1500.00)\n",
    "\n",
    "#exomol_cooling_func(read_path, states_df, all_trans_df, Ntemp, Tmax, ncolumn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_part_states(states_df):\n",
    "    if UncFilter != 'None' :\n",
    "        states_part_df = states_df[states_df['unc'].astype(float) <= UncFilter]\n",
    "        states_part_df['id'] = pd.to_numeric(states_part_df['id'])\n",
    "        states_part_df.set_index(['id'], inplace=True, drop=False)\n",
    "    else:\n",
    "        states_part_df = states_df\n",
    "        states_part_df['id'] = pd.to_numeric(states_part_df['id'])\n",
    "        states_part_df.set_index(['id'], inplace=True, drop=False)\n",
    "    if check_uncertainty == 1:\n",
    "        col_unc = ['unc']\n",
    "    else:\n",
    "        col_unc = []\n",
    "    if check_lifetime == 1:\n",
    "        col_lifetime = ['tau']\n",
    "    else:\n",
    "        col_lifetime = []\n",
    "    if check_gfactor == 1:\n",
    "        col_gfac = ['gfac']\n",
    "    else:\n",
    "        col_gfac = []\n",
    "    colname = ['id','E','g','J'] + col_unc + col_lifetime + col_gfac + QNslabel_list\n",
    "    states_part_df.drop(states_part_df.columns[len(colname):], axis=1, inplace=True)\n",
    "    states_part_df.columns = colname\n",
    "    QNcolumns = ['id','E','g','J'] + col_unc + col_lifetime + col_gfac + QNs_label\n",
    "    states_part_df = states_part_df[QNcolumns]\n",
    "    if QNsFilter !=[]:    \n",
    "        for i in range(len(QNs_label)):\n",
    "            if QNs_value[i] != ['']:\n",
    "                states_part_df = states_part_df[states_part_df[QNs_label[i]].isin(QNs_value[i])]\n",
    "    pd.set_option(\"display.max_columns\",30)  \n",
    "    return(states_part_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_part_transfiles(read_path):\n",
    "    # Get all the transitions files from the folder including the older version files which are named by vn(version number).\n",
    "    trans_filepaths_all = glob.glob(read_path + molecule + '/' + isotopologue + '/' + dataset + '/' + '*trans.bz2')\n",
    "    num_transfiles_all = len(trans_filepaths_all)    # The number of all transitions files including the older version files.\n",
    "    trans_filepaths = []    # The list of the lastest transitions files.\n",
    "    for i in range(num_transfiles_all):\n",
    "        split_version = trans_filepaths_all[i].split('__')[-1].split('.')[0].split('_')    # Split the filenames.\n",
    "        num = len(split_version)\n",
    "        # There are four format filenames.\n",
    "        # The lastest transitions files named in two formats:\n",
    "        # 1. Filenames are named with the name of isotopologue and dataset. \n",
    "        #    End with .trans.bz2.\n",
    "        #    e.g. 14N-16O__XABC.trans.bz2'\n",
    "        # 2. Filenames are named with the name of isotopologue and dataset. \n",
    "        #    Also have the range of wavenumbers xxxxx-yyyyy.\n",
    "        #    End with .trans.bz2.\n",
    "        #    e.g. 1H2-16O__POKAZATEL__00000-00100.trans.bz2\n",
    "        # 3. The older version transitions files are named with vn(version number) based on the first format of the lastest files.\n",
    "        #    e.g. 14N-16O__XABC_v2.trans.bz2\n",
    "        # 4. The older version transitions files are named with updated date (yyyymmdd).\n",
    "        #    e.g. 1H3_p__MiZATeP__20170330.trans.bz2\n",
    "        # After split the filenames:\n",
    "        # The first format filenames only leave the dataset name, e.g. XABC.\n",
    "        # The second format filenames only leave the range of the wavenumber, e.g. 00000-00100.\n",
    "        # The third format filenames leave two parts(dataset name and version number), e.g. XABC and v2.\n",
    "        # The fourth format filenames only leave the updated date, e.g. 20170330.\n",
    "        # This program only process the lastest data, so extract the filenames named by the first two format.\n",
    "        if num == 1:     \n",
    "            if split_version[0] == dataset:        \n",
    "                trans_filepaths.append(trans_filepaths_all[i])\n",
    "            elif len(split_version[0].split('-')) == 2:\n",
    "                trans_filepaths.append(trans_filepaths_all[i])\n",
    "        \n",
    "    if len(trans_filepaths) == 1:\n",
    "        filenames = trans_filepaths\n",
    "    else:\n",
    "        filenames = []\n",
    "        for trans_filename in tqdm(trans_filepaths, position=0, leave=True, ascii=True):\n",
    "            lower = int(trans_filename.split('__')[2].split('.')[0].split('-')[0])\n",
    "            upper = int(trans_filename.split('__')[2].split('.')[0].split('-')[1]) \n",
    "            if (lower <= int(min_wn) < upper):\n",
    "                filenames.append(trans_filename)\n",
    "            if (lower >= int(min_wn) and upper <= int(max_wn)):\n",
    "                filenames.append(trans_filename)\n",
    "            if (lower <= int(max_wn) < upper):\n",
    "                filenames.append(trans_filename)    \n",
    "    return(list(set(filenames)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_part_trans(read_path):\n",
    "    trans_filenames = get_part_transfiles(read_path)\n",
    "    t_df = dict()\n",
    "    trans_part_df = pd.DataFrame()\n",
    "    # Initialise the iterator object.\n",
    "    for trans_filename in tqdm(trans_filenames, position=0, leave=True, ascii=True):\n",
    "        t_df[trans_filename] = pd.read_csv(trans_filename, compression='bz2', sep='\\s+', header=None, \n",
    "                                           chunksize=1_000_000, iterator=True, encoding='utf-8')\n",
    "        for chunk in t_df[trans_filename]:\n",
    "            trans_part_df = pd.concat([trans_part_df, chunk])\n",
    "    ncolumn = len(trans_part_df.columns)\n",
    "    if ncolumn == 3: \n",
    "        trans_col_name={0:'u', 1:'l', 2:'A'}\n",
    "    else:\n",
    "        trans_col_name={0:'u', 1:'l', 2:'A', 3:'v'}\n",
    "    trans_part_df = trans_part_df.rename(columns=trans_col_name)\n",
    "    return(trans_part_df, ncolumn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_broad(broad_df, states_l_df):\n",
    "    J_df = pd.DataFrame()\n",
    "    max_broad_J = max(broad_df['Jpp'])\n",
    "    J_df['Jpp'] = states_l_df['J'].values.astype('float')\n",
    "    J_df['Jpp'][J_df.Jpp > max_broad_J] = max_broad_J\n",
    "    id_broad = (J_df['Jpp']-0.1).round(0).astype(int)\n",
    "    gamma_L = broad_df['gamma_L'][id_broad].values\n",
    "    n_air = broad_df['n_air'][id_broad].values\n",
    "    return(gamma_L, n_air)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_abscoefs(v, gp, A, Epp, Q, abundance):\n",
    "    #abscoef = gp * A * np.exp(- c2 * Epp / T) * (1 - np.exp(- c2 * v / T)) / (8 * np.pi * c * v**2 * Q) * abundance  \n",
    "    abscoef = ne.evaluate('gp * A * exp(- c2 * Epp / T) * (1 - exp(- c2 * v / T)) * Inv8Pic / (v ** 2 * Q) * abundance')  \n",
    "    return abscoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_emicoefs(v, gp, A, Ep, Q, abundance):\n",
    "    # emicoef = gp * A * v * np.exp(- c2 * Ep / T) / (4 * np.pi) / Q * abundance   \n",
    "    emicoef = ne.evaluate('gp * A * v * exp(- c2 * Ep / T) * Inv4Pi / Q * abundance')\n",
    "    return emicoef"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_uncertainty(unc_u, unc_l):\n",
    "    unc = ne.evaluate('sqrt(unc_u ** 2 + unc_l ** 2)')\n",
    "    return unc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversion\n",
    "\n",
    "## ExoMol to HITRAN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_QNValues_exomol2hitran(states_unc_df, GlobalQNLabel_list, LocalQNLabel_list):\n",
    "    QNLabel_list = GlobalQNLabel_list+LocalQNLabel_list\n",
    "    if 'Gtot' in QNLabel_list:\n",
    "        states_unc_df[\"Gtot\"] = (states_unc_df[\"Gtot\"].replace('1',\"A1'\").replace('2',\"A2'\").replace('3',\"E'\")\n",
    "                                 .replace('4','A1\"').replace('5','A2\"').replace('6','E\"'))\n",
    "    if 'Gvib' in QNLabel_list:\n",
    "        states_unc_df[\"Gvib\"] = (states_unc_df[\"Gvib\"].replace('1',\"A1'\").replace('2',\"A2'\").replace('3',\"E'\")\n",
    "                                 .replace('4','A1\"').replace('5','A2\"').replace('6','E\"'))   \n",
    "    if 'Grot' in QNLabel_list:\n",
    "        states_unc_df[\"Grot\"] = (states_unc_df[\"Grot\"].replace('1',\"A1'\").replace('2',\"A2'\").replace('3',\"E'\")\n",
    "                                 .replace('4','A1\"').replace('5','A2\"').replace('6','E\"'))                   \n",
    "    if 'taui' in QNLabel_list:\n",
    "        states_unc_df[\"taui\"] = states_unc_df[\"taui\"].replace('0','s').replace('1','a')\n",
    "    return(states_unc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_unc_states(states_df):\n",
    "    if Conversion != 0:\n",
    "        if ConversionUnc != 'None':\n",
    "            states_unc_df = states_df[states_df['unc'].astype(float) <= ConversionUnc]\n",
    "        else:\n",
    "            states_unc_df = states_df\n",
    "        states_unc_df['id'] = pd.to_numeric(states_unc_df['id'])\n",
    "        states_unc_df.set_index(['id'], inplace=True, drop=False)\n",
    "    else:\n",
    "        states_unc_df = states_df\n",
    "        states_unc_df['id'] = pd.to_numeric(states_unc_df['id'])\n",
    "        states_unc_df.set_index(['id'], inplace=True, drop=False)\n",
    "    if check_uncertainty == 1:\n",
    "        col_unc = ['unc']\n",
    "    else:\n",
    "        col_unc = []\n",
    "    if check_lifetime == 1:\n",
    "        col_lifetime = ['tau']\n",
    "    else:\n",
    "        col_lifetime = []\n",
    "    if check_gfactor == 1:\n",
    "        col_gfac = ['gfac']\n",
    "    else:\n",
    "        col_gfac = []\n",
    "    fullcolname = ['id','E','g','J'] + col_unc + col_lifetime + col_gfac + QNslabel_list\n",
    "    states_unc_df = states_unc_df.iloc[:, : len(fullcolname)]\n",
    "    states_unc_df.columns = fullcolname  \n",
    "    colnames = ['id','E','g'] + col_unc + GlobalQNLabel_list + LocalQNLabel_list\n",
    "    states_unc_df = states_unc_df[colnames] \n",
    "    states_unc_df = convert_QNValues_exomol2hitran(states_unc_df, GlobalQNLabel_list, LocalQNLabel_list)\n",
    "    #pd.set_option(\"display.max_columns\",30) \n",
    "    return(states_unc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_QNFormat_exomol2hitran(states_u_df, states_l_df, GlobalQNLabel_list, GlobalQNFormat_list, \n",
    "                                   LocalQNLabel_list, LocalQNFormat_list):\n",
    "    from pandarallel import pandarallel\n",
    "    pandarallel.initialize(nb_workers=8,progress_bar=False)    # Initialize.\n",
    "\n",
    "    gQNp = pd.DataFrame()\n",
    "    gQNpp = pd.DataFrame()\n",
    "    n_gQN = len(GlobalQNLabel_list)\n",
    "    for i in range(n_gQN):\n",
    "        gQN_format = GlobalQNFormat_list[i].replace(\"%\",'{: >')+'}'\n",
    "        gQN_label = GlobalQNLabel_list[i]\n",
    "        try:\n",
    "            if 'd' in gQN_format or 'f' in gQN_format: \n",
    "                gQNp[gQN_label+\"'\"] = pd.Series(pd.to_numeric(states_u_df[gQN_label]\n",
    "                                                              .values)).parallel_map(gQN_format.format)\n",
    "                gQNpp[gQN_label+'\"'] = pd.Series(pd.to_numeric(states_l_df[gQN_label]\n",
    "                                                               .values)).parallel_map(gQN_format.format)\n",
    "            elif 's' in gQN_format or 'a' in gQN_format: \n",
    "                gQNp[gQN_label+\"'\"] = pd.Series(states_u_df[gQN_label].str.replace('(','',regex=True)\n",
    "                                                .str.replace(')','',regex=True).values).parallel_map(gQN_format.format)\n",
    "                gQNpp[gQN_label+'\"'] = pd.Series(states_l_df[gQN_label].str.replace('(','',regex=True)\n",
    "                                                .str.replace(')','',regex=True).values).parallel_map(gQN_format.format)\n",
    "        except:\n",
    "            if 'd' in gQN_format or 'f' in gQN_format: \n",
    "                gQNp[gQN_label+\"'\"] = pd.Series(pd.to_numeric(states_u_df[gQN_label].values)).map(gQN_format.format)\n",
    "                gQNpp[gQN_label+'\"'] = pd.Series(pd.to_numeric(states_l_df[gQN_label].values)).map(gQN_format.format)\n",
    "            elif 's' in gQN_format or 'a' in gQN_format:       \n",
    "                gQNp[gQN_label+\"'\"] = pd.Series(states_u_df[gQN_label].str.replace('(','',regex=True)\n",
    "                                                .str.replace(')','',regex=True).values).map(gQN_format.format)\n",
    "                gQNpp[gQN_label+'\"'] = pd.Series(states_l_df[gQN_label].str.replace('(','',regex=True)\n",
    "                                                .str.replace(')','',regex=True).values).map(gQN_format.format)\n",
    "    globalQNp = pd.DataFrame(gQNp).sum(axis=1).map('{: >15}'.format) \n",
    "    globalQNpp = pd.DataFrame(gQNpp).sum(axis=1).map('{: >15}'.format)  \n",
    "\n",
    "    lQNp = pd.DataFrame()\n",
    "    lQNpp = pd.DataFrame()\n",
    "    n_lQN = len(LocalQNLabel_list)\n",
    "    for i in range(n_lQN):\n",
    "        lQN_format = LocalQNFormat_list[i].replace(\"%\",'{: >')+'}'\n",
    "        lQN_label = LocalQNLabel_list[i]\n",
    "        try:\n",
    "            if 'd' in lQN_format or 'f' in lQN_format: \n",
    "                lQNp[lQN_label+\"'\"] = pd.Series(pd.to_numeric(states_u_df[lQN_label].values)).parallel_map(lQN_format.format)\n",
    "                lQNpp[lQN_label+'\"'] = pd.Series(pd.to_numeric(states_l_df[lQN_label].values)).parallel_map(lQN_format.format)\n",
    "            elif 's' in lQN_format or 'a' in lQN_format: \n",
    "                lQNp[lQN_label+\"'\"] = pd.Series(states_u_df[lQN_label].str.replace('(','',regex=True)\n",
    "                                                .str.replace(')','',regex=True).values).parallel_map(lQN_format.format)\n",
    "                lQNpp[lQN_label+'\"'] = pd.Series(states_l_df[lQN_label].str.replace('(','',regex=True)\n",
    "                                                .str.replace(')','',regex=True).values).parallel_map(lQN_format.format)\n",
    "        except:\n",
    "            if 'd' in lQN_format or 'f' in lQN_format: \n",
    "                lQNp[lQN_label+\"'\"] = pd.Series(pd.to_numeric(states_u_df[lQN_label].values)).map(lQN_format.format)\n",
    "                lQNpp[lQN_label+'\"'] = pd.Series(pd.to_numeric(states_l_df[lQN_label].values)).map(lQN_format.format)\n",
    "            elif 's' in lQN_format or 'a' in lQN_format: \n",
    "                lQNp[lQN_label+\"'\"] = pd.Series(states_u_df[lQN_label].str.replace('(','',regex=True)\n",
    "                                                .str.replace(')','',regex=True).values).map(lQN_format.format)\n",
    "                lQNpp[lQN_label+'\"'] = pd.Series(states_l_df[lQN_label].str.replace('(','',regex=True)\n",
    "                                                .str.replace(')','',regex=True).values).map(lQN_format.format)\n",
    "            \n",
    "    localQNp = pd.DataFrame(lQNp).sum(axis=1).map('{: >15}'.format) \n",
    "    localQNpp = pd.DataFrame(lQNpp).sum(axis=1).map('{: >15}'.format)  \n",
    "\n",
    "    QN_df = pd.concat([globalQNp,globalQNpp,localQNp,localQNpp],axis='columns')\n",
    "    QN_df.columns = [\"V'\", 'V\"', \"Q'\", 'Q\"']\n",
    "    return(QN_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linelist_ExoMol2HITRAN(states_unc_df,trans_part_df, ncolumn):\n",
    "    \n",
    "    if ncolumn == 4:\n",
    "        trans_part_df = trans_part_df[trans_part_df['v'].between(ConversionMinFreq,ConversionMaxFreq)] \n",
    "        id_u = trans_part_df['u'].values\n",
    "        id_s = states_unc_df['id'].values\n",
    "\n",
    "        trans_part_df.set_index(['u'], inplace=True, drop=False)\n",
    "        id_us = list(set(id_u).intersection(set(id_s)))\n",
    "        trans_us_df = trans_part_df.loc[id_us]\n",
    "\n",
    "        id_l = trans_us_df['l'].values\n",
    "        id_ls = list(set(id_l).intersection(set(id_s)))\n",
    "        trans_us_df.set_index(['l'], inplace=True, drop=False)\n",
    "        trans_s_df = trans_us_df.loc[id_ls]\n",
    "        trans_s_df.sort_values(by=['v'], inplace=True)\n",
    "    else:\n",
    "        id_u = trans_part_df['u'].values\n",
    "        id_s = pd.to_numeric(states_unc_df['id']).values\n",
    "\n",
    "        trans_part_df.set_index(['u'], inplace=True, drop=False)\n",
    "        id_us = list(set(id_u).intersection(set(id_s)))\n",
    "        trans_us_df = trans_part_df.loc[id_us]\n",
    "\n",
    "        id_l = trans_us_df['l'].values\n",
    "        id_ls = list(set(id_l).intersection(set(id_s)))\n",
    "        trans_us_df.set_index(['l'], inplace=True, drop=False)\n",
    "        trans_s_df = trans_us_df.loc[id_ls]\n",
    "\n",
    "        id_su = trans_s_df['u'].values\n",
    "        id_sl = trans_s_df['l'].values\n",
    "        states_u_df = states_unc_df.loc[id_su]\n",
    "        states_l_df = states_unc_df.loc[id_sl]\n",
    "\n",
    "        Ep = states_u_df['E'].values.astype('float')\n",
    "        Epp = states_l_df['E'].values.astype('float')\n",
    "        trans_s_df['v'] = cal_v(Ep, Epp)\n",
    "        trans_s_df = trans_s_df[trans_s_df['v'].between(ConversionMinFreq,ConversionMaxFreq)] \n",
    "        trans_s_df.sort_values(by=['v'], inplace=True)\n",
    "        \n",
    "    id_su = trans_s_df['u'].values\n",
    "    id_sl = trans_s_df['l'].values\n",
    "    states_u_df = states_unc_df.loc[id_su]\n",
    "    states_l_df = states_unc_df.loc[id_sl]\n",
    "\n",
    "    Ep = states_u_df['E'].values.astype('float')\n",
    "    Epp = states_l_df['E'].values.astype('float')\n",
    "    gp = states_u_df['g'].values.astype('int')\n",
    "    gpp = states_l_df['g'].values.astype('int')\n",
    "    A = trans_s_df['A'].values.astype('float')\n",
    "    v = trans_s_df['v'].values.astype('float')\n",
    "    unc_u = states_u_df['unc'].values.astype('float')\n",
    "    unc_l = states_l_df['unc'].values.astype('float')\n",
    "    unc = cal_uncertainty(unc_u, unc_l)\n",
    "    \n",
    "    broad_col_name = ['code', 'gamma_L', 'n_air', 'Jpp']\n",
    "    default_broad_df = pd.DataFrame(columns=broad_col_name)\n",
    "    default_gamma_L = 0.07\n",
    "    default_n_air = 0.5\n",
    "    default_broad_df = pd.DataFrame([['code', default_gamma_L, default_n_air,'Jpp']],columns=broad_col_name)\n",
    "    air_broad_df = pd.DataFrame(columns=broad_col_name)\n",
    "    rows = len(id_sl)\n",
    "    pattern_air = read_path + molecule + '/**/*air.broad'\n",
    "    if glob.glob(pattern_air, recursive=True) != []:\n",
    "        for fname_air in glob.glob(pattern_air, recursive=True):\n",
    "            air_broad_df = pd.read_csv(fname_air, sep='\\s+', names=broad_col_name, header=None, engine='python')\n",
    "            gamma_air = extract_broad(air_broad_df,states_l_df)[0]\n",
    "            n_air = extract_broad(air_broad_df,states_l_df)[1]\n",
    "    else:\n",
    "        gamma_air= np.full((1,rows),default_broad_df['gamma_L'][0])[0]\n",
    "        n_air = np.full((1,rows),default_broad_df['n_air'][0])[0]\n",
    "    pattern_self = read_path + molecule + '/**/*self.broad'\n",
    "    if glob.glob(pattern_self, recursive=True) != []:\n",
    "        for fname_self in glob.glob(pattern_self, recursive=True):\n",
    "            self_broad_df = pd.read_csv(fname_self, sep='\\s+', names=broad_col_name, header=None, engine='python')\n",
    "            gamma_self = extract_broad(self_broad_df,states_l_df)[0]\n",
    "    else:\n",
    "        gamma_self= np.full((1,rows),default_broad_df['gamma_L'][0])[0]  \n",
    "    \n",
    "    QN_df = convert_QNFormat_exomol2hitran(states_u_df, states_l_df, GlobalQNLabel_list, GlobalQNFormat_list, LocalQNLabel_list, LocalQNFormat_list)\n",
    "\n",
    "    return (A, v, Ep, Epp, gp, gpp, unc, gamma_air, gamma_self, n_air, QN_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_code(unc):\n",
    "    unc[(1<=unc)] = '000000'\n",
    "    unc[(0.1<=unc) & (unc<1)] = '140000'\n",
    "    unc[(0.01<=unc) & (unc<0.1)] = '240000'\n",
    "    unc[(0.001<=unc) & (unc<0.01)] = '340000'\n",
    "    unc[(0.0001<=unc) & (unc<0.001)] = '440000'\n",
    "    unc[(0.00001<=unc) & (unc<0.0001)] = '540000'\n",
    "    unc[(0.000001<=unc) & (unc<0.00001)] = '640000'\n",
    "    unc[(0.0000001<=unc) & (unc<0.000001)] = '740000'\n",
    "    unc[(0.00000001<=unc) & (unc<0.0000001)] = '840000'\n",
    "    unc[(unc<0.00000001)] = '940000'\n",
    "    unc = unc.astype(int)\n",
    "    return(unc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_exomol2hitran(read_path, states_df, trans_part_df, ncolumn):\n",
    "    states_unc_df = read_unc_states(states_df)\n",
    "    A, v, Ep, Epp, gp, gpp, unc, gamma_air, gamma_self, n_air, QN_df = linelist_ExoMol2HITRAN(states_unc_df,trans_part_df, ncolumn)\n",
    "    Q = read_exomol_pf(read_path, T)\n",
    "    I = cal_abscoefs(v, gp, A, Epp, Q, abundance)\n",
    "    unc = error_code(unc)\n",
    "    nrows = len(A)\n",
    "    delta_air = ['']*nrows \n",
    "    iref = ['']*nrows \n",
    "    flag = ['']*nrows \n",
    "    '''\n",
    "    hitran_column_name = ['M','I','v','S','A','gamma_air','gamma_self',\n",
    "                          'E\"','n_air','delta_air','Vp','Vpp','Qp','Qpp',\n",
    "                          'Ierr','Iref','flag','gp','gpp']\n",
    "    '''\n",
    "    hitran_begin_dic = {'M':molecule_id, 'I':isotopologue_id, 'v':v, 'S':I, 'A':A, \n",
    "                        'gamma_air':gamma_air,'gamma_self':gamma_self,'E\"':Epp,'n_air':n_air,'delta_air':delta_air}\n",
    "    hitran_begin_df = pd.DataFrame(hitran_begin_dic)\n",
    "    hitran_end_dic = {'Error':unc,'Iref':iref,'*':flag,\"g'\":gp, 'g\"':gpp}\n",
    "    hitran_end_df = pd.DataFrame(hitran_end_dic)\n",
    "\n",
    "    hitran_res_df = pd.concat([hitran_begin_df, QN_df, hitran_end_df], axis='columns')\n",
    "    if ConversionThreshold != 'None':\n",
    "        hitran_res_df = hitran_res_df[hitran_res_df['I'] >= ConversionThreshold]\n",
    "    hitran_res_df = hitran_res_df.sort_values('v')\n",
    "    return(hitran_res_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conversion_exomol2hitran(read_path, states_df, trans_part_df, ncolumn):\n",
    "    \n",
    "    print('Convert data from the ExoMol format to the HITRAN format.')  \n",
    "    t = Timer()\n",
    "    t.start()\n",
    "    \n",
    "    hitran_res_df = convert_exomol2hitran(read_path, states_df, trans_part_df, ncolumn)\n",
    "        \n",
    "    conversion_folder = save_path + '/conversion/'\n",
    "    if os.path.exists(conversion_folder):\n",
    "        pass\n",
    "    else:\n",
    "        os.makedirs(conversion_folder, exist_ok=True)  \n",
    "    conversion_path = conversion_folder + isotopologue + '__' + dataset + '.par'\n",
    "    hitran_format = \"%2s%1s%12.6f%10.3E%10.3E%5.3f%5.3f%10.4f%4.2f%8s%15s%15s%15s%15s%6s%12s%1s%7.1f%7.1f\"\n",
    "    np.savetxt(conversion_path, hitran_res_df, fmt=hitran_format)\n",
    "\n",
    "    t.end()\n",
    "    print('Converted par file has been saved!\\n')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#states_df = read_all_states(read_path)\n",
    "#(trans_part_df, ncolumn) = read_part_trans(read_path)\n",
    "#conversion_exomol2hitran(read_path, states_df, trans_part_df, ncolumn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HITRAN to ExoMol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def globalQNclasses(molecule,isotopologue):\n",
    "    globalQNclass1a = {'class':['CO','HF','HBr','HI','N2','NO+','NO_p','H2','CS'],\n",
    "                       'label': ['none','v1'],\n",
    "                       'format':['%13s','%2d']}\n",
    "    globalQNclass1b = {'class':['O2','NO','OH','ClO','SO'],\n",
    "                       'label':['none','X','Omega','none','v1'],\n",
    "                       'format':['%6s','%2s','%3s','%2s','%2d']}\n",
    "    globalQNclass2a = {'class':['CO2'],\n",
    "                       'label':['none','v1','v2','l2','v3','r'],\n",
    "                       'format':['%6s','%2d','%2d','%2d','%2d','%1d']}\n",
    "    globalQNclass2b = {'class':['N2O','OCS','HCN','CS2'],\n",
    "                       'label':['none','v1','v2','l2','v3'],\n",
    "                       'format':['%7s','%2d','%2d','%2d','%2d']}\n",
    "    globalQNclass3  = {'class':['H2O','O3','SO2','NO2','HOCl','H2S','HO2','HOBr'],\n",
    "                       'label':['none','v1','v2','v3'],\n",
    "                       'format':['%9s','%2d','%2d','%2d']}\n",
    "    globalQNclass4a = {'class':['15N-1H3','PH3','NF3'],\n",
    "                       'label':['none','v1','v2','v3','v4','S'],\n",
    "                       'format':['%5s','%2d','%2d','%2d','%2d','%2s']}\n",
    "    globalQNclass4b = {'class':['14N-1H3'],\n",
    "                       'label':['none','v1','v2','v3','v4','none','l3','l4','none','l','none','Gvib'],\n",
    "                       'format':['%1s','%1d','%1d','%1d','%1d','%1s','%1d','%1d','%1s','%1d','%1s','%4s']}\n",
    "    globalQNclass5a = {'class':['C2H2'],\n",
    "                       'label':['none','v1','v2','v3','v4','v5','l4','l5','+-','none','S'],\n",
    "                       'format':['%1s','%1d','%1d','%1d','%2d','%2d','%2d','%2d','%1s','%1s','%1s']}\n",
    "    globalQNclass5b = {'class':['C4H2'],\n",
    "                       'label':['none','v1','v2','v3','v4','v5','v6','v7','v8','v9','none','Sym','none','S'],\n",
    "                       'format':['%1s','%1d','%1d','%1d','%1d','%1d','%1d','%1d','%1d','%1d','%1s','%1s','%1s','%2s']}\n",
    "    globalQNclass5c = {'class':['HC3N'],\n",
    "                       'label':['none','v1','v2','v3','v4','v5','v6','v7','l5','l6','l7'],\n",
    "                       'format':['%2s','%1d','%1d','%1d','%1d','%1d','%1d','%1d','%2d','%2d','%2d']}\n",
    "    globalQNclass5d = {'class':['C2N2'],\n",
    "                       'label':['v1','v2','v3','v4','v5','l','+-','r','S'],\n",
    "                       'format':['%2d','%2d','%2d','%2d','%2d','%2d','%1s','%1d','%1s']}\n",
    "    globalQNclass6a = {'class':['H2CO','COF2','COCl2'],\n",
    "                       'label':['none','v1','v2','v3','v4','v5','v6'],\n",
    "                       'format':['%3s','%2d','%2d','%2d','%2d','%2d','%2d']}\n",
    "    globalQNclass6b = {'class':['H2O2'],\n",
    "                       'label':['none','v1','v2','v3','n','r','v5','v6'],\n",
    "                       'format':['%3s','%2d','%2d','%2d','%1d','%1d','%2d','%2d']}\n",
    "    globalQNclass7  = {'class':['SO3'],\n",
    "                       'label':['v1','v2','v3','l3','v4','l4','Gvib'],\n",
    "                       'format':['%2d','%2d','%2d','%2d','%2d','%2d','%3s']}\n",
    "    globalQNclass8  = {'class':['12C-1H4','13C-1H4','CF4','GeH4'],\n",
    "                       'label':['none','v1','v2','v3','v4','n','C'],\n",
    "                       'format':['%3s','%2d','%2d','%2d','%2d','%2s','%2s']}\n",
    "    globalQNclass9  = {'class':['12C-1H3-2H','13C-1H3-2H','HNO3','CH3Cl','C2H6','SF6','HCOOH','ClONO2','C2H4','CH3OH','CH3Br','CH3CN','CH3F','CH3I'],\n",
    "                       'label':['vibband'],\n",
    "                       'format':['%15s']}\n",
    "    globalQNclass = [globalQNclass1a,globalQNclass1b,globalQNclass2a,globalQNclass2b,globalQNclass3,\n",
    "                     globalQNclass4a,globalQNclass4b,globalQNclass5a,globalQNclass5b,globalQNclass5c,globalQNclass5d,\n",
    "                     globalQNclass6a,globalQNclass6b,globalQNclass7,globalQNclass8,globalQNclass9]\n",
    "    for gQNclass in globalQNclass:\n",
    "        if molecule in gQNclass.get('class'):\n",
    "            GlobalQNLabels = gQNclass.get('label')\n",
    "            GlobalQNFormats = gQNclass.get('format')   \n",
    "        elif isotopologue in gQNclass.get('class'):\n",
    "            GlobalQNLabels = gQNclass.get('label')\n",
    "            GlobalQNFormats = gQNclass.get('format')             \n",
    "    return(GlobalQNLabels,GlobalQNFormats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def localQNgroups(molecule,isotopologue):\n",
    "    localQNgroup1  = {'group':['H2O','O3','SO2','NO2','HNO3','H2CO','HOCl','H2O2','COF2','H2S','HCOOH','HO2','ClONO2','HOBr','C2H4','COCl2'],\n",
    "                      'ulabel': ['J','Ka','Kc','F','Sym'],\n",
    "                      'uformat':['%3d','%3d','%3d','%5s','%1s'],\n",
    "                      'llabel': ['J','Ka','Kc','F','Sym'],\n",
    "                      'lformat':['%3d','%3d','%3d','%5s','%1s']}\n",
    "    localQNgroup2a = {'group':['CO2','N2O','CO','HF','HCl','HBr','HI','OCS','N2','HCN','NO+','NO_p','HC3N','H2','CS','C2N2','CS2'],\n",
    "                      'ulabel':['m','none','F'],\n",
    "                      'uformat':['%1s','%9s','%5s'],\n",
    "                      'llabel': ['none','Br','J','Sym','F'],\n",
    "                      'lformat':['%5s','%1s','%3d','%1s','%5s']}\n",
    "    localQNgroup2b = {'group':['C4H2'],\n",
    "                      'ulabel':['l6','l7','l8','l9','none'],\n",
    "                      'uformat':['%2s','%2s','%2s','%2s','%7s'],\n",
    "                      'llabel': ['l6','l7','l8','l9','none','Br','J','Sym','none'],\n",
    "                      'lformat':['%2s','%2s','%2s','%2s','%1s','%1s','%3d','%1s','%1s']}\n",
    "    localQNgroup3  = {'group':['12C-1H4','13C-1H4','SF6','CF4','GeH4'],\n",
    "                      'ulabel':['none','J','C','alpha','F'],\n",
    "                      'uformat':['%2s','%3d','%2s','%3d','%5s'],\n",
    "                      'llabel': ['none','J','C','alpha','F'],\n",
    "                      'lformat':['%2s','%3d','%2s','%3d','%5s']}\n",
    "    localQNgroup4a = {'group':['12C-1H3-2H','13C-1H3-2H','15N-1H3','CH3Cl','PH3','CH3OH','CH3Br','CH3CN','CH3F','CH3I','NF3'],\n",
    "                      'ulabel':['J','K','l','C','Sym','F'],\n",
    "                      'uformat':['%3d','%3d','%2d','%2s','%1s','%4s'],\n",
    "                      'llabel': ['J','K','l','C','Sym','F'],\n",
    "                      'lformat':['%3d','%3d','%2d','%2s','%1s','%4s']}\n",
    "    localQNgroup4b = {'group':['14N-1H3'],\n",
    "                      'ulabel':['J','K','l','none','Grot','Gtot','none'],\n",
    "                      'uformat':['%2d','%3d','%2d','%1s','%3s','%3s','%1s'],\n",
    "                      'llabel': ['J','K','l','none','Grot','Gtot','none'],\n",
    "                      'lformat':['%2d','%3d','%2d','%1s','%3s','%3s','%1s']}\n",
    "    localQNgroup4c = {'group':['C2H6'],\n",
    "                      'ulabel':['J','K','l','Sym','F'],\n",
    "                      'uformat':['%3d','%3d','%2d','%3s','%4s'],\n",
    "                      'llabel': ['J','K','l','Sym','F'],\n",
    "                      'lformat':['%3d','%3d','%2d','%3s','%4s']}\n",
    "    localQNgroup5  = {'group':['SO3'],\n",
    "                      'ulabel':['none','J','K','none','Gtot','none'],\n",
    "                      'uformat':['%3s','%3d','%3d','%2s','%3s','%1s'],\n",
    "                      'llabel': ['none','J','K','none','Grot','none'],\n",
    "                      'lformat':['%3s','%3d','%3d','%2s','%3s','%1s']}\n",
    "    localQNgroup6  = {'group':['O2','SO'],\n",
    "                      'ulabel':['none','F'],\n",
    "                      'uformat':['%10s','%5s'],\n",
    "                      'llabel': ['none','Br','N','Br','J','F','M'],\n",
    "                      'lformat':['%1s','%1s','%3d','%1s','%3d','%5s','%1s']}\n",
    "    localQNgroup7a = {'group':['NO','ClO'],\n",
    "                      'ulabel':['m','none','F'],\n",
    "                      'uformat':['%1s','%9s','%5s'],\n",
    "                      'llabel': ['none','Br','J','Sym','F'],\n",
    "                      'lformat':['%2s','%2s','%5.1f','%1s','%5s']}\n",
    "    localQNgroup7b = {'group':['OH'],\n",
    "                      'ulabel':['none','F'],\n",
    "                      'uformat':['%10s','%5s'],\n",
    "                      'llabel': ['none','Br','J','Sym','F'],\n",
    "                      'lformat':['%1s','%2s','%5.1f','%2s','%5s']}\n",
    "    localQNgroup = [localQNgroup1,localQNgroup2a,localQNgroup2b,localQNgroup3,\n",
    "                    localQNgroup4a,localQNgroup4b,localQNgroup4c,\n",
    "                    localQNgroup5,localQNgroup6,localQNgroup7a,localQNgroup7b]\n",
    "    for lQNgroup in localQNgroup:\n",
    "        if molecule in lQNgroup.get('group'):\n",
    "            LocalQNupperLabels = lQNgroup.get('ulabel')\n",
    "            LocalQNupperFormats = lQNgroup.get('uformat')\n",
    "            LocalQNlowerLabels = lQNgroup.get('llabel')\n",
    "            LocalQNlowerFormats = lQNgroup.get('lformat')\n",
    "        elif isotopologue in lQNgroup.get('group'):\n",
    "            LocalQNupperLabels = lQNgroup.get('ulabel')\n",
    "            LocalQNupperFormats = lQNgroup.get('uformat')\n",
    "            LocalQNlowerLabels = lQNgroup.get('llabel')\n",
    "            LocalQNlowerFormats = lQNgroup.get('lformat')\n",
    "    return(LocalQNupperLabels, LocalQNlowerLabels, LocalQNupperFormats, LocalQNlowerFormats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_code2unc(unc_code):    \n",
    "    unc_code[(unc_code=='0')] = 10\n",
    "    unc_code[(unc_code=='1')] = 1\n",
    "    unc_code[(unc_code=='2')] = 0.1\n",
    "    unc_code[(unc_code=='3')] = 0.01\n",
    "    unc_code[(unc_code=='4')] = 0.001\n",
    "    unc_code[(unc_code=='5')] = 0.0001\n",
    "    unc_code[(unc_code=='6')] = 0.00001\n",
    "    unc_code[(unc_code=='7')] = 0.000001\n",
    "    unc_code[(unc_code=='8')] = 0.0000001\n",
    "    unc_code[(unc_code=='9')] = 0.00000001\n",
    "    unc_states_df = pd.DataFrame()\n",
    "    unc_states_df['Unc'] = pd.DataFrame(unc_code)\n",
    "    return(unc_states_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_QNValues_hitran2exomol(hitran2exomol_states_df, GlobalQNLabel_list, LocalQNLabel_list):\n",
    "    QNLabel_list = GlobalQNLabel_list+LocalQNLabel_list\n",
    "    if 'Gtot' in QNLabel_list:\n",
    "        hitran2exomol_states_df[\"Gtot\"] = (hitran2exomol_states_df[\"Gtot\"]\n",
    "                                           .str.replace('A1',\"1'\").str.replace('A2',\"2'\").str.replace(\"E'\",'3')\n",
    "                                           .str.replace('A1\"','4').str.replace('A2\"','5').str.replace('E\"','6'))    \n",
    "    if 'Gvib' in QNLabel_list:\n",
    "        hitran2exomol_states_df[\"Gvib\"] = (hitran2exomol_states_df[\"Gvib\"]\n",
    "                                           .str.replace('A1',\"1'\").str.replace('A2',\"2'\").str.replace(\"E'\",'3')\n",
    "                                           .str.replace('A1\"','4').str.replace('A2\"','5').str.replace('E\"','6'))    \n",
    "    if 'Grot' in QNLabel_list:\n",
    "        hitran2exomol_states_df[\"Grot\"] = (hitran2exomol_states_df[\"Grot\"]\n",
    "                                           .str.replace('A1',\"1'\").str.replace('A2',\"2'\").str.replace(\"E'\",'3')\n",
    "                                           .str.replace('A1\"','4').str.replace('A2\"','5').str.replace('E\"','6'))                  \n",
    "    if 'taui' in QNLabel_list:\n",
    "        hitran2exomol_states_df[\"taui\"] = hitran2exomol_states_df[\"taui\"].str.replace('s','0').str.replace('a','1')\n",
    "    return(hitran2exomol_states_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_Jp(Fp, Fpp, Jpp):\n",
    "    Jp = ne.evaluate('Fp + Fpp - Jpp')\n",
    "    return(Jp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_E_hitran2exomol(hitran_df):\n",
    "    Epp = hitran_df['Epp'].values\n",
    "    v = hitran_df['v'].values\n",
    "    Ep = cal_Ep(Epp, v)\n",
    "    Ep_df = pd.DataFrame(Ep,columns=['Ep'])\n",
    "    return(Ep_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_J_hitran2exomol(LQNu_df, LQNl_df, LocalQNupperLabels):\n",
    "    Jpp = pd.to_numeric(LQNl_df['J'].values, errors='coerce')\n",
    "    Jpp_df = pd.DataFrame(Jpp,columns=['Jpp'])\n",
    "    if 'J' not in LocalQNupperLabels:\n",
    "        if 'F' in LocalQNupperLabels:\n",
    "            Fp = pd.to_numeric(LQNu_df['F'].values, errors='coerce')\n",
    "            Fpp = pd.to_numeric(LQNl_df['F'].values, errors='coerce')\n",
    "            Jp = cal_Jp(Fp, Fpp, Jpp)\n",
    "        else:\n",
    "            Jp = [' ']*len(Jpp)\n",
    "        LocalQNupperLabels = LocalQNupperLabels + ['J']    \n",
    "        LQNu_df['J'] = Jp\n",
    "    return(LocalQNupperLabels, LQNu_df, Jpp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_QN_hitran2exomol(hitran_df,GlobalQNLabels,LocalQNupperLabels,LocalQNlowerLabels,\n",
    "                             GlobalQNFormats,LocalQNupperFormats,LocalQNlowerFormats):\n",
    "    GQN_format = list(map(int, list(map(float, (str(GlobalQNFormats).replace(\"'%\",\"\").replace(\"[\",\"\")\n",
    "                                                .replace(\"']\",\"\").replace(\"',\",\"\").replace('s','').replace('d','')\n",
    "                                                .replace('f','').replace('e','').split(' '))))))\n",
    "    LQNu_format = list(map(int, list(map(float, (str(LocalQNupperFormats).replace(\"'%\",\"\").replace(\"[\",\"\")\n",
    "                                                .replace(\"']\",\"\").replace(\"',\",\"\").replace('s','').replace('d','')\n",
    "                                                .replace('f','').replace('e','').split(' '))))))\n",
    "    LQNl_format = list(map(int, list(map(float, (str(LocalQNlowerFormats).replace(\"'%\",\"\").replace(\"[\",\"\")\n",
    "                                                .replace(\"']\",\"\").replace(\"',\",\"\").replace('s','').replace('d','')\n",
    "                                                .replace('f','').replace('e','').split(' ')))))) \n",
    "\n",
    "    # Global quantum numbers    \n",
    "    GQNu_df = pd.DataFrame()  \n",
    "    GQNl_df = pd.DataFrame()  \n",
    "    n_GQN = len(GlobalQNLabels)\n",
    "    reverse_GQNLabel = list(reversed(GlobalQNLabels)) \n",
    "    reverse_GQNFormat = list(reversed(GQN_format)) \n",
    "    j = 15\n",
    "    for i in range(n_GQN):\n",
    "        GQNu_df[reverse_GQNLabel[i]] = hitran_df['Vp'].map(lambda x: x[j-reverse_GQNFormat[i]:j]) \n",
    "        GQNl_df[reverse_GQNLabel[i]] = hitran_df['Vpp'].map(lambda x: x[j-reverse_GQNFormat[i]:j]) \n",
    "        j -= reverse_GQNFormat[i]\n",
    "    if 'none' in GlobalQNLabels:\n",
    "        GQNu_df = GQNu_df[reverse_GQNLabel].drop(columns=['none'])\n",
    "        GQNl_df = GQNl_df[reverse_GQNLabel].drop(columns=['none']) \n",
    "\n",
    "    # Local quantum numbers\n",
    "    LQNu_df = pd.DataFrame()  \n",
    "    n_LQNu = len(LocalQNupperLabels)\n",
    "    reverse_LQNupperLabel = list(reversed(LocalQNupperLabels)) \n",
    "    reverse_LQNupperFormat = list(reversed(LQNu_format)) \n",
    "    j = 15\n",
    "    for i in range(n_LQNu):\n",
    "        LQNu_df[reverse_LQNupperLabel[i]] = hitran_df['Qp'].map(lambda x: x[j-reverse_LQNupperFormat[i]:j]) \n",
    "        j -= reverse_LQNupperFormat[i]\n",
    "    if 'none' in LocalQNupperLabels:\n",
    "        LQNu_df = LQNu_df[reverse_LQNupperLabel].drop(columns=['none'])\n",
    "\n",
    "    LQNl_df = pd.DataFrame()  \n",
    "    n_LQNl = len(LocalQNlowerLabels)\n",
    "    reverse_LQNlowerLabel = list(reversed(LocalQNlowerLabels)) \n",
    "    reverse_LQNlowerFormat = list(reversed(LQNl_format)) \n",
    "    j = 15\n",
    "    hitran_df['Qpp'] = hitran_df['Qpp'].str.replace(' .5', '0.5', regex=True)\n",
    "    for i in range(n_LQNl):\n",
    "        LQNl_df[reverse_LQNlowerLabel[i]] = hitran_df['Qpp'].map(lambda x: x[j-reverse_LQNlowerFormat[i]:j]) \n",
    "        j -= reverse_LQNlowerFormat[i]\n",
    "    if 'none' in LocalQNlowerLabels:\n",
    "        LQNl_df = LQNl_df[reverse_LQNlowerLabel].drop(columns=['none'])\n",
    "\n",
    "    LocalQNupperLabels, LQNu_df, Jpp_df = convert_J_hitran2exomol(LQNu_df, LQNl_df, LocalQNupperLabels)\n",
    "\n",
    "    while 'none' in GlobalQNLabels: GlobalQNLabels.remove('none')\n",
    "    while 'none' in LocalQNupperLabels: LocalQNupperLabels.remove('none')\n",
    "    while 'none' in LocalQNlowerLabels: LocalQNlowerLabels.remove('none')\n",
    "    GQNu_df = GQNu_df[GlobalQNLabels]\n",
    "    GQNl_df = GQNl_df[GlobalQNLabels]\n",
    "    LQNu_df = LQNu_df[LocalQNupperLabels]\n",
    "    LQNl_df = LQNl_df[LocalQNlowerLabels]\n",
    "    QNu_label = GlobalQNLabels + LocalQNupperLabels\n",
    "    QNl_label = GlobalQNLabels + LocalQNlowerLabels\n",
    "    hitranQNlabel = QNu_label + QNl_label\n",
    "    hitranQNlabels = sorted(set(hitranQNlabel),key=hitranQNlabel.index)\n",
    "    return(hitranQNlabels, Jpp_df, GQNu_df, GQNl_df, LQNu_df, LQNl_df, QNu_label, QNl_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_hitran2StatesTrans(hitran_df, hitranQNlabels, QNu_label, QNl_label, GQNu_df, GQNl_df, LQNu_df, LQNl_df):\n",
    "    Ep_df = convert_E_hitran2exomol(hitran_df)\n",
    "    hitran2exomol_upper_df = pd.concat([hitran_df[['A','gp','Unc']],Ep_df,GQNu_df,LQNu_df], axis=1, join='inner')\n",
    "    hitran2exomol_lower_df = pd.concat([hitran_df[['A','gpp','Unc','Epp']],GQNl_df,LQNl_df], axis=1, join='inner')\n",
    "    hitran2exomol_upper_df.columns = ['A','g','Unc','E'] + QNu_label\n",
    "    hitran2exomol_lower_df.columns = ['A','g','Unc','E'] + QNl_label\n",
    "    hitran2exomol_st_df = pd.concat([hitran2exomol_upper_df, hitran2exomol_lower_df], axis=0)\n",
    "    unc_code = hitran2exomol_st_df['Unc'].values\n",
    "    unc_states_df = error_code2unc(unc_code)\n",
    "    hitran2exomol_st_df = hitran2exomol_st_df.fillna('')\n",
    "    hitran2exomol_st_E = hitran2exomol_st_df.groupby(['g','Unc'] + hitranQNlabels)['E'].mean().reset_index()\n",
    "    hitran2exomol_st_Unc = hitran2exomol_st_E.groupby(['g'] + hitranQNlabels)['Unc'].min().reset_index()\n",
    "    hitran2exomol_st_df = (hitran2exomol_st_Unc.merge(hitran2exomol_st_E, on=['g','Unc']+hitranQNlabels, how='inner')\n",
    "                           .sort_values('E').reset_index().drop(columns='index'))\n",
    "        \n",
    "    # States\n",
    "    id_states_df = pd.DataFrame(hitran2exomol_st_df.index+1, columns=['id'])\n",
    "    hitran2exomol_stQN_df = pd.concat([id_states_df,hitran2exomol_st_df], axis=1)\n",
    "    hitran2exomol_states_df = convert_QNValues_hitran2exomol(hitran2exomol_stQN_df, GlobalQNLabel_list, LocalQNLabel_list)\n",
    "    hitranQNlabels.remove('J')\n",
    "    #states_columns_order = ['id','E','g','J','Unc']+hitranQNlabels\n",
    "    states_columns_order = ['id','E','g','J','Unc']+QNslabel_list\n",
    "    hitran2exomol_states_df = hitran2exomol_states_df[states_columns_order]\n",
    "\n",
    "\n",
    "    # Transitions\n",
    "    hitran2exomol_upperAE_df = (hitran2exomol_upper_df.fillna('').merge(hitran2exomol_states_df, on=['g']+QNu_label, how='inner')\n",
    "                                .drop(columns=['g','J','Unc_x','Unc_y','E_x']+hitranQNlabels).sort_values('A').reset_index()\n",
    "                                .rename(columns={'id':'uid','E_y':\"E'\"}))\n",
    "    hitran2exomol_lowerAE_df = (hitran2exomol_lower_df.fillna('').merge(hitran2exomol_states_df, on=['g']+QNl_label, how='inner')\n",
    "                                .drop(columns=['g','J','Unc_x','Unc_y','E_x']+hitranQNlabels).sort_values('A').reset_index()\n",
    "                                .rename(columns={'A':'A2','id':'lid','E_y':'E\"'}))\n",
    "    hitran2exomol_AE = pd.concat([hitran2exomol_upperAE_df, hitran2exomol_lowerAE_df],axis=1).drop(columns=['index','A2'])\n",
    "    Ep = hitran2exomol_AE[\"E'\"].to_numpy()\n",
    "    Epp = hitran2exomol_AE['E\"'].to_numpy()\n",
    "    hitran2exomol_AE['v'] = cal_v(Ep, Epp)\n",
    "    hitran2exomol_trans_df = hitran2exomol_AE[['uid','lid','A','v']].sort_values('v')\n",
    "    return(hitran2exomol_states_df, hitran2exomol_trans_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_hitran2broad(hitran_df, Jpp_df):\n",
    "    broad_code_df = pd.DataFrame(np.full_like(Jpp_df.astype(str),'a0'), columns=['code'])\n",
    "    hitran2exomol_air_df = pd.concat([broad_code_df, hitran_df[['gamma_air','n_air']], Jpp_df], axis=1).drop_duplicates()\n",
    "    hitran2exomol_self_df = pd.concat([broad_code_df, hitran_df[['gamma_self','n_air']], Jpp_df], axis=1).drop_duplicates()\n",
    "    return(hitran2exomol_air_df, hitran2exomol_self_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conversion_states(hitran2exomol_states_df):\n",
    "\n",
    "    print('Convert data from the HITRAN format to the ExoMol format states.')  \n",
    "    t = Timer()\n",
    "    t.start()\n",
    "    \n",
    "    conversion_folder = save_path + '/conversion/'\n",
    "    if os.path.exists(conversion_folder):\n",
    "        pass\n",
    "    else:\n",
    "        os.makedirs(conversion_folder, exist_ok=True)  \n",
    "    conversion_states_path = conversion_folder + isotopologue + '__' + dataset + '.states'\n",
    "    #states_format = (\"%12s %12.6f %6s %7s %12.6f \" \n",
    "    #                + str(GlobalQNFormat_list).replace(\"['\",\"\").replace(\"']\",\"\").replace(\"'\",\"\").replace(\",\",\"\").replace(\"d\",\"s\") + \" \"\n",
    "    #                + str(LocalQNFormat_list[1:]).replace(\"['\",\"\").replace(\"']\",\"\").replace(\"'\",\"\").replace(\",\",\"\").replace(\"d\",\"s\"))\n",
    "    states_format = (\"%12s %12.6f %6s %7s %12.6f \" \n",
    "                     + str(QNsformat_list).replace(\"['\",\"\").replace(\"']\",\"\")\n",
    "                     .replace(\"'\",\"\").replace(\",\",\"\").replace(\"d\",\"s\"))\n",
    "    np.savetxt(conversion_states_path, hitran2exomol_states_df, fmt=states_format)\n",
    "\n",
    "    t.end()\n",
    "    print('Converted states file has been saved!\\n')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conversion_trans(hitran2exomol_trans_df): \n",
    "    print('Convert data from the HITRAN format to the ExoMol format transitions.')  \n",
    "    t = Timer()\n",
    "    t.start()\n",
    "  \n",
    "    conversion_folder = save_path + '/conversion/'\n",
    "    if os.path.exists(conversion_folder):\n",
    "        pass\n",
    "    else:\n",
    "        os.makedirs(conversion_folder, exist_ok=True)  \n",
    "    conversion_trans_path = conversion_folder + isotopologue + '__' + dataset + '.trans'\n",
    "    trans_format = \"%12d %12d %10.4e %15.6f\"\n",
    "    np.savetxt(conversion_trans_path, hitran2exomol_trans_df, fmt=trans_format)\n",
    "\n",
    "    t.end()\n",
    "    print('Converted transition file has been saved!\\n')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conversion_broad(hitran2exomol_air_df, hitran2exomol_self_df):\n",
    "    print('Convert data from the HITRAN format to the ExoMol format broadening.')  \n",
    "    t = Timer()\n",
    "    t.start()\n",
    "\n",
    "    conversion_folder = save_path + '/conversion/'\n",
    "    if os.path.exists(conversion_folder):\n",
    "        pass\n",
    "    else:\n",
    "        os.makedirs(conversion_folder, exist_ok=True)  \n",
    "    conversion_airbroad_path = conversion_folder + isotopologue + '__air.broad'\n",
    "    conversion_selfbroad_path = conversion_folder + isotopologue + '__self.broad'\n",
    "    broad_format = \"%2s %6.4f %6.3f %7s\"\n",
    "    np.savetxt(conversion_airbroad_path, hitran2exomol_air_df, fmt=broad_format)\n",
    "    np.savetxt(conversion_selfbroad_path, hitran2exomol_self_df, fmt=broad_format)\n",
    "\n",
    "    t.end()\n",
    "    print('Converted broadening files have been saved!\\n')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conversion_hitran2exomol(hitran_df):\n",
    "    GlobalQNLabels,GlobalQNFormats = globalQNclasses(molecule,isotopologue)\n",
    "    LocalQNupperLabels, LocalQNlowerLabels, LocalQNupperFormats, LocalQNlowerFormats = localQNgroups(molecule,isotopologue)\n",
    "    (hitranQNlabels, Jpp_df, GQNu_df, GQNl_df, \n",
    "     LQNu_df, LQNl_df, QNu_label, QNl_label) = convert_QN_hitran2exomol(hitran_df,GlobalQNLabels,LocalQNupperLabels,\n",
    "                                                                        LocalQNlowerLabels,GlobalQNFormats,\n",
    "                                                                        LocalQNupperFormats,LocalQNlowerFormats)\n",
    "    hitran2exomol_states_df, hitran2exomol_trans_df = convert_hitran2StatesTrans(hitran_df, hitranQNlabels, QNu_label, QNl_label, \n",
    "                                                                                 GQNu_df, GQNl_df, LQNu_df, LQNl_df)\n",
    "    hitran2exomol_air_df, hitran2exomol_self_df = convert_hitran2broad(hitran_df, Jpp_df)\n",
    "    conversion_states(hitran2exomol_states_df)\n",
    "    conversion_trans(hitran2exomol_trans_df)\n",
    "    conversion_broad(hitran2exomol_air_df, hitran2exomol_self_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parfile_df = read_parfile(read_path)\n",
    "#hitran_df = read_hitran_parfile (read_path, parfile_df).reset_index().drop(columns='index')\n",
    "#conversion_hitran2exomol(hitran_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stick Spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linelist_StickSpectra(states_part_df,trans_part_df, ncolumn):\n",
    "    if ncolumn == 4:\n",
    "        trans_part_df = trans_part_df[trans_part_df['v'].between(min_wn, max_wn)] \n",
    "        id_u = trans_part_df['u'].values\n",
    "        id_s = states_part_df['id'].values\n",
    "        trans_part_df.set_index(['u'], inplace=True, drop=False)\n",
    "        id_us = list(set(id_u).intersection(set(id_s)))\n",
    "        trans_us_df = trans_part_df.loc[id_us]\n",
    "        id_l = trans_us_df['l'].values\n",
    "        id_ls = list(set(id_l).intersection(set(id_s)))\n",
    "        if id_ls != []:\n",
    "            trans_us_df.set_index(['l'], inplace=True, drop=False)\n",
    "            trans_s_df = trans_us_df.loc[id_ls]\n",
    "            trans_s_df.sort_values(by=['v'], inplace=True)\n",
    "            id_su = trans_s_df['u'].values\n",
    "            id_sl = trans_s_df['l'].values\n",
    "            states_u_df = states_part_df.loc[id_su]\n",
    "            states_l_df = states_part_df.loc[id_sl]\n",
    "            Ep = states_u_df['E'].values.astype('float')\n",
    "            Epp = states_l_df['E'].values.astype('float')\n",
    "            gp = states_u_df['g'].values.astype('int')\n",
    "            Jp = pd.to_numeric(states_u_df['J']).values\n",
    "            Jpp = pd.to_numeric(states_l_df['J']).values\n",
    "            A = trans_s_df['A'].values.astype('float')\n",
    "            v = trans_s_df['v'].values.astype('float')\n",
    "            QNp = pd.DataFrame()\n",
    "            QNpp = pd.DataFrame()\n",
    "            for i in range(len(QNs_label)):\n",
    "                QNp[QNs_label[i]+\"'\"] = states_u_df[QNs_label[i]].values\n",
    "                QNpp[QNs_label[i]+'\"'] = states_l_df[QNs_label[i]].values\n",
    "            stick_qn_df = pd.concat([QNp,QNpp],axis='columns')\n",
    "        else:\n",
    "            raise ImportError(\"Empty result with the input filter values. Please type new filter values in the input file.\")  \n",
    "    else:\n",
    "        id_u = trans_part_df['u'].values\n",
    "        id_s = states_part_df['id'].values\n",
    "        trans_part_df.set_index(['u'], inplace=True, drop=False)\n",
    "        id_us = list(set(id_u).intersection(set(id_s)))\n",
    "        trans_us_df = trans_part_df.loc[id_us]\n",
    "        id_l = trans_us_df['l'].values\n",
    "        id_ls = list(set(id_l).intersection(set(id_s)))\n",
    "        trans_us_df.set_index(['l'], inplace=True, drop=False)\n",
    "        trans_s_df = trans_us_df.loc[id_ls]\n",
    "        id_su = trans_s_df['u'].values\n",
    "        id_sl = trans_s_df['l'].values\n",
    "        states_u_df = states_part_df.loc[id_su]\n",
    "        states_l_df = states_part_df.loc[id_sl]\n",
    "        trans_s_df['Ep'] = states_u_df['E'].values.astype('float')\n",
    "        trans_s_df['Epp'] = states_l_df['E'].values.astype('float')\n",
    "        trans_s_df['gp'] = states_u_df['g'].values.astype('int')\n",
    "        trans_s_df['Jp'] = pd.to_numeric(states_u_df['J']).values\n",
    "        trans_s_df['Jpp'] = pd.to_numeric(states_l_df['J']).values\n",
    "        trans_s_df['A'] = trans_s_df['A'].values.astype('float')\n",
    "        trans_s_df['v'] = cal_v(trans_s_df['Ep'].values, trans_s_df['Epp'].values)\n",
    "        trans_s_df = trans_s_df[trans_s_df['v'].between(min_wn, max_wn)]\n",
    "        if len(trans_s_df) != 0:\n",
    "            trans_s_df.sort_values(by=['v'], inplace=True) \n",
    "            Ep = trans_s_df['Ep'].values\n",
    "            Epp = trans_s_df['Epp'].values\n",
    "            gp = trans_s_df['gp'].values\n",
    "            Jp = trans_s_df['Jp'].values\n",
    "            Jpp = trans_s_df['Jpp'].values\n",
    "            A = trans_s_df['A'].values\n",
    "            v = trans_s_df['v'].values\n",
    "            id_su = trans_s_df['u'].values\n",
    "            states_u_df = states_part_df.loc[id_su]        \n",
    "            id_sl = trans_s_df['l'].values\n",
    "            states_l_df = states_part_df.loc[id_sl]\n",
    "            QNp = pd.DataFrame()\n",
    "            QNpp = pd.DataFrame()\n",
    "            for i in range(len(QNs_label)):\n",
    "                QNp[QNs_label[i]+\"'\"] = states_u_df[QNs_label[i]].values\n",
    "                QNpp[QNs_label[i]+'\"'] = states_l_df[QNs_label[i]].values\n",
    "            stick_qn_df = pd.concat([QNp,QNpp],axis='columns')\n",
    "        else:\n",
    "            raise ImportError(\"Empty result with the input filter values. Please type new filter values in the input file.\")  \n",
    "    return (A, v, Ep, Epp, gp, Jp, Jpp, stick_qn_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stick spectra\n",
    "def exomol_stick_spectra(read_path, states_part_df, trans_part_df, ncolumn, T):\n",
    "    print('Calculate stick spectra.')  \n",
    "    t = Timer()\n",
    "    t.start()\n",
    "    A, v, Ep, Epp, gp, Jp, Jpp, stick_qn_df = linelist_StickSpectra(states_part_df,trans_part_df, ncolumn)\n",
    "    Q = read_exomol_pf(read_path, T)\n",
    "    I = cal_abscoefs(v, gp, A, Epp, Q, abundance)\n",
    "    stick_st_dic = {'v':v, 'I':I, \"J'\":Jp, \"E'\":Ep, 'J\"':Jpp, 'E\"':Epp}\n",
    "    stick_st_df = pd.DataFrame(stick_st_dic)\n",
    "    stick_spectra_df = pd.concat([stick_st_df, stick_qn_df], axis='columns')\n",
    "    if threshold != 'None':\n",
    "        stick_spectra_df = stick_spectra_df[stick_spectra_df['I'] >= threshold]\n",
    "    stick_spectra_df = stick_spectra_df.sort_values('v')  \n",
    "    QNsfmf = (str(QNs_format).replace(\"'\",\"\").replace(\",\",\"\").replace(\"[\",\"\").replace(\"]\",\"\")\n",
    "              .replace('d','s').replace('i','s').replace('.1f','s'))\n",
    "    ss_folder = save_path + '/stick_spectra/stick/'\n",
    "    if os.path.exists(ss_folder):\n",
    "        pass\n",
    "    else:\n",
    "        os.makedirs(ss_folder, exist_ok=True)\n",
    "    ss_path = ss_folder + isotopologue + '__' + dataset + '.stick'\n",
    "    ss_colname = stick_spectra_df.columns\n",
    "    fmt = '%12.8E %12.8E %7s %12.4f %7s %12.4f '+QNsfmf+' '+QNsfmf\n",
    "    np.savetxt(ss_path, stick_spectra_df, fmt=fmt, header='')\n",
    "    \n",
    "    # Plot cross sections and save it as .png.\n",
    "    if PlotStickSpectraYN == 'Y':\n",
    "        from matplotlib.ticker import MultipleLocator, FormatStrFormatter\n",
    "        parameters = {'axes.labelsize': 14, \n",
    "                    'legend.fontsize': 14,\n",
    "                    'xtick.labelsize': 12,\n",
    "                    'ytick.labelsize': 12}\n",
    "        plt.rcParams.update(parameters)\n",
    "        ss_plot_folder = save_path + '/stick_spectra/plots/'\n",
    "        if os.path.exists(ss_plot_folder):\n",
    "            pass\n",
    "        else:\n",
    "            os.makedirs(ss_plot_folder, exist_ok=True)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.ylim([1e-30, 10*max(I)])\n",
    "        plt.plot(v, I, label='T = '+str(T)+' K', linewidth=0.4)\n",
    "        plt.semilogy()\n",
    "        #plt.title(database+' '+molecule+' intensity') \n",
    "        plt.xlabel('Wavenumber, cm$^{-1}$')\n",
    "        plt.ylabel('Intensity, cm/molecule')\n",
    "        plt.legend()\n",
    "        leg = plt.legend()                  # Get the legend object.\n",
    "        for line in leg.get_lines():\n",
    "            line.set_linewidth(1.0)         # Change the line width for the legend.\n",
    "        plt.savefig(ss_plot_folder+molecule+'__T'+str(T)+'__'+str(min_wn)\n",
    "                    +'-'+str(max_wn)+'__'+database+'.png', dpi=500)\n",
    "        plt.show()\n",
    "        print('Stick spectra plot saved.')\n",
    "    t.end()\n",
    "    print('Stick spectra has been saved!\\n')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66ae4e0a7bf34cb69e3f65cc9b896e43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate stick spectra.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stick spectra plot saved.\n",
      "Running time on CPU       : 1.3740567719999999 s\n",
      "Running time on system    : 1.4708049297332764 s\n",
      "Stick spectra has been saved!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#T = 300\n",
    "#states_df = read_all_states(read_path)\n",
    "#states_part_df = read_part_states(states_df)\n",
    "#(trans_part_df, ncolumn) = read_part_trans(read_path)\n",
    "#exomol_stick_spectra(read_path, states_part_df, trans_part_df, ncolumn, T)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linelist_exomol_abs(cutoff,broad,ratio,nbroad,broad_dfs,states_part_df,trans_part_df, ncolumn): \n",
    "    if ncolumn == 4:\n",
    "        if cutoff == 'None':\n",
    "            trans_part_df = trans_part_df[trans_part_df['v'].between(min_wn, max_wn)] \n",
    "        else:\n",
    "            trans_part_df = trans_part_df[trans_part_df['v'].between(min_wn - cutoff, max_wn + cutoff)] \n",
    "        id_u = trans_part_df['u'].values\n",
    "        id_s = states_part_df['id'].values\n",
    "        trans_part_df.set_index(['u'], inplace=True, drop=False)\n",
    "        id_us = list(set(id_u).intersection(set(id_s)))\n",
    "        trans_us_df = trans_part_df.loc[id_us]\n",
    "        id_l = trans_us_df['l'].values\n",
    "        id_ls = list(set(id_l).intersection(set(id_s)))\n",
    "        if id_ls != []:\n",
    "            trans_us_df.set_index(['l'], inplace=True, drop=False)\n",
    "            trans_s_df = trans_us_df.loc[id_ls]\n",
    "            trans_s_df.sort_values(by=['v'], inplace=True)\n",
    "            id_su = trans_s_df['u'].values\n",
    "            id_sl = trans_s_df['l'].values\n",
    "            states_u_df = states_part_df.loc[id_su]\n",
    "            states_l_df = states_part_df.loc[id_sl]\n",
    "            Epp = states_l_df['E'].values.astype('float')\n",
    "            gp = states_u_df['g'].values.astype('int')\n",
    "            A = trans_s_df['A'].values.astype('float')\n",
    "            v = trans_s_df['v'].values.astype('float')\n",
    "        else:\n",
    "            raise ImportError(\"Empty result with the input filter values. Please type new filter values in the input file.\")  \n",
    "    else:\n",
    "        id_u = trans_part_df['u'].values\n",
    "        id_s = states_part_df['id'].values\n",
    "        trans_part_df.set_index(['u'], inplace=True, drop=False)\n",
    "        id_us = list(set(id_u).intersection(set(id_s)))\n",
    "        trans_us_df = trans_part_df.loc[id_us]\n",
    "        id_l = trans_us_df['l'].values\n",
    "        id_ls = list(set(id_l).intersection(set(id_s)))\n",
    "        trans_us_df.set_index(['l'], inplace=True, drop=False)\n",
    "        trans_s_df = trans_us_df.loc[id_ls]\n",
    "        id_su = trans_s_df['u'].values\n",
    "        id_sl = trans_s_df['l'].values\n",
    "        states_u_df = states_part_df.loc[id_su]\n",
    "        states_l_df = states_part_df.loc[id_sl]\n",
    "        trans_s_df['Ep'] = states_u_df['E'].values.astype('float')\n",
    "        trans_s_df['Epp'] = states_l_df['E'].values.astype('float')\n",
    "        trans_s_df['gp'] = states_u_df['g'].values.astype('int')\n",
    "        trans_s_df['v'] = cal_v(trans_s_df['Ep'].values, trans_s_df['Epp'].values)\n",
    "        if cutoff == 'None':\n",
    "            trans_s_df = trans_s_df[trans_s_df['v'].between(min_wn, max_wn)]\n",
    "        else:\n",
    "            trans_s_df = trans_s_df[trans_s_df['v'].between(min_wn - cutoff, max_wn + cutoff)]\n",
    "        if len(trans_s_df) != 0:\n",
    "            trans_s_df.sort_values(by=['v'], inplace=True)\n",
    "            Epp = trans_s_df['Epp'].values\n",
    "            gp = trans_s_df['gp'].values\n",
    "            A = trans_s_df['A'].values\n",
    "            v = trans_s_df['v'].values\n",
    "            id_sl = trans_s_df['l'].values\n",
    "            states_l_df = states_part_df.loc[id_sl]\n",
    "        else:\n",
    "            raise ImportError(\"Empty result with the input filter values. Please type new filter values in the input file.\")  \n",
    "    gamma_L = pd.DataFrame()\n",
    "    n_air = pd.DataFrame()\n",
    "    rows = len(id_sl)\n",
    "    for i in range(nbroad):\n",
    "        if broad[i] == 'Default':\n",
    "            gamma_L[i] = np.full((1,rows),broad_dfs[i]['gamma_L'][0])[0] * ratio[i]\n",
    "            n_air[i] = np.full((1,rows),broad_dfs[i]['n_air'][0])[0] * ratio[i]\n",
    "        else:\n",
    "            gamma_L[i] = extract_broad(broad_dfs[i],states_l_df)[0] * ratio[i]\n",
    "            n_air[i] = extract_broad(broad_dfs[i],states_l_df)[1] * ratio[i]\n",
    "    return (A, v, Epp, gp, gamma_L, n_air)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linelist_exomol_emi(cutoff,broad,ratio,nbroad,broad_dfs,states_part_df,trans_part_df, ncolumn):\n",
    "    if ncolumn == 4:\n",
    "        if cutoff == 'None':\n",
    "            trans_part_df = trans_part_df[trans_part_df['v'].between(min_wn, max_wn)] \n",
    "        else:\n",
    "            trans_part_df = trans_part_df[trans_part_df['v'].between(min_wn - cutoff, max_wn + cutoff)] \n",
    "        id_u = trans_part_df['u'].values\n",
    "        id_s = states_part_df['id'].values\n",
    "        trans_part_df.set_index(['u'], inplace=True, drop=False)\n",
    "        id_us = list(set(id_u).intersection(set(id_s)))\n",
    "        trans_us_df = trans_part_df.loc[id_us]\n",
    "        id_l = trans_us_df['l'].values\n",
    "        id_ls = list(set(id_l).intersection(set(id_s)))\n",
    "        if id_ls != []:\n",
    "            trans_us_df.set_index(['l'], inplace=True, drop=False)\n",
    "            trans_s_df = trans_us_df.loc[id_ls]\n",
    "            trans_s_df.sort_values(by=['v'], inplace=True)\n",
    "            id_su = trans_s_df['u'].values\n",
    "            id_sl = trans_s_df['l'].values\n",
    "            states_u_df = states_part_df.loc[id_su]\n",
    "            states_l_df = states_part_df.loc[id_sl]\n",
    "            Ep = states_u_df['E'].values.astype('float')\n",
    "            gp = states_u_df['g'].values.astype('int')\n",
    "            A = trans_s_df['A'].values.astype('float')\n",
    "            v = trans_s_df['v'].values.astype('float')\n",
    "        else:\n",
    "            raise ImportError(\"Empty result with the input filter values. Please type new filter values in the input file.\")  \n",
    "    else:\n",
    "        id_u = trans_part_df['u'].values\n",
    "        id_s = states_part_df['id'].values\n",
    "        trans_part_df.set_index(['u'], inplace=True, drop=False)\n",
    "        id_us = list(set(id_u).intersection(set(id_s)))\n",
    "        trans_us_df = trans_part_df.loc[id_us]\n",
    "        id_l = trans_us_df['l'].values\n",
    "        id_ls = list(set(id_l).intersection(set(id_s)))\n",
    "        trans_us_df.set_index(['l'], inplace=True, drop=False)\n",
    "        trans_s_df = trans_us_df.loc[id_ls]\n",
    "        id_su = trans_s_df['u'].values\n",
    "        id_sl = trans_s_df['l'].values\n",
    "        states_u_df = states_part_df.loc[id_su]\n",
    "        states_l_df = states_part_df.loc[id_sl]\n",
    "        trans_s_df['Ep'] = states_u_df['E'].values.astype('float')\n",
    "        trans_s_df['Epp'] = states_l_df['E'].values.astype('float')\n",
    "        trans_s_df['gp'] = states_u_df['g'].values.astype('int')\n",
    "        trans_s_df['v'] = cal_v(trans_s_df['Ep'].values, trans_s_df['Epp'].values)\n",
    "        if cutoff == 'None':\n",
    "            trans_s_df = trans_s_df[trans_s_df['v'].between(min_wn, max_wn)]\n",
    "        else:\n",
    "            trans_s_df = trans_s_df[trans_s_df['v'].between(min_wn - cutoff, max_wn + cutoff)]\n",
    "        if len(trans_s_df) != 0:\n",
    "            trans_s_df.sort_values(by=['v'], inplace=True)\n",
    "            Ep = trans_s_df['Ep'].values\n",
    "            gp = trans_s_df['gp'].values\n",
    "            A = trans_s_df['A'].values\n",
    "            v = trans_s_df['v'].values\n",
    "            id_sl = trans_s_df['l'].values\n",
    "            states_l_df = states_part_df.loc[id_sl]\n",
    "        else:\n",
    "            raise ImportError(\"Empty result with the input filter values. Please type new filter values in the input file.\")  \n",
    "    gamma_L = pd.DataFrame()\n",
    "    n_air = pd.DataFrame()\n",
    "    rows = len(id_sl)\n",
    "    for i in range(nbroad):\n",
    "        if broad[i] == 'Default':\n",
    "            gamma_L[i] = np.full((1,rows),broad_dfs[i]['gamma_L'][0])[0] * ratio[i]\n",
    "            n_air[i] = np.full((1,rows),broad_dfs[i]['n_air'][0])[0] * ratio[i]\n",
    "        else:\n",
    "            gamma_L[i] = extract_broad(broad_dfs[i],states_l_df)[0] * ratio[i]\n",
    "            n_air[i] = extract_broad(broad_dfs[i],states_l_df)[1] * ratio[i]\n",
    "    return (A, v, Ep, gp, gamma_L, n_air)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linelist_hitran_abs(hitran_df):\n",
    "    '''\n",
    "    Read HITRAN .par file as the input file.\n",
    "    Return the data for calculating wavennumbers and cross sections with line profiles.\n",
    "    \n",
    "    '''\n",
    "    A = hitran_df['A'].values\n",
    "    Epp = hitran_df['Epp'].values\n",
    "    n_air = hitran_df['n_air'].values\n",
    "    gamma_air = hitran_df['gamma_air'].values\n",
    "    gamma_self = hitran_df['gamma_self'].values\n",
    "    delta_air = hitran_df['delta_air'].values\n",
    "    gp = hitran_df['gp'].values\n",
    "    v = hitran_df['v'].values\n",
    "    #if broad == 'Air':\n",
    "    #    v = hitran_df['v'].values + delta_air * (P - P_ref) / P\n",
    "    #else:\n",
    "    #    v = hitran_df['v'].values\n",
    "    return (A, v, Epp, gp, n_air, gamma_air, gamma_self, delta_air)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Line Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Doppler_HWHM(v,T):\n",
    "    '''Return the Doppler half-width at half-maximum (HWHM) -- alpha.'''\n",
    "    # alpha = np.sqrt(2 * N_A * kB * T * np.log(2) / mass) * v / c\n",
    "    alpha = ne.evaluate('Sqrt2NAkBln2mInvc * sqrt(T) * v')\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gaussian_standard_deviation(alpha):\n",
    "    '''Return the Gaussian standard deviation -- sigma.'''\n",
    "    # sigma = alpha / np.sqrt(2 * np.log(2))\n",
    "    sigma = ne.evaluate('alpha * InvSqrt2ln2')\n",
    "    return sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Lorentzian_HWHM(gamma_L, n_air,T,P):\n",
    "    '''Return the Lorentzian half-width at half-maximum (HWHM) -- gamma.'''\n",
    "    gamma = ne.evaluate('gamma_L * (Tref / T)**n_air * (P / Pref)')\n",
    "    return gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DopplerHWHM_alpha(num_v, alpha_HWHM, v, T):\n",
    "    if alpha_HWHM != 'None':\n",
    "        alpha = np.full(num_v, alpha_HWHM)\n",
    "    else:\n",
    "        alpha = Doppler_HWHM(v,T)\n",
    "    return(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LorentzianHWHM_gamma(num_v, gamma_HWHM, broad, gamma_L, n_air, gamma_air, gamma_self, ratios, T, P):\n",
    "    if gamma_HWHM != 'None':\n",
    "        gamma = np.full(num_v, gamma_HWHM)\n",
    "    else:\n",
    "        if database == 'EXOMOL':\n",
    "            gamma = pd.DataFrame()\n",
    "            for i in range(len(broad)):\n",
    "                gamma[i] = Lorentzian_HWHM (gamma_L[i].values, n_air[i].values,T,P)\n",
    "            gamma = gamma.sum(axis=1).values  \n",
    "        elif database == 'HITRAN':   \n",
    "            gamma_L = gamma_air*ratios[1]+ gamma_self*ratios[2]\n",
    "            gamma = Lorentzian_HWHM(gamma_L, n_air,T,P) \n",
    "    return(gamma)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def FWHM(alpha, gamma):\n",
    "    '''Return the Gaussian full-width at half-maximum (FWHM)   -- fG.\n",
    "       Return the Lorentzian full-width at half-maximum (FWHM) -- fL.\n",
    "    '''\n",
    "    # fG = 2 * sigma * np.sqrt(2 * np.log(2)) = 2 * alpha\n",
    "    # fG = ne.evaluate('sigma * TwoSqrt2ln2')\n",
    "    fG = ne.evaluate('2 * alpha')\n",
    "    fL = ne.evaluate('2 * gamma')\n",
    "    return (fG, fL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Doppler_profile(dv, alpha):\n",
    "    '''Return Doppler line profile at dv with HWHM alpha.'''\n",
    "    # Doppler_profile = np.sqrt(np.log(2) / np.pi) / alpha * np.exp(-np.log(2) * (dv / alpha)**2) \n",
    "    DopplerProfile = ne.evaluate('Sqrtln2InvPi / alpha * exp(Negln2 * (dv / alpha)**2)')\n",
    "    return DopplerProfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Lorentzian_profile(dv, gamma):\n",
    "    '''Return Lorentzian line profile at dv with HWHM gamma.'''\n",
    "    LorentzianProfile = ne.evaluate('gamma / PI / (dv**2 + gamma**2)')\n",
    "    return LorentzianProfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SciPyVoigt_profile(dv, sigma, gamma):\n",
    "    '''Return the Voigt line profile with Lorentzian component HWHM gamma and Gaussian component HWHM alpha.'''\n",
    "    SciPyVoigtProfile = voigt_profile(dv, sigma, gamma)\n",
    "    return SciPyVoigtProfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SciPyWofzVoigt_profile(dv, sigma, gamma):\n",
    "    '''Return the Voigt line profile with Lorentzian component HWHM gamma and Gaussian component HWHM alpha.'''\n",
    "    # scipy_wofz_Voigt_profile = np.real(wofz((dv + 1j*gamma)/sigma/np.sqrt(2))) / sigma / np.sqrt(2*np.pi)\n",
    "    z = ne.evaluate('(dv + 1j*gamma)/sigma*InvSqrt2')\n",
    "    wz = wofz(z)\n",
    "    SciPyWofzVoigtProfile = ne.evaluate('real(wz) / sigma * InvSqrt2Pi')\n",
    "    return SciPyWofzVoigtProfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Humlicek1(t):\n",
    "    w = ne.evaluate('t * InvSqrtPi / (0.5 + t**2)')\n",
    "    return(w)\n",
    "\n",
    "def Humlicek2(t, u):\n",
    "    w = ne.evaluate('(t*(1.4104739589+u*InvSqrtPi))/(0.75+u*(3+u))')\n",
    "    return(w)\n",
    "\n",
    "def Humlicek3(t):\n",
    "    w = ne.evaluate('(16.4955+t*(20.20933+t*(11.96482+t*(3.778987+0.5642236*t))))/(16.4955+t*(38.82363+t*(39.27121+t*(21.69274+t*(6.699398+t)))))')\n",
    "    return(w)\n",
    "\n",
    "def Humlicek4(t, u):\n",
    "    nom = ne.evaluate('t*(36183.31-u*(3321.99-u*(1540.787-u*(219.031-u*(35.7668-u*(1.320522-u*0.56419))))))')\n",
    "    den = ne.evaluate('32066.6-u*(24322.8-u*(9022.23-u*(2186.18-u*(364.219-u*(61.5704-u*(1.84144-u))))))')\n",
    "    w = ne.evaluate('exp(u)-nom/den')   \n",
    "    return(w)\n",
    "\n",
    "def HumlicekVoigt_profile(dv, alpha, gamma):\n",
    "    x = ne.evaluate('dv * Sqrtln2 / alpha')\n",
    "    y = ne.evaluate('gamma * Sqrtln2 / alpha')\n",
    "    t = ne.evaluate('y-1j*x')\n",
    "    s = ne.evaluate('abs(x)+y')\n",
    "    u = ne.evaluate('t**2')\n",
    "    w = np.zeros_like(alpha)\n",
    "    ybound = ne.evaluate('0.195*abs(x)-0.176')\n",
    "    # Region 1\n",
    "    humfilter1 = s >= 15\n",
    "    t1 = t[humfilter1]\n",
    "    w[humfilter1] = Humlicek1(t1)\n",
    "    # Region 2\n",
    "    humfilter2 = (5.5 <= s) & (s < 15)\n",
    "    t2 = t[humfilter2]\n",
    "    u2 = u[humfilter2]\n",
    "    w[humfilter2] = Humlicek2(t2, u2)\n",
    "    # Region 3\n",
    "    humfilter3 = (s < 5.5) & (y >= ybound)\n",
    "    t3 = t[humfilter3]\n",
    "    w[humfilter3] = Humlicek3(t3)\n",
    "    # Region 4\n",
    "    humfilter4 = (s < 5.5) & (y < ybound)\n",
    "    t4 = t[humfilter4]\n",
    "    u4 = u[humfilter4]\n",
    "    w[humfilter4] = Humlicek4(t4, u4)  \n",
    "    HumlicekVoigtProfile = ne.evaluate('real(w) / alpha * Sqrtln2InvPi')\n",
    "    return HumlicekVoigtProfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PseudoVoigt_profile(dv, alpha, gamma, eta, hV):\n",
    "    '''\n",
    "    fv is the total FWHM parameter and the Voigt full-width at half-maximum (FWHM), \n",
    "    which can be found from the widths of the associated Gaussian and Lorentzian widths.\n",
    "    eta is a function of Lorentz (fL), Gaussian (fG) and total (fV) full width at half maximum (FWHM) parameters.\n",
    "    '''\n",
    "    GaussianProfile = Doppler_profile(dv, hV)\n",
    "    LorentzianProfile = Lorentzian_profile(dv, hV)\n",
    "    PseudoVoigtProfile = ne.evaluate('eta * LorentzianProfile + (1 - eta) * GaussianProfile')\n",
    "    return PseudoVoigtProfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PseudoVoigt(alpha, gamma):\n",
    "    '''\n",
    "    fv is the total FWHM parameter and the Voigt full-width at half-maximum (FWHM), \n",
    "    which can be found from the widths of the associated Gaussian and Lorentzian widths.\n",
    "    eta is a function of Lorentz (fL), Gaussian (fG) and total (fV) full width at half maximum (FWHM) parameters.\n",
    "    '''  \n",
    "    hV = ne.evaluate('(alpha**5+2.69269*alpha**4*gamma+2.42843*alpha**3*gamma**2+4.47163*alpha**2*gamma**3+0.07842*alpha*gamma**4+gamma**5)**0.2')\n",
    "    eta = ne.evaluate('1.36603*(gamma/hV) - 0.47719*(gamma/hV)**2 + 0.11116*(gamma/hV)**3')\n",
    "    return (eta, hV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PseudoKielkopfVoigt(alpha, gamma):\n",
    "    '''\n",
    "    fv is the total FWHM parameter and the Voigt full-width at half-maximum (FWHM), \n",
    "    which can be found from the widths of the associated Gaussian and Lorentzian widths.\n",
    "    eta is a function of Lorentz (fL), Gaussian (fG) and total (fV) full width at half maximum (FWHM) parameters.\n",
    "    '''\n",
    "    hV = ne.evaluate('0.5346 * gamma + sqrt(0.2166 * gamma**2 + alpha**2)')\n",
    "    eta = ne.evaluate('1.36603*(gamma/hV) - 0.47719*(gamma/hV)**2 + 0.11116*(gamma/hV)**3')\n",
    "    return (eta, hV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PseudoOliveroVoigt(alpha, gamma):\n",
    "    '''\n",
    "    fv is the total FWHM parameter and the Voigt full-width at half-maximum (FWHM), \n",
    "    which can be found from the widths of the associated Gaussian and Lorentzian widths.\n",
    "    eta is a function of Lorentz (fL), Gaussian (fG) and total (fV) full width at half maximum (FWHM) parameters.\n",
    "    '''\n",
    "    d = ne.evaluate('(gamma-alpha)/(gamma+alpha)')\n",
    "    hV = ne.evaluate('(1-0.18121*(1-d**2)-(0.023665*exp(0.6*d)+0.00418*exp(-1.9*d))*sinPI*d)*(alpha+gamma)')\n",
    "    eta = ne.evaluate('1.36603*(gamma/hV) - 0.47719*(gamma/hV)**2 + 0.11116*(gamma/hV)**3')\n",
    "    return (eta, hV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PseudoLiuLinVoigt(alpha, gamma):\n",
    "    '''\n",
    "    fv is the total FWHM parameter and the Voigt full-width at half-maximum (FWHM), \n",
    "    which can be found from the widths of the associated Gaussian and Lorentzian widths.\n",
    "    eta is a function of Lorentz (fL), Gaussian (fG) and total (fV) full width at half maximum (FWHM) parameters.\n",
    "    '''\n",
    "    d = ne.evaluate('(gamma-alpha)/(gamma+alpha)')\n",
    "    hV = ne.evaluate('(1-0.18121*(1-d**2)-(0.023665*exp(0.6*d)+0.00418*exp(-1.9*d))*sinPI*d)*(alpha+gamma)')\n",
    "    eta = ne.evaluate('0.68188+0.61293*d-0.18384*d**2-0.11568*d**3')\n",
    "    return (eta, hV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PseudoRoccoVoigt(alpha, gamma):\n",
    "    '''\n",
    "    hv is the half width parameter and the Voigt half-width at half-maximum (HWHM), \n",
    "    which can be found from the widths of the associated Gaussian and Lorentzian widths.\n",
    "    eta is a function of Lorentz (fL), Gaussian (fG) and (hV) half width at half maximum (HWHM) parameters.\n",
    "    '''  \n",
    "    y = gamma*Sqrtln2/alpha\n",
    "    erfy = erf(y)\n",
    "    bhalfy = ne.evaluate('y+Sqrtln2*exp(-0.6055*y+0.0718*y**2-0.0049*y**3+0.000136*y**4)')\n",
    "    Vy = ne.evaluate('bhalfy*exp(y**2)*(1-erfy)')\n",
    "    eta = ne.evaluate('(Vy-Sqrtln2)/(Vy*OneminSqrtPIln2)')\n",
    "    hV = ne.evaluate('alpha / Sqrtln2 * bhalfy')\n",
    "    return (eta, hV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BinnedGaussian_profile(dv, alpha):\n",
    "    '''Return binned Gaussian line profile at dv with HWHM alpha.'''\n",
    "    erfxpos = erf(ne.evaluate('Sqrtln2*(dv+binSizeHalf)/alpha'))\n",
    "    erfxneg = erf(ne.evaluate('Sqrtln2*(dv-binSizeHalf)/alpha'))\n",
    "    BinnedGaussianProfile = ne.evaluate('erfxpos-erfxneg')\n",
    "    return BinnedGaussianProfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BinnedLorentzian_profile(dv, gamma, bnormBinsize):\n",
    "    '''Return binned Lorentzian line profile at dv with HWHM gamma.'''\n",
    "    BinnedLorentzianProfile = ne.evaluate('(arctan((dv+binSizeHalf)/gamma)-arctan((dv-binSizeHalf)/gamma))*bnormBinsize')\n",
    "    return BinnedLorentzianProfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BinnedVoigt_bnormq(wngrid_start, wngrid_end, v, sigma, gamma, x):\n",
    "    '''Return binned Voigt line profile at dv with HWHM gamma.'''\n",
    "    vxsigma = ne.evaluate('v+x*sigma')\n",
    "    bnormq = ne.evaluate('1/(arctan((wngrid_end-vxsigma)/gamma)-arctan((wngrid_start-vxsigma)/gamma))')\n",
    "    return bnormq\n",
    "\n",
    "def BinnedVoigt_lorenz(dv, sigma, gamma, x):\n",
    "    '''Return binned Voigt line profile at dv with HWHM gamma.'''\n",
    "    dvxsigma = ne.evaluate('dv-x*sigma')\n",
    "    lorenz = ne.evaluate('arctan((dvxsigma+binSizeHalf)/gamma)-arctan((dvxsigma-binSizeHalf)/gamma)')\n",
    "    return lorenz\n",
    "\n",
    "def BinnedVoigt_profile(w, bnormq, lorenz):\n",
    "    '''Return binned Voigt line profile at dv with HWHM gamma.'''\n",
    "    BinnedVoigtProfile = ne.evaluate('sum(w*bnormq*lorenz)')\n",
    "    return BinnedVoigtProfile"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Cross Sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_section_Doppler(wn_grid, v, alpha, coef, cutoff, threshold):\n",
    "    '''\n",
    "    Read ExoMol .states, .trans, .pf and .broad files as the input files.\n",
    "    Return the wavennumbers and cross sections with Doppler profile.\n",
    "    \n",
    "    '''  \n",
    "    xsec = np.zeros_like(wn_grid)\n",
    "    if (cutoff == 'None') & (threshold == 'None'):   \n",
    "        start = max(0,wn_grid.searchsorted(v.min())-1)\n",
    "        end = min(wn_grid.searchsorted(v.max()),len(wn_grid))\n",
    "        _xsec = np.zeros(shape=(end-start))\n",
    "        for i in range(start,end):\n",
    "            idx = i-start\n",
    "            wn_grid_i = wn_grid[i]\n",
    "            dv = ne.evaluate('wn_grid_i - v')\n",
    "            Doppler = Doppler_profile(dv, alpha)\n",
    "            _xsec[idx] = ne.evaluate('sum(coef * Doppler)')\n",
    "    elif (cutoff == 'None') & (threshold != 'None'):\n",
    "        filter = coef >= threshold\n",
    "        _alpha = alpha[filter]\n",
    "        if _alpha.size > 0:\n",
    "            _coef = coef[filter]\n",
    "            start = max(0,wn_grid.searchsorted(v.min())-1)\n",
    "            end = min(wn_grid.searchsorted(v.max()),len(wn_grid))\n",
    "            _xsec = np.zeros(shape=(end-start))\n",
    "            for i in range(start,end):\n",
    "                idx = i-start\n",
    "                wn_grid_i = wn_grid[i]\n",
    "                _dv = ne.evaluate('wn_grid_i - v')[filter]\n",
    "                Doppler = Doppler_profile(_dv, _alpha)\n",
    "                _xsec[idx] = ne.evaluate('sum(_coef * Doppler)')\n",
    "    elif (cutoff != 'None') & (threshold == 'None'):\n",
    "        start = max(0,wn_grid.searchsorted(v.min()-cutoff)-1)\n",
    "        end = min(wn_grid.searchsorted(v.max()+cutoff),len(wn_grid))\n",
    "        _xsec = np.zeros(shape=(end-start))\n",
    "        for i in range(start,end):\n",
    "            idx = i-start\n",
    "            wn_grid_i = wn_grid[i]\n",
    "            dv = ne.evaluate('wn_grid_i - v')\n",
    "            filter = np.abs(dv) <= cutoff\n",
    "            _dv = dv[filter]\n",
    "            if _dv.size > 0:\n",
    "                _alpha = alpha[filter]\n",
    "                _coef = coef[filter]\n",
    "                Doppler = Doppler_profile(_dv, _alpha)\n",
    "                _xsec[idx] = ne.evaluate('sum(_coef * Doppler)')\n",
    "    else: \n",
    "        filter_threshold = coef >= threshold\n",
    "        start = max(0,wn_grid.searchsorted(v.min()-cutoff)-1)\n",
    "        end = min(wn_grid.searchsorted(v.max()+cutoff),len(wn_grid))\n",
    "        _xsec = np.zeros(shape=(end-start))\n",
    "        for i in range(start,end):\n",
    "            idx = i-start\n",
    "            wn_grid_i = wn_grid[i]\n",
    "            dv = ne.evaluate('wn_grid_i - v')\n",
    "            filter_cutoff = np.abs(dv) <= cutoff\n",
    "            filter = filter_cutoff & filter_threshold\n",
    "            _dv = dv[filter]\n",
    "            if _dv.size > 0:\n",
    "                _alpha = alpha[filter]\n",
    "                _coef = coef[filter]\n",
    "                Doppler = Doppler_profile(_dv, _alpha)\n",
    "                _xsec[idx] = ne.evaluate('sum(_coef * Doppler)')      \n",
    "            \n",
    "    xsec[start:end] += _xsec\n",
    "    return (xsec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_section_Lorentzian(wn_grid, v, gamma, coef, cutoff, threshold):\n",
    "    '''\n",
    "    Read ExoMol .states, .trans, .pf and .broad files as the input files.\n",
    "    Return the wavennumbers and cross sections with Lorentzian profile.\n",
    "    \n",
    "    '''\n",
    "    xsec = np.zeros_like(wn_grid)\n",
    "    if (cutoff == 'None') & (threshold == 'None'):\n",
    "        start = max(0,wn_grid.searchsorted(v.min())-1)\n",
    "        end = min(wn_grid.searchsorted(v.max()),len(wn_grid))\n",
    "        _xsec = np.zeros(shape=(end-start))\n",
    "        for i in range(start,end):\n",
    "            idx = i-start\n",
    "            wn_grid_i = wn_grid[i]\n",
    "            dv = ne.evaluate('wn_grid_i - v')\n",
    "            Lorentzian = Lorentzian_profile(dv, gamma)\n",
    "            _xsec[idx] = ne.evaluate('sum(coef * Lorentzian)')       \n",
    "    elif (cutoff == 'None') & (threshold != 'None'):\n",
    "        filter = coef >= threshold\n",
    "        _gamma = gamma[filter]\n",
    "        if _gamma.size > 0:\n",
    "            _coef = coef[filter]\n",
    "            start = max(0,wn_grid.searchsorted(v.min())-1)\n",
    "            end = min(wn_grid.searchsorted(v.max()),len(wn_grid))\n",
    "            _xsec = np.zeros(shape=(end-start))\n",
    "            for i in range(start,end):\n",
    "                idx = i-start\n",
    "                wn_grid_i = wn_grid[i]\n",
    "                _dv = ne.evaluate('wn_grid_i - v')[filter]\n",
    "                Lorentzian = Lorentzian_profile(_dv, _gamma)\n",
    "                _xsec[idx] = ne.evaluate('sum(_coef * Lorentzian)')       \n",
    "    elif (cutoff != 'None') & (threshold == 'None'):\n",
    "        start = max(0,wn_grid.searchsorted(v.min()-cutoff)-1)\n",
    "        end = min(wn_grid.searchsorted(v.max()+cutoff),len(wn_grid))\n",
    "        _xsec = np.zeros(shape=(end-start))\n",
    "        for i in range(start,end):\n",
    "            idx = i-start\n",
    "            wn_grid_i = wn_grid[i]\n",
    "            dv = ne.evaluate('wn_grid_i - v')\n",
    "            filter = np.abs(dv) <= cutoff\n",
    "            _dv = dv[filter]\n",
    "            if _dv.size > 0:\n",
    "                _gamma = gamma[filter]\n",
    "                _coef = coef[filter]\n",
    "                Lorentzian = Lorentzian_profile(_dv, _gamma)\n",
    "                _xsec[idx] = ne.evaluate('sum(_coef * Lorentzian)')        \n",
    "    else: \n",
    "        filter_threshold = coef >= threshold\n",
    "        start = max(0,wn_grid.searchsorted(v.min()-cutoff)-1)\n",
    "        end = min(wn_grid.searchsorted(v.max()+cutoff),len(wn_grid))\n",
    "        _xsec = np.zeros(shape=(end-start))\n",
    "        for i in range(start,end):\n",
    "            idx = i-start\n",
    "            wn_grid_i = wn_grid[i]\n",
    "            dv = ne.evaluate('wn_grid_i - v')\n",
    "            filter_cutoff = np.abs(dv) <= cutoff\n",
    "            filter = filter_cutoff & filter_threshold\n",
    "            _dv = dv[filter]\n",
    "            if _dv.size > 0:\n",
    "                _gamma = gamma[filter]\n",
    "                _coef = coef[filter]\n",
    "                Lorentzian = Lorentzian_profile(_dv, _gamma)\n",
    "                _xsec[idx] = ne.evaluate('sum(_coef * Lorentzian)')        \n",
    "            \n",
    "    xsec[start:end] += _xsec\n",
    "    return (xsec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_section_SciPyVoigt(wn_grid, v, sigma, gamma, coef, cutoff, threshold):\n",
    "    '''\n",
    "    Read ExoMol .states, .trans, .pf and .broad files as the input files.\n",
    "    Return the wavennumbers and cross sections with SciPy Voigt profile.\n",
    "    \n",
    "    '''\n",
    "    xsec = np.zeros_like(wn_grid)\n",
    "    if (cutoff == 'None') & (threshold == 'None'):\n",
    "        start = max(0,wn_grid.searchsorted(v.min())-1)\n",
    "        end = min(wn_grid.searchsorted(v.max()),len(wn_grid))\n",
    "        _xsec = np.zeros(shape=(end-start))\n",
    "        for i in range(start,end):\n",
    "            idx = i-start\n",
    "            wn_grid_i = wn_grid[i]\n",
    "            dv = ne.evaluate('wn_grid_i - v')\n",
    "            SciPyVoigt = SciPyVoigt_profile(dv, sigma, gamma)\n",
    "            _xsec[idx] = ne.evaluate('sum(coef * SciPyVoigt)') \n",
    "    elif (cutoff == 'None') & (threshold != 'None'):\n",
    "        filter = coef >= threshold\n",
    "        _sigma = sigma[filter]\n",
    "        if _sigma.size > 0:\n",
    "            _gamma = gamma[filter]\n",
    "            _coef = coef[filter]\n",
    "            start = max(0,wn_grid.searchsorted(v.min())-1)\n",
    "            end = min(wn_grid.searchsorted(v.max()),len(wn_grid))\n",
    "            _xsec = np.zeros(shape=(end-start))\n",
    "            for i in range(start,end):\n",
    "                idx = i-start\n",
    "                wn_grid_i = wn_grid[i]\n",
    "                _dv = ne.evaluate('wn_grid_i - v')[filter]\n",
    "                SciPyVoigt = SciPyVoigt_profile(_dv, _sigma, _gamma)\n",
    "                _xsec[idx] = ne.evaluate('sum(_coef * SciPyVoigt)') \n",
    "    elif (cutoff != 'None') & (threshold == 'None'):\n",
    "        start = max(0,wn_grid.searchsorted(v.min()-cutoff)-1)\n",
    "        end = min(wn_grid.searchsorted(v.max()+cutoff),len(wn_grid))\n",
    "        _xsec = np.zeros(shape=(end-start))\n",
    "        for i in range(start,end):\n",
    "            idx = i-start\n",
    "            wn_grid_i = wn_grid[i]\n",
    "            dv = ne.evaluate('wn_grid_i - v')\n",
    "            filter = np.abs(dv) <= cutoff\n",
    "            _dv = dv[filter]\n",
    "            if _dv.size > 0:\n",
    "                _sigma = sigma[filter]\n",
    "                _gamma = gamma[filter]\n",
    "                _coef = coef[filter]\n",
    "                SciPyVoigt = SciPyVoigt_profile(_dv, _sigma, _gamma)\n",
    "                _xsec[idx] = ne.evaluate('sum(_coef * SciPyVoigt)') \n",
    "    else: \n",
    "        filter_threshold = coef >= threshold\n",
    "        start = max(0,wn_grid.searchsorted(v.min()-cutoff)-1)\n",
    "        end = min(wn_grid.searchsorted(v.max()+cutoff),len(wn_grid))\n",
    "        _xsec = np.zeros(shape=(end-start))\n",
    "        for i in range(start,end):\n",
    "            idx = i-start\n",
    "            wn_grid_i = wn_grid[i]\n",
    "            dv = ne.evaluate('wn_grid_i - v')\n",
    "            filter_cutoff = np.abs(dv) <= cutoff\n",
    "            filter = filter_cutoff & filter_threshold\n",
    "            _dv = dv[filter]\n",
    "            if _dv.size > 0:\n",
    "                _sigma = sigma[filter]\n",
    "                _gamma = gamma[filter]\n",
    "                _coef = coef[filter]\n",
    "                SciPyVoigt = SciPyVoigt_profile(_dv, _sigma, _gamma)\n",
    "                _xsec[idx] = ne.evaluate('sum(_coef * SciPyVoigt)') \n",
    "            \n",
    "    xsec[start:end] += _xsec\n",
    "    return (xsec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_section_SciPyWofzVoigt(wn_grid, v, sigma, gamma, coef, cutoff, threshold):\n",
    "    '''\n",
    "    Read ExoMol .states, .trans, .pf and .broad files as the input files.\n",
    "    Return the wavennumbers and cross sections with SciPy Wofz Voigt profile.\n",
    "\n",
    "    '''\n",
    "    xsec = np.zeros_like(wn_grid)\n",
    "    if (cutoff == 'None') & (threshold == 'None'):\n",
    "        start = max(0,wn_grid.searchsorted(v.min())-1)\n",
    "        end = min(wn_grid.searchsorted(v.max()),len(wn_grid))\n",
    "        _xsec = np.zeros(shape=(end-start))\n",
    "        for i in range(start,end):\n",
    "            idx = i-start\n",
    "            wn_grid_i = wn_grid[i]\n",
    "            dv = ne.evaluate('wn_grid_i - v')\n",
    "            SciPyWofzVoigt = SciPyWofzVoigt_profile(dv, sigma, gamma)\n",
    "            _xsec[idx] = ne.evaluate('sum(coef * SciPyWofzVoigt)')\n",
    "    elif (cutoff == 'None') & (threshold != 'None'):            \n",
    "        filter = coef >= threshold\n",
    "        _sigma = sigma[filter]\n",
    "        if _sigma.size > 0:\n",
    "            _gamma = gamma[filter]\n",
    "            _coef = coef[filter]\n",
    "            start = max(0,wn_grid.searchsorted(v.min())-1)\n",
    "            end = min(wn_grid.searchsorted(v.max()),len(wn_grid))\n",
    "            _xsec = np.zeros(shape=(end-start))\n",
    "            for i in range(start,end):\n",
    "                idx = i-start\n",
    "                wn_grid_i = wn_grid[i]\n",
    "                _dv = ne.evaluate('wn_grid_i - v')[filter]\n",
    "                SciPyWofzVoigt = SciPyWofzVoigt_profile(_dv, _sigma, _gamma)\n",
    "                _xsec[idx] = ne.evaluate('sum(_coef * SciPyWofzVoigt)') \n",
    "    elif (cutoff != 'None') & (threshold == 'None'):\n",
    "        start = max(0,wn_grid.searchsorted(v.min()-cutoff)-1)\n",
    "        end = min(wn_grid.searchsorted(v.max()+cutoff),len(wn_grid))\n",
    "        _xsec = np.zeros(shape=(end-start))\n",
    "        for i in range(start,end):\n",
    "            idx = i-start\n",
    "            wn_grid_i = wn_grid[i]\n",
    "            dv = ne.evaluate('wn_grid_i - v')\n",
    "            filter = np.abs(dv) <= cutoff\n",
    "            _dv = dv[filter]\n",
    "            if _dv.size > 0:\n",
    "                _sigma = sigma[filter]\n",
    "                _gamma = gamma[filter]\n",
    "                _coef = coef[filter]\n",
    "                SciPyWofzVoigt = SciPyWofzVoigt_profile(_dv, _sigma, _gamma)\n",
    "                _xsec[idx] = ne.evaluate('sum(_coef * SciPyWofzVoigt)')\n",
    "    else: \n",
    "        filter_threshold = coef >= threshold\n",
    "        start = max(0,wn_grid.searchsorted(v.min()-cutoff)-1)\n",
    "        end = min(wn_grid.searchsorted(v.max()+cutoff),len(wn_grid))\n",
    "        _xsec = np.zeros(shape=(end-start))\n",
    "        for i in range(start,end):\n",
    "            idx = i-start\n",
    "            wn_grid_i = wn_grid[i]\n",
    "            dv = ne.evaluate('wn_grid_i - v')\n",
    "            filter_cutoff = np.abs(dv) <= cutoff\n",
    "            filter = filter_cutoff & filter_threshold\n",
    "            _dv = dv[filter]\n",
    "            if _dv.size > 0:\n",
    "                _sigma = sigma[filter]\n",
    "                _gamma = gamma[filter]\n",
    "                _coef = coef[filter]\n",
    "                SciPyWofzVoigt = SciPyWofzVoigt_profile(_dv, _sigma, _gamma)\n",
    "                _xsec[idx] = ne.evaluate('sum(_coef * SciPyWofzVoigt)')\n",
    "            \n",
    "    xsec[start:end] += _xsec\n",
    "    return (xsec)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_section_HumlicekVoigt(wn_grid, v, alpha, gamma, coef, cutoff, threshold):\n",
    "    '''\n",
    "    Read ExoMol .states, .trans, .pf and .broad files as the input files.\n",
    "    Return the wavennumbers and cross sections with Humlicek Voigt profile.\n",
    "    \n",
    "    '''\n",
    "    xsec = np.zeros_like(wn_grid)\n",
    "    if (cutoff == 'None') & (threshold == 'None'):\n",
    "        start = max(0,wn_grid.searchsorted(v.min())-1)\n",
    "        end = min(wn_grid.searchsorted(v.max()),len(wn_grid))\n",
    "        _xsec = np.zeros(shape=(end-start))\n",
    "        for i in range(start,end):\n",
    "            idx = i-start\n",
    "            wn_grid_i = wn_grid[i]\n",
    "            dv = ne.evaluate('wn_grid_i - v')\n",
    "            HumlicekVoigt = HumlicekVoigt_profile(dv, alpha, gamma)\n",
    "            _xsec[idx] = ne.evaluate('sum(coef * HumlicekVoigt)') \n",
    "    elif (cutoff == 'None') & (threshold != 'None'):\n",
    "        filter = coef >= threshold\n",
    "        _alpha = alpha[filter]\n",
    "        if _alpha.size > 0:\n",
    "            _gamma = gamma[filter]\n",
    "            _coef = coef[filter]\n",
    "            start = max(0,wn_grid.searchsorted(v.min())-1)\n",
    "            end = min(wn_grid.searchsorted(v.max()),len(wn_grid))\n",
    "            _xsec = np.zeros(shape=(end-start))\n",
    "            for i in range(start,end):\n",
    "                idx = i-start\n",
    "                wn_grid_i = wn_grid[i]\n",
    "                _dv = ne.evaluate('wn_grid_i - v')[filter]\n",
    "                HumlicekVoigt = HumlicekVoigt_profile(_dv, _alpha, _gamma)\n",
    "                _xsec[idx] = ne.evaluate('sum(_coef * HumlicekVoigt)') \n",
    "    elif (cutoff != 'None') & (threshold == 'None'):\n",
    "        start = max(0,wn_grid.searchsorted(v.min()-cutoff)-1)\n",
    "        end = min(wn_grid.searchsorted(v.max()+cutoff),len(wn_grid))\n",
    "        _xsec = np.zeros(shape=(end-start))\n",
    "        for i in range(start,end):\n",
    "            idx = i-start\n",
    "            wn_grid_i = wn_grid[i]\n",
    "            dv = ne.evaluate('wn_grid_i - v')\n",
    "            filter = np.abs(dv) <= cutoff\n",
    "            _dv = dv[filter]\n",
    "            if _dv.size > 0:\n",
    "                _alpha = alpha[filter]\n",
    "                _gamma = gamma[filter]\n",
    "                _coef = coef[filter]\n",
    "                HumlicekVoigt = HumlicekVoigt_profile(_dv, _alpha, _gamma)\n",
    "                _xsec[idx] = ne.evaluate('sum(_coef * HumlicekVoigt)') \n",
    "    else: \n",
    "        filter_threshold = coef >= threshold\n",
    "        start = max(0,wn_grid.searchsorted(v.min()-cutoff)-1)\n",
    "        end = min(wn_grid.searchsorted(v.max()+cutoff),len(wn_grid))\n",
    "        _xsec = np.zeros(shape=(end-start))\n",
    "        for i in range(start,end):\n",
    "            idx = i-start\n",
    "            wn_grid_i = wn_grid[i]\n",
    "            dv = ne.evaluate('wn_grid_i - v')\n",
    "            filter_cutoff = np.abs(dv) <= cutoff\n",
    "            filter = filter_cutoff & filter_threshold\n",
    "            _dv = dv[filter]\n",
    "            if _dv.size > 0:\n",
    "                _alpha = alpha[filter]\n",
    "                _gamma = gamma[filter]\n",
    "                _coef = coef[filter]\n",
    "                HumlicekVoigt = HumlicekVoigt_profile(_dv, _alpha, _gamma)\n",
    "                _xsec[idx] = ne.evaluate('sum(_coef * HumlicekVoigt)') \n",
    "            \n",
    "    xsec[start:end] += _xsec\n",
    "    return (xsec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_section_PseudoVoigt(wn_grid, v, alpha, gamma, eta, hV, coef, cutoff, threshold):\n",
    "    '''\n",
    "    Read ExoMol .states, .trans, .pf and .broad files as the input files.\n",
    "    Return the wavennumbers and cross sections with Pseudo Voigt profile.\n",
    "\n",
    "    '''\n",
    "    xsec = np.zeros_like(wn_grid)\n",
    "    if (cutoff == 'None') & (threshold == 'None'):\n",
    "        start = max(0,wn_grid.searchsorted(v.min())-1)\n",
    "        end = min(wn_grid.searchsorted(v.max()),len(wn_grid))\n",
    "        _xsec = np.zeros(shape=(end-start))\n",
    "        for i in range(start,end):\n",
    "            idx = i-start\n",
    "            wn_grid_i = wn_grid[i]\n",
    "            dv = ne.evaluate('wn_grid_i - v')\n",
    "            PseudoVoigt = PseudoVoigt_profile(dv, alpha, gamma, eta, hV)\n",
    "            _xsec[idx] = ne.evaluate('sum(coef * PseudoVoigt)')\n",
    "    elif (cutoff == 'None') & (threshold != 'None'):\n",
    "        filter = coef >= threshold\n",
    "        _alpha = alpha[filter]\n",
    "        if _alpha.size > 0:\n",
    "            _gamma = gamma[filter]\n",
    "            _eta = eta[filter]\n",
    "            _hV = hV[filter]\n",
    "            _coef = coef[filter]\n",
    "            start = max(0,wn_grid.searchsorted(v.min())-1)\n",
    "            end = min(wn_grid.searchsorted(v.max()),len(wn_grid))\n",
    "            _xsec = np.zeros(shape=(end-start))\n",
    "            for i in range(start,end):\n",
    "                idx = i-start\n",
    "                wn_grid_i = wn_grid[i]\n",
    "                _dv = ne.evaluate('wn_grid_i - v')[filter]\n",
    "                PseudoVoigt = PseudoVoigt_profile(_dv, _alpha, _gamma, _eta, _hV)\n",
    "                _xsec[idx] = ne.evaluate('sum(_coef * PseudoVoigt)')\n",
    "    elif (cutoff != 'None') & (threshold == 'None'):\n",
    "        start = max(0,wn_grid.searchsorted(v.min()-cutoff)-1)\n",
    "        end = min(wn_grid.searchsorted(v.max()+cutoff),len(wn_grid))\n",
    "        _xsec = np.zeros(shape=(end-start))\n",
    "        for i in range(start,end):\n",
    "            idx = i-start\n",
    "            wn_grid_i = wn_grid[i]\n",
    "            dv = ne.evaluate('wn_grid_i - v')\n",
    "            filter = np.abs(dv) <= cutoff\n",
    "            _dv = dv[filter]\n",
    "            if _dv.size > 0:\n",
    "                _alpha = alpha[filter]\n",
    "                _gamma = gamma[filter]\n",
    "                _eta = eta[filter]\n",
    "                _hV = hV[filter]\n",
    "                _coef = coef[filter]\n",
    "                PseudoVoigt = PseudoVoigt_profile(_dv, _alpha, _gamma, _eta, _hV)\n",
    "                _xsec[idx] = ne.evaluate('sum(_coef * PseudoVoigt)')\n",
    "    else: \n",
    "        filter_threshold = coef >= threshold\n",
    "        start = max(0,wn_grid.searchsorted(v.min()-cutoff)-1)\n",
    "        end = min(wn_grid.searchsorted(v.max()+cutoff),len(wn_grid))\n",
    "        _xsec = np.zeros(shape=(end-start))\n",
    "        for i in range(start,end):\n",
    "            idx = i-start\n",
    "            wn_grid_i = wn_grid[i]\n",
    "            dv = ne.evaluate('wn_grid_i - v')\n",
    "            filter_cutoff = np.abs(dv) <= cutoff\n",
    "            filter = filter_cutoff & filter_threshold\n",
    "            _dv = dv[filter]\n",
    "            if _dv.size > 0:\n",
    "                _alpha = alpha[filter]\n",
    "                _gamma = gamma[filter]\n",
    "                _eta = eta[filter]\n",
    "                _hV = hV[filter]\n",
    "                _coef = coef[filter]\n",
    "                PseudoVoigt = PseudoVoigt_profile(_dv, _alpha, _gamma, _eta, _hV)\n",
    "                _xsec[idx] = ne.evaluate('sum(_coef * PseudoVoigt)')\n",
    "            \n",
    "    xsec[start:end] += _xsec\n",
    "    return (xsec)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_section_BinnedGaussian(wn_grid, v, alpha, coef, cutoff, threshold):\n",
    "    '''\n",
    "    Read ExoMol .states, .trans, .pf and .broad files as the input files.\n",
    "    Return the wavennumbers and cross sections with binned Gaussian profile.\n",
    "    \n",
    "    '''  \n",
    "    xsec = np.zeros_like(wn_grid)\n",
    "    if (cutoff == 'None') & (threshold == 'None'):   \n",
    "        start = max(0,wn_grid.searchsorted(v.min())-1)\n",
    "        end = min(wn_grid.searchsorted(v.max()),len(wn_grid))\n",
    "        _xsec = np.zeros(shape=(end-start))\n",
    "        for i in range(start,end):\n",
    "            idx = i-start\n",
    "            wn_grid_i = wn_grid[i]\n",
    "            dv = ne.evaluate('wn_grid_i - v')\n",
    "            BinnedGaussian = BinnedGaussian_profile(dv, alpha)\n",
    "            _xsec[idx] = ne.evaluate('sum(coef * BinnedGaussian)')\n",
    "    elif (cutoff == 'None') & (threshold != 'None'):            \n",
    "        filter = coef >= threshold\n",
    "        _alpha = alpha[filter]\n",
    "        if _alpha.size > 0:\n",
    "            _coef = coef[filter]\n",
    "            start = max(0,wn_grid.searchsorted(v.min())-1)\n",
    "            end = min(wn_grid.searchsorted(v.max()),len(wn_grid))\n",
    "            _xsec = np.zeros(shape=(end-start))\n",
    "            for i in range(start,end):\n",
    "                idx = i-start\n",
    "                wn_grid_i = wn_grid[i]\n",
    "                _dv = ne.evaluate('wn_grid_i - v')[filter]\n",
    "                BinnedGaussian = BinnedGaussian_profile(_dv, _alpha)\n",
    "                _xsec[idx] = ne.evaluate('sum(_coef * BinnedGaussian)')\n",
    "    elif (cutoff != 'None') & (threshold == 'None'):\n",
    "        start = max(0,wn_grid.searchsorted(v.min()-cutoff)-1)\n",
    "        end = min(wn_grid.searchsorted(v.max()+cutoff),len(wn_grid))\n",
    "        _xsec = np.zeros(shape=(end-start))\n",
    "        for i in range(start,end):\n",
    "            idx = i-start\n",
    "            wn_grid_i = wn_grid[i]\n",
    "            dv = ne.evaluate('wn_grid_i - v')\n",
    "            filter = np.abs(dv) <= cutoff\n",
    "            _dv = dv[filter]\n",
    "            if _dv.size > 0:\n",
    "                _alpha = alpha[filter]\n",
    "                _coef = coef[filter]\n",
    "                BinnedGaussian = BinnedGaussian_profile(_dv, _alpha)\n",
    "                _xsec[idx] = ne.evaluate('sum(_coef * BinnedGaussian)')\n",
    "    else: \n",
    "        filter_threshold = coef >= threshold\n",
    "        start = max(0,wn_grid.searchsorted(v.min()-cutoff)-1)\n",
    "        end = min(wn_grid.searchsorted(v.max()+cutoff),len(wn_grid))\n",
    "        _xsec = np.zeros(shape=(end-start))\n",
    "        for i in range(start,end):\n",
    "            idx = i-start\n",
    "            wn_grid_i = wn_grid[i]\n",
    "            dv = ne.evaluate('wn_grid_i - v')\n",
    "            filter_cutoff = np.abs(dv) <= cutoff\n",
    "            filter = filter_cutoff & filter_threshold\n",
    "            _dv = dv[filter]\n",
    "            if _dv.size > 0:\n",
    "                _alpha = alpha[filter]\n",
    "                _coef = coef[filter]\n",
    "                BinnedGaussian = BinnedGaussian_profile(_dv, _alpha)\n",
    "                _xsec[idx] = ne.evaluate('sum(_coef * BinnedGaussian)')     \n",
    "            \n",
    "    xsec[start:end] += _xsec\n",
    "    xsec = ne.evaluate('xsec/binSize2')\n",
    "    return (xsec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_section_BinnedLorentzian(wn_grid, v, gamma, coef, cutoff, threshold):\n",
    "    '''\n",
    "    Read ExoMol .states, .trans, .pf and .broad files as the input files.\n",
    "    Return the wavennumbers and cross sections with binned Lorentzian profile.\n",
    "    \n",
    "    '''\n",
    "    xsec = np.zeros_like(wn_grid)\n",
    "    if (cutoff == 'None') & (threshold == 'None'):\n",
    "        start = max(0,wn_grid.searchsorted(v.min())-1)\n",
    "        end = min(wn_grid.searchsorted(v.max()),len(wn_grid))\n",
    "        wngrid_start = wn_grid[start]\n",
    "        wngrid_end = wn_grid[end-1]\n",
    "        bnormBinsize = ne.evaluate('1/(arctan((wngrid_end-v)/gamma)-arctan((wngrid_start-v)/gamma))/bin_size')\n",
    "        _xsec = np.zeros(shape=(end-start))\n",
    "        for i in range(start,end):\n",
    "            idx = i-start\n",
    "            wn_grid_i = wn_grid[i]\n",
    "            dv = ne.evaluate('wn_grid_i - v')\n",
    "            BinnedLorentzian = BinnedLorentzian_profile(dv, gamma, bnormBinsize)\n",
    "            _xsec[idx] = ne.evaluate('sum(coef * BinnedLorentzian)')        \n",
    "    elif (cutoff == 'None') & (threshold != 'None'):\n",
    "        filter = coef >= threshold\n",
    "        _gamma = gamma[filter]\n",
    "        if _gamma.size > 0:\n",
    "            _coef = coef[filter] \n",
    "            start = max(0,wn_grid.searchsorted(v.min())-1)\n",
    "            end = min(wn_grid.searchsorted(v.max()),len(wn_grid))\n",
    "            wngrid_start = wn_grid[start]\n",
    "            wngrid_end = wn_grid[end-1]\n",
    "            bnormBinsize = ne.evaluate('1/(arctan((wngrid_end-v)/_gamma)-arctan((wngrid_start-v)/_gamma))/bin_size')\n",
    "            _xsec = np.zeros(shape=(end-start))\n",
    "            for i in range(start,end):\n",
    "                idx = i-start\n",
    "                wn_grid_i = wn_grid[i]\n",
    "                _dv = ne.evaluate('wn_grid_i - v')[filter]\n",
    "                BinnedLorentzian = BinnedLorentzian_profile(_dv, _gamma, bnormBinsize)\n",
    "                _xsec[idx] = ne.evaluate('sum(_coef * BinnedLorentzian)')    \n",
    "    elif (cutoff != 'None') & (threshold == 'None'):\n",
    "        start = max(0,wn_grid.searchsorted(v.min()-cutoff)-1)\n",
    "        end = min(wn_grid.searchsorted(v.max()+cutoff),len(wn_grid))\n",
    "        wngrid_start = wn_grid[start]\n",
    "        wngrid_end = wn_grid[end-1]\n",
    "        bnormBinsize = ne.evaluate('1/(arctan((wngrid_end-v)/gamma)-arctan((wngrid_start-v)/gamma))/bin_size')\n",
    "        _xsec = np.zeros(shape=(end-start))\n",
    "        for i in range(start,end):\n",
    "            idx = i-start\n",
    "            wn_grid_i = wn_grid[i]\n",
    "            dv = ne.evaluate('wn_grid_i - v')\n",
    "            filter = np.abs(dv) <= cutoff\n",
    "            _dv = dv[filter]\n",
    "            if _dv.size > 0:\n",
    "                _gamma = gamma[filter]\n",
    "                _coef = coef[filter]\n",
    "                _bnormBinsize = bnormBinsize[filter]\n",
    "                BinnedLorentzian = BinnedLorentzian_profile(_dv, _gamma, _bnormBinsize)\n",
    "                _xsec[idx] = ne.evaluate('sum(_coef * BinnedLorentzian)')        \n",
    "    else: \n",
    "        filter_threshold = coef >= threshold\n",
    "        start = max(0,wn_grid.searchsorted(v.min()-cutoff)-1)\n",
    "        end = min(wn_grid.searchsorted(v.max()+cutoff),len(wn_grid))\n",
    "        wngrid_start = wn_grid[start]\n",
    "        wngrid_end = wn_grid[end-1]\n",
    "        bnormBinsize = ne.evaluate('1/(arctan((wngrid_end-v)/gamma)-arctan((wngrid_start-v)/gamma))/bin_size')\n",
    "        _xsec = np.zeros(shape=(end-start))\n",
    "        for i in range(start,end):\n",
    "            idx = i-start\n",
    "            wn_grid_i = wn_grid[i]\n",
    "            dv = ne.evaluate('wn_grid_i - v')\n",
    "            filter_cutoff = np.abs(dv) <= cutoff\n",
    "            filter = filter_cutoff & filter_threshold\n",
    "            _dv = dv[filter]\n",
    "            if _dv.size > 0:\n",
    "                _gamma = gamma[filter]\n",
    "                _coef = coef[filter]\n",
    "                _bnormBinsize = bnormBinsize[filter]\n",
    "                BinnedLorentzian = BinnedLorentzian_profile(_dv, _gamma, _bnormBinsize)\n",
    "                _xsec[idx] = ne.evaluate('sum(_coef * BinnedLorentzian)')          \n",
    "            \n",
    "    xsec[start:end] += _xsec\n",
    "    return (xsec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_section_BinnedVoigt(wn_grid, v, sigma, gamma, coef, cutoff, threshold):\n",
    "    '''\n",
    "    Read ExoMol .states, .trans, .pf and .broad files as the input files.\n",
    "    Return the wavennumbers and cross sections with binned Voigt profile.\n",
    "\n",
    "    '''\n",
    "    nquad = 20\n",
    "    roots, weights= roots_hermite(nquad, mu=False)\n",
    "    bnormq = []\n",
    "    xsec = np.zeros_like(wn_grid)\n",
    "    if (cutoff == 'None') & (threshold == 'None'):   \n",
    "        start = max(0,wn_grid.searchsorted(v.min())-1)\n",
    "        end = min(wn_grid.searchsorted(v.max()),len(wn_grid))\n",
    "        wngrid_start = wn_grid[start]\n",
    "        wngrid_end = wn_grid[end-1]\n",
    "        for iquad in range(0, nquad):\n",
    "            xi = roots[iquad]   \n",
    "            bnormq.append(BinnedVoigt_bnormq(wngrid_start, wngrid_end, v, sigma, gamma, xi))\n",
    "        bnormqT =np.transpose(np.array(bnormq))\n",
    "        _xsec = np.zeros(shape=(end-start))                \n",
    "        for i in range(start,end):\n",
    "            idx = i-start\n",
    "            wn_grid_i = wn_grid[i]\n",
    "            dv = ne.evaluate('wn_grid_i - v')\n",
    "            lorenz = []\n",
    "            for iquad in range(0, nquad):\n",
    "                xi = roots[iquad] \n",
    "                lorenz.append(BinnedVoigt_lorenz(dv, sigma, gamma, xi))\n",
    "            lorenzT = np.transpose(np.array(lorenz))  \n",
    "            BinnedVoigtProfile = ne.evaluate('sum(weights*bnormqT*lorenzT)')   \n",
    "            _xsec[idx] = ne.evaluate('sum(coef * BinnedVoigtProfile)')                       \n",
    "    elif (cutoff == 'None') & (threshold != 'None'):\n",
    "        filter = coef >= threshold\n",
    "        _sigma = sigma[filter]\n",
    "        if _sigma.size > 0:\n",
    "            _gamma = gamma[filter]\n",
    "            _coef = coef[filter]\n",
    "            start = max(0,wn_grid.searchsorted(v.min())-1)\n",
    "            end = min(wn_grid.searchsorted(v.max()),len(wn_grid))\n",
    "            wngrid_start = wn_grid[start]\n",
    "            wngrid_end = wn_grid[end-1]\n",
    "            for iquad in range(0, nquad):\n",
    "                xi = roots[iquad]   \n",
    "                bnormq.append(BinnedVoigt_bnormq(wngrid_start, wngrid_end, v, _sigma, _gamma, xi))\n",
    "            bnormqT =np.transpose(np.array(bnormq))\n",
    "            _xsec = np.zeros(shape=(end-start))\n",
    "            for i in range(start,end):\n",
    "                idx = i-start\n",
    "                wn_grid_i = wn_grid[i]\n",
    "                _dv = ne.evaluate('wn_grid_i - v')[filter]\n",
    "                lorenz = []\n",
    "                for iquad in range(0, nquad):\n",
    "                    xi = roots[iquad]  \n",
    "                    lorenz.append(BinnedVoigt_lorenz(_dv, _sigma, _gamma, xi))\n",
    "                lorenzT = np.transpose(np.array(lorenz))  \n",
    "                BinnedVoigtProfile = ne.evaluate('sum(weights*bnormqT*lorenzT)')   \n",
    "                _xsec[idx] = ne.evaluate('sum(_coef * BinnedVoigtProfile)')                    \n",
    "    elif (cutoff != 'None') & (threshold == 'None'):\n",
    "        start = max(0,wn_grid.searchsorted(v.min()-cutoff)-1)\n",
    "        end = min(wn_grid.searchsorted(v.max()+cutoff),len(wn_grid))\n",
    "        wngrid_start = wn_grid[start]\n",
    "        wngrid_end = wn_grid[end-1]\n",
    "        for iquad in range(0, nquad):\n",
    "            xi = roots[iquad]   \n",
    "            bnormq.append(BinnedVoigt_bnormq(wngrid_start, wngrid_end, v, sigma, gamma, xi))\n",
    "        _xsec = np.zeros(shape=(end-start))\n",
    "        for i in range(start,end):\n",
    "            idx = i-start\n",
    "            wn_grid_i = wn_grid[i]\n",
    "            dv = ne.evaluate('wn_grid_i - v')\n",
    "            filter = np.abs(dv) <= cutoff\n",
    "            _dv = dv[filter]\n",
    "            if _dv.size > 0:\n",
    "                _sigma = sigma[filter]\n",
    "                _gamma = gamma[filter]\n",
    "                _coef = coef[filter]\n",
    "                lorenz = []\n",
    "                for iquad in range(0, nquad):\n",
    "                    xi = roots[iquad]  \n",
    "                    lorenz.append(BinnedVoigt_lorenz(_dv, _sigma, _gamma, xi))\n",
    "                bnormqT =np.transpose(np.array([bnormq[i][filter] for i in range(nquad)]))\n",
    "                lorenzT = np.transpose(np.array(lorenz))  \n",
    "                BinnedVoigtProfile = ne.evaluate('sum(weights*bnormqT*lorenzT)')   \n",
    "                _xsec[idx] = ne.evaluate('sum(_coef * BinnedVoigtProfile)')    \n",
    "    else: \n",
    "        filter_threshold = coef >= threshold\n",
    "        start = max(0,wn_grid.searchsorted(v.min()-cutoff)-1)\n",
    "        end = min(wn_grid.searchsorted(v.max()+cutoff),len(wn_grid))\n",
    "        wngrid_start = wn_grid[start]\n",
    "        wngrid_end = wn_grid[end-1]\n",
    "        for iquad in range(0, nquad):\n",
    "            xi = roots[iquad]   \n",
    "            bnormq.append(BinnedVoigt_bnormq(wngrid_start, wngrid_end, v, sigma, gamma, xi))\n",
    "        _xsec = np.zeros(shape=(end-start))\n",
    "        for i in range(start,end):\n",
    "            idx = i-start\n",
    "            wn_grid_i = wn_grid[i]\n",
    "            dv = ne.evaluate('wn_grid_i - v')\n",
    "            filter_cutoff = np.abs(dv) <= cutoff\n",
    "            filter = filter_cutoff & filter_threshold\n",
    "            _dv = dv[filter]\n",
    "            if _dv.size > 0:\n",
    "                _sigma = sigma[filter]\n",
    "                _gamma = gamma[filter]\n",
    "                _coef = coef[filter]\n",
    "                lorenz = []   \n",
    "                for iquad in range(0, nquad):\n",
    "                    xi = roots[iquad]  \n",
    "                    lorenz.append(BinnedVoigt_lorenz(_dv, _sigma, _gamma, xi))\n",
    "                bnormqT =np.transpose(np.array([bnormq[i][filter] for i in range(nquad)]))\n",
    "                lorenzT = np.transpose(np.array(lorenz))  \n",
    "                BinnedVoigtProfile = ne.evaluate('sum(weights*bnormqT*lorenzT)')   \n",
    "                _xsec[idx] = ne.evaluate('sum(_coef * BinnedVoigtProfile)')              \n",
    "    xsec[start:end] += _xsec\n",
    "    xsec = ne.evaluate('xsec*InvbinSizePIhalf')\n",
    "    return (xsec)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot and Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_xsec(wn, xsec, database, profile):\n",
    "    \n",
    "    plots_foldername = save_path+'/xsecs/plots/'+molecule+'/'+database+'/'\n",
    "    if os.path.exists(plots_foldername):\n",
    "        pass\n",
    "    else:\n",
    "        os.makedirs(plots_foldername, exist_ok=True)       \n",
    "    \n",
    "    xsecs_foldername = save_path+'/xsecs/files/'+molecule+'/'+database+'/'\n",
    "    if os.path.exists(xsecs_foldername):\n",
    "        pass\n",
    "    else:\n",
    "        os.makedirs(xsecs_foldername, exist_ok=True)\n",
    "\n",
    "    print('{:25s} : {:<6}'.format('Temperature selected', T), 'K')\n",
    "    print('{:25s} : {:<6}'.format('Pressure selected', P), 'bar')\n",
    "    \n",
    "    '''\n",
    "    wn_xsec = pd.DataFrame()\n",
    "    wn_xsec['v'] = wn\n",
    "    wn_xsec['xsec'] = xsec\n",
    "    wn_xsec = wn_xsec[wn_xsec.replace([np.inf, -np.inf], np.nan).notnull().all(axis=1)]\n",
    "    wn = wn_xsec['v'].values\n",
    "    xsec = wn_xsec['xsec'].values\n",
    "    '''\n",
    "    \n",
    "    #plt.legend(fancybox=True, framealpha=0.0)\n",
    "    parameters = {'axes.labelsize': 14,\n",
    "                'legend.fontsize': 14,\n",
    "                'xtick.labelsize': 12,\n",
    "                'ytick.labelsize': 12}\n",
    "    plt.rcParams.update(parameters)\n",
    "    \n",
    "    if 'L' not in wn_wl:\n",
    "        print('{:25s} : {:<6}'.format('Cutoff is', cutoff), u'cm\\u207B\\u00B9')\n",
    "        print('{:25s} : {:<6}'.format('Threshold is', threshold), u'cm\\u207B\\u00B9/(molecule cm\\u207B\\u00B2)')\n",
    "        print('{:25s} : {} {} {} {}'.format('Wavenumber range selected', min_wn, u'cm\\u207B\\u00B9 -', max_wn, 'cm\\u207B\\u00B9'))\n",
    "        \n",
    "        # Plot cross sections and save it as .png.\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.ylim([1e-30, 10*max(xsec)])\n",
    "        plt.plot(wn, xsec, label='T = '+str(T)+' K, '+profile, linewidth=0.4)\n",
    "        plt.semilogy()\n",
    "        #plt.title(database+' '+molecule+' '+abs_emi+' Cross-Section with '+ profile) \n",
    "        plt.xlabel('Wavenumber, cm$^{-1}$')\n",
    "        plt.ylabel('Cross-section, cm$^{2}$/molecule')\n",
    "        plt.legend()\n",
    "        leg = plt.legend()                  # Get the legend object.\n",
    "        for line in leg.get_lines():\n",
    "            line.set_linewidth(1.0)         # Change the line width for the legend.\n",
    "        plt.savefig(plots_foldername+molecule+'__T'+str(T)+'__'+wn_wl+str(min_wn)+'-'+str(max_wn)+'__'\n",
    "                   +database+'__'+abs_emi+'__'+profile+'.png', dpi=500)\n",
    "        plt.show()\n",
    "        print('Cross sections plot saved.')\n",
    "\n",
    "        # Save cross sections into .xsec file.\n",
    "        xsec_df = pd.DataFrame()\n",
    "        xsec_df['wavenumber'] = wn\n",
    "        xsec_df['cross-section'] = xsec\n",
    "        xsec_filename = (xsecs_foldername+molecule+'__T'+str(T)+'__'+wn_wl+str(min_wn)+'-'+str(max_wn)+'__'\n",
    "                         +database+'__'+abs_emi+'__'+profile+'.xsec')\n",
    "        np.savetxt(xsec_filename, xsec_df, fmt=\"%.06f %20.8e\")\n",
    "        print('Cross sections file saved.')\n",
    "        \n",
    "    elif 'L' in wn_wl:\n",
    "        wl = 10000 / wn\n",
    "        min_wl = '%.02f' % (10000 / max_wn)\n",
    "        max_wl = '%.02f' % (10000 / min_wn)\n",
    "        print('{:25s} : {:<6}'.format('Cutoff is', 10000/cutoff),u'\\xb5m')\n",
    "        print('{:25s} : {:<6}'.format('Threshold is',10000/threshold),u'\\xb5m/(moleculeu \\xb5m\\u00B2)')\n",
    "        print('{:25s} : {} {} {} {}'.format('Wavelength range selected',min_wl,u'\\xb5m -',max_wl,u'\\xb5m'))\n",
    "\n",
    "        # Plot cross sections and save it as .png.\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.ylim([1e-30, 10*max(xsec)])\n",
    "        plt.plot(wl, xsec, label='T = '+str(T)+' K, '+profile, linewidth=0.4)\n",
    "        plt.semilogy()\n",
    "        #plt.title(database+' '+molecule+' '+abs_emi+' Cross-Section with '+ profile) \n",
    "        plt.xlabel(u'Wavelength, \\xb5m')\n",
    "        plt.ylabel(u'Cross-section, \\xb5m\\u207B\\u00B2/molecule')\n",
    "        plt.legend()\n",
    "        leg = plt.legend()                  # Get the legend object.\n",
    "        for line in leg.get_lines():\n",
    "            line.set_linewidth(1.0)         # Change the line width for the legend.\n",
    "        plt.savefig(plots_foldername+molecule+'__T'+str(T)+'__'+wn_wl+str(min_wl)+'-'+str(max_wl)+'__'\n",
    "                    +database+'__'+abs_emi+'__'+profile+'.png', dpi=500)\n",
    "        plt.show()\n",
    "        print('Cross sections plot saved.')\n",
    "        \n",
    "        # Save cross sections into .xsec file.\n",
    "        xsec_df = pd.DataFrame()\n",
    "        xsec_df['wavelength'] = wl\n",
    "        xsec_df['cross-section'] = xsec\n",
    "        xsec_filename = (xsecs_foldername+molecule+'__T'+str(T)+'__'+wn_wl+str(min_wl)+'-'+str(max_wl)+'__'\n",
    "                         +database+'__'+abs_emi+'__'+profile+'.xsec')\n",
    "        np.savetxt(xsec_filename, xsec_df, fmt=\"%.06f %20.8e\")\n",
    "        print('Cross sections file saved.')\n",
    "\n",
    "    else:\n",
    "        print('Please type in correct format: wn or wl.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crosssection(read_path, states_part_df, trans_part_df, hitran_df, ncolumn):\n",
    "    print('Calculate cross-sections.')\n",
    "    t = Timer()\n",
    "    t.start()\n",
    "    # ExoMol or HITRAN\n",
    "    if database == 'EXOMOL':\n",
    "        gamma_air = gamma_self = []\n",
    "        broad, ratio, nbroad, broad_dfs = read_broad(read_path)\n",
    "        Q = read_exomolweb_pf(T)              # Read partition function from the ExoMol website.\n",
    "        # Q = read_exomol_pf(read_path, T)    # Read partition function from local partition function file.\n",
    "        # Absorption or emission cross section\n",
    "        if abs_emi == 'A': \n",
    "            print('Absorption cross section')\n",
    "            A, v, Epp, gp, gamma_L, n_air = linelist_exomol_abs(cutoff,broad,ratio,nbroad,broad_dfs,states_part_df,trans_part_df, ncolumn)\n",
    "            coef = cal_abscoefs(v, gp, A, Epp, Q, abundance)\n",
    "        elif abs_emi == 'E': \n",
    "            print('Emission cross section')\n",
    "            A, v, Ep, gp, gamma_L, n_air = linelist_exomol_emi(cutoff,broad,ratio,nbroad,broad_dfs,states_part_df,trans_part_df, ncolumn)\n",
    "            coef = cal_emicoefs(v, gp, A, Ep, Q, abundance)\n",
    "        else:\n",
    "            raise ImportError(\"Please choose one from: 'Absoption' or 'Emission'.\")         \n",
    "    elif database == 'HITRAN':\n",
    "        gamma_L = []\n",
    "        A, v, Epp, gp, n_air, gamma_air, gamma_self, delta_air = linelist_hitran_abs(hitran_df)\n",
    "        Q = read_hitran_pf(T)\n",
    "        # Absorption or emission cross section\n",
    "        if abs_emi == 'A': \n",
    "            print('Absorption cross section') \n",
    "            coef = cal_abscoefs(v, gp, A, Epp, Q, abundance)\n",
    "        elif abs_emi == 'E': \n",
    "            print('Emission cross section')\n",
    "            Ep = cal_Ep(Epp, v)\n",
    "            coef = cal_emicoefs(v, gp, A, Ep, Q, abundance)\n",
    "        else:\n",
    "            raise ImportError(\"Please choose one from: 'Absoption' or 'Emission'.\") \n",
    "    else:\n",
    "        raise ImportError(\"Please add the name of the database 'ExoMol' or 'HITRAN' into the input file.\")\n",
    "    # Line profile: Gaussion, Lorentzian or Voigt\n",
    "    num_v = len(v)\n",
    "    if 'LOR' not in profile:\n",
    "        alpha = DopplerHWHM_alpha(num_v, alpha_HWHM, v, T)\n",
    "    if 'DOP' not in profile and 'GAU' not in profile:\n",
    "        gamma = LorentzianHWHM_gamma(num_v, gamma_HWHM, broad, gamma_L, n_air, gamma_air, gamma_self, ratios, T, P)\n",
    "    if 'SCI' in profile or 'W' in profile:\n",
    "        sigma = Gaussian_standard_deviation(alpha)     \n",
    "    if 'VOI' in profile and 'BIN' in profile:\n",
    "        sigma = Gaussian_standard_deviation(alpha)  \n",
    "    # Line profiles\n",
    "    if profile[0:3] == 'DOP':\n",
    "        print('Doppler profile')\n",
    "        xsec = cross_section_Doppler(wn_grid, v, alpha, coef, cutoff, threshold)\n",
    "    elif profile[0:3] == 'GAU':\n",
    "        print('Gaussion profile')\n",
    "        xsec = cross_section_Doppler(wn_grid, v, alpha, coef, cutoff, threshold)\n",
    "    elif profile[0:3] == 'LOR':\n",
    "        print('Lorentzian profile')\n",
    "        xsec = cross_section_Lorentzian(wn_grid, v, gamma, coef, cutoff, threshold)\n",
    "    elif 'SCI' in profile and 'W' not in profile:\n",
    "        print('SciPy Voigt profile')\n",
    "        xsec = cross_section_SciPyVoigt(wn_grid, v, sigma, gamma, coef, cutoff, threshold)\n",
    "    elif 'W' in profile:\n",
    "        print('SciPy wofz Voigt profile')\n",
    "        xsec = cross_section_SciPyWofzVoigt(wn_grid, v, sigma, gamma, coef, cutoff, threshold)\n",
    "    elif 'H' in profile:\n",
    "        print('Humlicek Voigt profile')\n",
    "        xsec = cross_section_HumlicekVoigt(wn_grid, v, alpha, gamma, coef, cutoff, threshold)  \n",
    "    elif 'PS' in profile and 'K' not in profile and 'L' not in profile and 'R' not in profile:\n",
    "        print('Pseudo Voigt profile')\n",
    "        eta, hV = PseudoVoigt(alpha, gamma)\n",
    "        xsec = cross_section_PseudoVoigt(wn_grid, v, alpha, gamma, eta, hV, coef, cutoff, threshold)       \n",
    "    elif 'K' in profile and 'H' not in profile:\n",
    "        print('Kielkopf Pseudo Voigt profile')\n",
    "        eta, hV = PseudoKielkopfVoigt(alpha, gamma)\n",
    "        xsec = cross_section_PseudoVoigt(wn_grid, v, alpha, gamma, eta, hV, coef, cutoff, threshold)       \n",
    "    elif 'OL' in profile:\n",
    "        print('Olivero Pseudo Voigt profile')\n",
    "        eta, hV = PseudoOliveroVoigt(alpha, gamma)\n",
    "        xsec = cross_section_PseudoVoigt(wn_grid, v, alpha, gamma, eta, hV, coef, cutoff, threshold)       \n",
    "    elif 'LI' in profile or 'LL' in profile:\n",
    "        print('Liu-Lin Pseudo Voigt profile')\n",
    "        eta, hV = PseudoLiuLinVoigt(alpha, gamma)\n",
    "        xsec = cross_section_PseudoVoigt(wn_grid, v, alpha, gamma, eta, hV, coef, cutoff, threshold)       \n",
    "    elif 'RO' in profile:\n",
    "        print('Rocco Pseudo Voigt profile')\n",
    "        eta, hV = PseudoRoccoVoigt(alpha, gamma)\n",
    "        xsec = cross_section_PseudoVoigt(wn_grid, v, alpha, gamma, eta, hV, coef, cutoff, threshold) \n",
    "    elif 'BIN' in profile and 'DOP' in profile:\n",
    "        print('Binned Doppler profile')\n",
    "        xsec = cross_section_BinnedGaussian(wn_grid, v, alpha, coef, cutoff, threshold)        \n",
    "    elif 'BIN' in profile and 'GAU' in profile:\n",
    "        print('Binned Gaussion profile')\n",
    "        xsec = cross_section_BinnedGaussian(wn_grid, v, alpha, coef, cutoff, threshold)\n",
    "    elif 'BIN' in profile and 'LOR' in profile:\n",
    "        print('Binned Lorentzian profile')\n",
    "        xsec = cross_section_BinnedLorentzian(wn_grid, v, gamma, coef, cutoff, threshold)\n",
    "    elif 'BIN' in profile and 'VOI' in profile:\n",
    "        print('Binned Voigt profile')\n",
    "        xsec = cross_section_BinnedVoigt(wn_grid, v, sigma, gamma, coef, cutoff, threshold)           \n",
    "    else:\n",
    "        raise ImportError('Please choose line profile from the list.')\n",
    "    \n",
    "    if PlotCrossSectionYN == 'Y':\n",
    "        plot_xsec(wn_grid, xsec, database, profile)    \n",
    "    t.end()\n",
    "    pass\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Results\n",
    "def get_results(read_path): \n",
    "    t_tot = Timer()\n",
    "    t_tot.start()  \n",
    "    states_part_df = pd.DataFrame()\n",
    "    trans_part_df = pd.DataFrame() \n",
    "    hitran_df = pd.DataFrame()\n",
    "    # ExoMol or HITRAN\n",
    "    if database == 'EXOMOL':\n",
    "        print('ExoMol database')\n",
    "        # All functions need whole states.\n",
    "        states_df = read_all_states(read_path)\n",
    "        # Only calculating lifetimes and cooling functions need whole transitions.\n",
    "        NeedAllTrans = Lifetimes + CoolingFunctions\n",
    "        if NeedAllTrans != 0: \n",
    "            all_trans_df = read_all_trans(read_path)\n",
    "        # Only calculating stick spectra and cross sections need part of states.\n",
    "        NeedPartStates = StickSpectra + CrossSections\n",
    "        if NeedPartStates != 0:\n",
    "            states_part_df = read_part_states(states_df) \n",
    "        # Conversion and calculating stick spectra and cross sections need part of transitions.\n",
    "        NeedPartTrans = Conversion + StickSpectra + CrossSections\n",
    "        if NeedPartTrans != 0:\n",
    "            (trans_part_df, ncolumn) = read_part_trans(read_path) \n",
    "        # Functions\n",
    "        Nfunctions = (PartitionFunctions + SpecificHeats + Lifetimes + CoolingFunctions \n",
    "                      + Conversion + StickSpectra  + CrossSections)\n",
    "        if Nfunctions > 0:\n",
    "            if PartitionFunctions == 1:\n",
    "                exomol_partition_func(states_df, Ntemp, Tmax)\n",
    "            if SpecificHeats == 1:\n",
    "                exomol_specificheat(states_df, Ntemp, Tmax)\n",
    "            if Lifetimes == 1:\n",
    "                exomol_lifetime(read_path, states_df, all_trans_df)\n",
    "            if CoolingFunctions == 1:\n",
    "                exomol_cooling_func(read_path, states_df, all_trans_df, Ntemp, Tmax)\n",
    "            if (Conversion==1 & ConversionFormat==1):\n",
    "                conversion_exomol2hitran(read_path, states_df, trans_part_df, ncolumn)\n",
    "            if StickSpectra == 1:\n",
    "                exomol_stick_spectra(read_path, states_part_df, trans_part_df, ncolumn, T)\n",
    "            if CrossSections ==1:\n",
    "                get_crosssection(read_path, states_part_df, trans_part_df, hitran_df, ncolumn) \n",
    "        else:   \n",
    "            raise ImportError(\"Please choose functions which you want to calculate.\")\n",
    "    elif database == 'HITRAN':\n",
    "        print('HITRAN database')\n",
    "        parfile_df = read_parfile(read_path)\n",
    "        hitran_df = read_hitran_parfile (read_path, parfile_df).reset_index().drop(columns='index')\n",
    "        if (Conversion==1 & ConversionFormat==2):\n",
    "            conversion_hitran2exomol(hitran_df)\n",
    "        if CrossSections ==1:\n",
    "            ncolumn = 0\n",
    "            get_crosssection(read_path, states_part_df, trans_part_df, hitran_df, ncolumn)\n",
    "    else:\n",
    "        raise ImportError(\"Please add the name of the database 'ExoMol' or 'HITRAN' into the input file.\")     \n",
    "    print('\\nThe program total running time:')    \n",
    "    t_tot.end()\n",
    "    print('\\nFinished!')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_results(read_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('exomol')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "722cf535e3d158a42a418157a233af576121476252bfbc7c5af47c8831a1fc54"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

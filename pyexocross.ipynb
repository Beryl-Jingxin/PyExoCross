{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all what we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding: utf-8\n",
    "import os\n",
    "import bz2\n",
    "import csv\n",
    "import glob\n",
    "import time\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from numba import njit\n",
    "from io import StringIO\n",
    "import matplotlib.pyplot as plt\n",
    "import threading, multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Input File Path and Parameters\n",
    "\n",
    "\n",
    "<table><tr><td bgcolor=skyblue><font size=24> Could be changed ! </font></td></tr></table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################\n",
    "inp_filepath = '/home/jingxin/PyExoCross/input/NO_exomol.inp'\n",
    "read_path = '/mnt/data/exomol/exomol3_data/'\n",
    "save_path = '/home/jingxin/data/pyexocross/'\n",
    "if os.path.exists(save_path):\n",
    "    pass\n",
    "else:\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "ratio = 1.0\n",
    "ratio_air = 0.7\n",
    "ratio_self = 0.3\n",
    "cutoff = 25.0\n",
    "threshold = 1e-30\n",
    "P = 1.0\n",
    "#########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Timer:    \n",
    "    def start(self):\n",
    "        self.start_CPU = time.process_time()\n",
    "        self.start_sys = time.time()\n",
    "        return self\n",
    "\n",
    "    def end(self, *args):\n",
    "        self.end_CPU = time.process_time()\n",
    "        self.end_sys = time.time()\n",
    "        self.interval_CPU = self.end_CPU - self.start_CPU\n",
    "        self.interval_sys = self.end_sys - self.start_sys\n",
    "        print('{:25s} : {}'.format('Running time on CPU', self.interval_CPU), 's')\n",
    "        print('{:25s} : {}'.format('Running time on system', self.interval_sys), 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Information from Input File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inp_para(inp_filepath, N_A):\n",
    "    \n",
    "    inp_col_name = ['c0','c1','c2','c3','c4','c5','c6','c7','c8','c9','c10']\n",
    "    inp_df = pd.read_csv(inp_filepath, sep='\\\\s+', names=inp_col_name, header=None)\n",
    "    col0 = inp_df['c0']\n",
    "    database = inp_df[col0.isin(['Database'])]['c1'].values[0]\n",
    "    molecule = inp_df[col0.isin(['Molecule'])]['c1'].values[0]\n",
    "    isotopologue = inp_df[col0.isin(['Isotopologue'])]['c1'].values\n",
    "    dataset = inp_df[col0.isin(['Dataset'])]['c1'].values\n",
    "    mol_iso_id = int(inp_df[col0.isin(['mol_iso_id'])]['c1'])\n",
    "    T = int(inp_df[col0.isin(['Temperature'])]['c1'])\n",
    "    min_wn = float(inp_df[col0.isin(['Range'])]['c1'])\n",
    "    max_wn = float(inp_df[col0.isin(['Range'])]['c2'])\n",
    "    N_point = int(inp_df[col0.isin(['Npoints'])]['c1'])\n",
    "    abs_emi = inp_df[col0.isin(['AbsorptionOREmission'])]['c1'].values[0]\n",
    "    profile = inp_df[col0.isin(['Profile'])]['c1'].values[0]\n",
    "    wn_wl = inp_df[col0.isin(['Wavenumber(wn)/wavelength(wl)'])]['c1'].values[0]\n",
    "    saveplots = inp_df[col0.isin(['SavePlots'])]['c1'].values[0]\n",
    "    savexsecs = inp_df[col0.isin(['SaveXsecs'])]['c1'].values[0]\n",
    "\n",
    "    molecule_id = int(mol_iso_id/10)\n",
    "    isotopologue_id = mol_iso_id - molecule_id * 10\n",
    "    isometa_url = 'https://hitran.org/docs/iso-meta/'\n",
    "    iso_meta_table = pd.read_html(isometa_url)[molecule_id - 1]\n",
    "    iso_meta_row = iso_meta_table[iso_meta_table['local ID'].isin([isotopologue_id])]\n",
    "    abundance = float(iso_meta_row['Abundance'][0].replace('\\xa0×\\xa010','E'))\n",
    "    \n",
    "    if database == 'ExoMol':\n",
    "        # Read ExoMol definition file (.def) to get the mass.\n",
    "        deffile_path = (read_path+'/'+molecule+'/'+isotopologue+'/'+dataset+'/'+isotopologue+'__'+dataset+'.def')\n",
    "        def_df = pd.read_csv(deffile_path[0],sep='\\\\s+',usecols=[0,1,2,3,4],names=['0','1','2','3','4'],header=None)\n",
    "        mass_exomol = def_df[def_df['4'].isin(['mass'])]['1'].values[0]     # ExoMol mass (kg)\n",
    "        mass = mass_exomol\n",
    "    elif database == 'HITRAN':\n",
    "        mass_hitran = float(iso_meta_row['Molar Mass /g·mol-1'])            # HITRAN molar mass (kg/mol)\n",
    "        mass = mass_hitran / N_A\n",
    "    else:\n",
    "        print('Please add the name of the database ExoMol or HITRAN into the input file.')\n",
    "    \n",
    "\n",
    "    \n",
    "    return database, molecule, isotopologue, dataset, T, min_wn, max_wn, N_point, abs_emi, profile, wn_wl, saveplots, savexsecs, molecule_id, isotopologue_id, abundance, mass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for calculating.\n",
    "import astropy.constants as ac\n",
    "T_ref = 296.0                       # Reference temperature is 296 K.\n",
    "P_ref = 1.0                         # Reference pressure is 1 atm.\n",
    "N_A = ac.N_A.value                  # Avogadro number (1/mol)\n",
    "h = ac.h.to('J s').value            # Planck's const (J s)\n",
    "c = ac.c.to('cm/s').value           # Velocity of light (cm/s)\n",
    "kB = ac.k_B.to('J/K').value         # Boltzmann's const (J/K)\n",
    "R = ac.R.to('J / (K mol)').value    # Gas constant (J/(K mol))\n",
    "c2 = h * c / kB                     # Second radiation constant (cm K)\n",
    "\n",
    "(database, molecule, isotopologue, dataset, T, min_wn, max_wn, N_point, abs_emi, profile, wn_wl, \n",
    "saveplots, savexsecs, molecule_id, isotopologue_id, abundance, mass) = inp_para(inp_filepath, N_A)\n",
    "c2_T = c2 / T                       # c2 / T (cm)\n",
    "c2_T_ref = c2 / T_ref               # c2 / T_ref (cm)\n",
    "pi_c_8 = 1 / (8 * np.pi * c)        # 8 * pi * c (s/cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Input Files\n",
    "\n",
    "Read the parameters of the linelist in ExoMol or HITRAN format text file. Return the dataframe of the data for the following calculations.\n",
    "\n",
    "## Read ExoMol Database Files\n",
    "\n",
    "### Read States File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all_states(read_path):\n",
    "    \n",
    "    s_df = dict()\n",
    "    states_df = pd.DataFrame()\n",
    "    states_filenames = glob.glob((read_path + molecule + '/' + isotopologue + '/' + dataset \n",
    "                                  + '/' + isotopologue + '__' + dataset + '.states.bz2')[0])\n",
    "\n",
    "    for states_filename in states_filenames:\n",
    "        s_df[states_filename] = pd.read_csv(states_filename, compression='bz2', sep='\\s+', header=None,\n",
    "                                            chunksize=100_000_000, iterator=True, low_memory=False)\n",
    "        for chunk in s_df[states_filename]:\n",
    "            states_df = pd.concat([states_df, chunk])\n",
    "            \n",
    "    pd.set_option(\"display.max_columns\",30)                           \n",
    "    return(states_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#read_all_states(read_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read transitions File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transfiles(read_path):\n",
    "    # Get all the transitions files from the folder including the older version files which are named by vn(version number).\n",
    "    trans_filepaths_all = glob.glob((read_path + molecule + '/' + isotopologue + '/' + dataset + '/' + '*trans.bz2')[0])\n",
    "    num_transfiles_all = len(trans_filepaths_all)    # The number of all transitions files including the older version files.\n",
    "    trans_filepaths = []    # The list of the lastest transitions files.\n",
    "    for i in range(num_transfiles_all):\n",
    "        split_version = trans_filepaths_all[i].split('__')[-1].split('.')[0].split('_')    # Split the filenames.\n",
    "        num = len(split_version)\n",
    "        # There are three format filenames.\n",
    "        # The lastest transitions files named in two formats:\n",
    "        # 1. Filenames are named with the name of isotopologue and dataset. \n",
    "        #    End with .trans.bz2.\n",
    "        #    e.g. 14N-16O__XABC.trans.bz2'\n",
    "        # 2. Filenames are named with the name of isotopologue and dataset. \n",
    "        #    Also have the range of wavenumbers xxxxx-yyyyy.\n",
    "        #    End with .trans.bz2.\n",
    "        #    e.g. 1H2-16O__POKAZATEL__00000-00100.trans.bz2\n",
    "        # 3. The older version transitions files are named with vn(version number) based on the first format of the lastest files.\n",
    "        #    e.g. 14N-16O__XABC_v2.trans.bz2\n",
    "        # After split the filenames:\n",
    "        # The first format filenames only leave the dataset name, e.g. XABC.\n",
    "        # The second format filenames only leave the range of the wavenumber, e.g. 00000-00100.\n",
    "        # The third format filenames leave two parts(dataset name and version number), e.g. XABC and v2.\n",
    "        # This program only process the lastest data, so extract the filenames named by the first two format.\n",
    "        if num == 1:        \n",
    "            trans_filepaths.append(trans_filepaths_all[i])\n",
    "    return(trans_filepaths)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all_trans(read_path):\n",
    "    \n",
    "    t_df = dict()\n",
    "    trans_df = pd.DataFrame()\n",
    "    trans_col_name = ['u', 'l', 'A', 'v']\n",
    "    trans_filepaths = get_transfiles(read_path)\n",
    "    #trans_filepaths = glob.glob((read_path + molecule + '/' + isotopologue + '/' + dataset + '/' + '*trans.bz2')[0])\n",
    "\n",
    "    for trans_filename in tqdm(trans_filepaths):\n",
    "        t_df[trans_filename] = pd.read_csv(trans_filename, compression='bz2', sep='\\s+', header=None,\n",
    "                                           names=trans_col_name, chunksize=100_000_000, iterator=True, low_memory=False)\n",
    "        for chunk in t_df[trans_filename]:\n",
    "            trans_df = pd.concat([trans_df,chunk])\n",
    "            \n",
    "    pd.set_option(\"display.max_columns\",30)                           \n",
    "    return(trans_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read_all_trans(read_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Partition Function File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_exomolweb_pf(T_ref, T):\n",
    "    \n",
    "    pf_url = ('http://www.exomol.com/db/' + molecule + '/' + isotopologue + '/' + dataset \n",
    "              + '/' + isotopologue + '__' + dataset + '.pf')[0]\n",
    "    pf_content = requests.get(pf_url).text\n",
    "    pf_col_name = ['T', 'Q']\n",
    "    pf_df = pd.read_csv(StringIO(pf_content), sep='\\\\s+', names=pf_col_name, header=None)\n",
    "    Q_ref = pf_df['Q'][T_ref-1]\n",
    "    Q = pf_df['Q'][T-1]\n",
    "\n",
    "    return(Q_ref, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_exomol_pf(read_path, T_ref, T):\n",
    "    \n",
    "    pf_filename = (read_path + molecule + '/' + isotopologue + '/' + dataset \n",
    "                   + '/' + isotopologue + '__' + dataset + '.pf')[0]\n",
    "    pf_col_name = ['T', 'Q']\n",
    "    pf_df = pd.read_csv(pf_filename, sep='\\\\s+', names=pf_col_name, header=None)\n",
    "    Q_ref = pf_df['Q'][T_ref-1]\n",
    "    Q = pf_df['Q'][T-1]\n",
    "\n",
    "    return(Q_ref, Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Broadening File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_broad(read_path):\n",
    "    \n",
    "    broad_col_name = ['code', 'gamma_L', 'n_air', 'Jpp']\n",
    "    broad_path = (read_path + molecule + '/' + isotopologue + '/' + isotopologue + '__air.broad')[0]\n",
    "    broad_df = pd.read_csv(broad_path, sep='\\s+', names=broad_col_name, header=None, engine='python')\n",
    "    return(broad_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read HITRAN Database Files\n",
    "\n",
    "### Read HITRAN Linelist File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_hitran_parfile (par_filepath, parfile_df):\n",
    "    '''\n",
    "    Read the parameters of the molecular absorption features\n",
    "    of HITRAN2020 format text file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    par_filepath : str\n",
    "        Input file path for reading.\n",
    "    Return\n",
    "    ------\n",
    "    hitran_df : DataFrame\n",
    "        The DataFrame of HITRAN data for the molecule.\n",
    "    '''    \n",
    "    par_filename = par_filepath.split('/')[3]\n",
    "    \n",
    "    if not os.path.exists:\n",
    "        raise ImportError('The input file ' + par_filename + ' does not exist.')\n",
    "\n",
    "    if (len(str(parfile_df[0][0])) < 160):\n",
    "        raise ImportError('The file ' + par_filename + ' is not a HITRAN2016 format data file.')\n",
    "    #hitran_column_name = ['M','I','v','S','Acoeff','gamma_air','gamma_self',\n",
    "    #                     'Epp','n_air','delta_air','Vp','Vpp','Qp','Qpp',\n",
    "    #                     'Ierr','Iref','flag','gp','gpp']\n",
    "\n",
    "    hitran_df = pd.DataFrame()\n",
    "    hitran_df['M'] = pd.to_numeric(parfile_df[0].map(lambda x: x[0:2]), errors='coerce').astype('int32')                 # Molecule identification number\n",
    "    hitran_df['I'] = pd.to_numeric(parfile_df[0].map(lambda x: x[2:3]), errors='coerce').astype('int32')                 # Isotopologue number\n",
    "    hitran_df['v'] = pd.to_numeric(parfile_df[0].map(lambda x: x[3:15]), errors='coerce').astype('float64')              # Transition wavenumber (in cm^{-1})\n",
    "    hitran_df['S'] = pd.to_numeric(parfile_df[0].map(lambda x: x[15:25]), errors='coerce').astype('float64')             # Intensity (cm^{-1} / (molecule cm^{-2}))\n",
    "    hitran_df['A'] = pd.to_numeric(parfile_df[0].map(lambda x: x[25:35]), errors='coerce').astype('float64')             # Einstein A-coefficient (in s^{-1})\n",
    "    hitran_df['gamma_air'] = pd.to_numeric(parfile_df[0].map(lambda x: x[35:40]), errors='coerce').astype('float64')     # Air-broadened half-width at half maximum (HWHM) coefficient (cm^{-1} atm^{-1})\n",
    "    hitran_df['gamma_self'] = pd.to_numeric(parfile_df[0].map(lambda x: x[40:45]), errors='coerce').astype('float64')    # Self-broadened half-width at half maximum (HWHM) coefficient (cm^{-1} atm^{-1})\n",
    "    hitran_df['Epp'] = pd.to_numeric(parfile_df[0].map(lambda x: x[45:55]), errors='coerce').astype('float64')           # Lower state energy (cm^{-1})\n",
    "    hitran_df['n_air'] = pd.to_numeric(parfile_df[0].map(lambda x: x[55:59]), errors='coerce').astype('float64')         # Temperature-dependent exponent for gamma_air\n",
    "    #hitran_df['delta_air'] = pd.to_numeric(parfile_df[0].map(lambda x: x[59:67]), errors='coerce').astype('float64')     # Air pressure_include line shift (cm^{-1} atm^{-1})\n",
    "    #hitran_df['gp'] = pd.to_numeric(parfile_df[0].map(lambda x: x[146:153]), errors='coerce').astype('float64')        # Statistical weight of the upper state\n",
    "    #hitran_df['gpp'] = pd.to_numeric(parfile_df[0].map(lambda x: x[153:160]), errors='coerce').astype('float64')        # Statistical weight of the lower state\n",
    "\n",
    "    hitran_df = hitran_df[hitran_df['M'].isin([molecule_id])]\n",
    "    hitran_df = hitran_df[hitran_df['I'].isin([isotopologue_id])]\n",
    "    hitran_df = hitran_df[hitran_df['v'].between(min_wn, max_wn)]\n",
    "    hitran_df = hitran_df[hitran_df['S'] > threshold]\n",
    "    \n",
    "    return hitran_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Partition Function File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_hitran_pf(T):\n",
    "    \n",
    "    isometa_url = 'https://hitran.org/docs/iso-meta/'\n",
    "    iso_meta_table = pd.read_html(isometa_url)[molecule_id - 1]\n",
    "    iso_meta_row = iso_meta_table[iso_meta_table['local ID'].isin([isotopologue_id])]\n",
    "    Q_ref = float(iso_meta_row.loc[0][6].replace('\\xa0×\\xa010','E'))\n",
    "    Q_url = 'https://hitran.org/data/Q/' + iso_meta_row.loc[0][7]\n",
    "    Q_content = requests.get(Q_url).text\n",
    "    Q_col_name = ['T', 'Q']\n",
    "    Q_df = pd.read_csv(StringIO(Q_content), sep='\\\\s+', names=Q_col_name, header=None)\n",
    "    Q = Q_df['Q'][T - 1]   \n",
    "    return(Q_ref, Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Parition Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_partition(E, g, T):\n",
    "    partition_func = np.sum(g * np.exp(-c2 * E / T))\n",
    "    return(partition_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partition function\n",
    "def exomol_partition_func(read_path, Ntemp, Tmax):\n",
    "    \n",
    "    states_df = read_all_states(read_path)\n",
    "    E = states_df[1]\n",
    "    g = states_df[2]\n",
    "    pf_list = []\n",
    "\n",
    "    for T in tqdm(range(Ntemp, Tmax+1, Ntemp)):\n",
    "        partition_func = calculate_partition(E, g, T)\n",
    "        pf_list.append(str(format(T, '8.1f') + ' ' + format(partition_func, '15.4f')))\n",
    "        \n",
    "    pf_folder = save_path + '/partition/'\n",
    "    if os.path.exists(pf_folder):\n",
    "        pass\n",
    "    else:\n",
    "        os.makedirs(pf_folder, exist_ok=True)\n",
    "    pf_path = (pf_folder + isotopologue + '__' + dataset + '.pf')[0]\n",
    " \n",
    "    with open(pf_path, 'w') as pf_file:\n",
    "        for pf in pf_list:\n",
    "            pf_file.write(pf + '\\n')\n",
    "        pf_file.close()\n",
    "\n",
    "    print('Partition function has been saved!')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:03<00:00, 1378.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partition function has been saved!\n",
      "Running time on CPU       : 3.786006424 s\n",
      "Running time on system    : 3.7964038848876953 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Ntemp = 1\n",
    "Tmax = int(5000.00)\n",
    "t = Timer()\n",
    "t.start()\n",
    "exomol_partition_func(read_path, Ntemp, Tmax)\n",
    "t.end()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Cooling Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_linelist(read_path):\n",
    "    states_df = read_all_states(read_path)\n",
    "    trans_df = read_all_trans(read_path)\n",
    "    \n",
    "    id_u = trans_df['u'].values\n",
    "    states_df.set_index([0], inplace=True, drop=False)\n",
    "    states_u_df = states_df.loc[id_u]\n",
    "    linelist_df = pd.DataFrame()\n",
    "    linelist_df['u'] = trans_df['u']\n",
    "    linelist_df['l'] = trans_df['l']\n",
    "    linelist_df['A'] = trans_df['A']\n",
    "    linelist_df['v'] = trans_df['v']\n",
    "    linelist_df['Ep'] = states_u_df[1].values\n",
    "    linelist_df['gp'] = states_u_df[2].values\n",
    "    \n",
    "    return linelist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_linelist_df = all_linelist(read_path)\n",
    "#all_linelist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel=True, fastmath=True)\n",
    "def calculate_cooling(A, v, Ep, gp, T, Q):\n",
    "    cooling_func = np.sum(A * h * c * v * gp * np.exp(-c2 * Ep / T)) / (4 * np.pi * Q) * 1e7\n",
    "    return(cooling_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cooling function\n",
    "def exomol_cooling_func(read_path, Ntemp, Tmax):\n",
    "    \n",
    "    linelist_df = all_linelist(read_path)\n",
    "    A = linelist_df['A'].values\n",
    "    v = linelist_df['v'].values\n",
    "    Ep = linelist_df['Ep'].values      # Lower state energy\n",
    "    gp = linelist_df['gp'].values      # Total degeneracy of lower state \n",
    "    cf_list = []\n",
    "    \n",
    "    for T in tqdm(range(Ntemp, Tmax+1, Ntemp)):\n",
    "        Q_ref, Q = read_exomol_pf(read_path, T_ref, T)\n",
    "        cooling_func = calculate_cooling(A, v, Ep, gp, T, Q)\n",
    "        cf_list.append(str(format(T, '8.1f') + ' ' + format(cooling_func, '20.8E')))\n",
    "\n",
    "    cf_folder = save_path + '/cooling/'\n",
    "    if os.path.exists(cf_folder):\n",
    "        pass\n",
    "    else:\n",
    "        os.makedirs(cf_folder, exist_ok=True)  \n",
    "    cf_path = (cf_folder + isotopologue + '__' + dataset + '.cooling')[0]\n",
    "    \n",
    "    with open(cf_path, 'w') as cf_file:\n",
    "        for cf in cf_list:\n",
    "            cf_file.write(cf + '\\n')\n",
    "        cf_file.close()\n",
    "\n",
    "    print('Cooling function has been saved!')   \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:10<00:00, 10.57s/it]\n",
      "  0%|          | 0/500 [00:00<?, ?it/s]OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n",
      "100%|██████████| 500/500 [00:03<00:00, 152.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cooling function has been saved!\n",
      "Running time on CPU       : 521.90417973 s\n",
      "Running time on system    : 16.756798028945923 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Ntemp = 1\n",
    "Tmax = int(500.00)\n",
    "t = Timer()\n",
    "t.start()\n",
    "exomol_cooling_func(read_path, Ntemp, Tmax)\n",
    "t.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lifetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lifetime\n",
    "def exomol_lifetime(read_path):\n",
    "    \n",
    "    states_df = read_all_states(read_path)\n",
    "    trans_df = read_all_trans(read_path)\n",
    "    sum_A = trans_df.groupby('u')['A'].sum()\n",
    "    lifetime = 1 / sum_A\n",
    "    lt_df = lifetime.map('{: >12.4E}'.format).reset_index()\n",
    "    states_trans_df = pd.concat([states_df[0], lt_df['u']])\n",
    "    states_trans_df = states_trans_df.drop_duplicates(keep=False)\n",
    "    add_u = pd.DataFrame()\n",
    "    add_u['u'] = states_trans_df\n",
    "    add_u['A'] = '  Inf       '\n",
    "    lifetime_df = pd.concat([lt_df, add_u], ignore_index=True)\n",
    "    lifetime_df.sort_values('u',inplace=True)\n",
    "    \n",
    "    lf_folder = save_path + '/lifetime/'\n",
    "    if os.path.exists(lf_folder):\n",
    "        pass\n",
    "    else:\n",
    "        os.makedirs(lf_folder, exist_ok=True)  \n",
    "    lf_path = (lf_folder + isotopologue + '__' + dataset + '.life')[0]\n",
    "    lifetime_df['A'].to_csv(lf_path, header=None, index=False, chunksize = 1000)\n",
    "\n",
    "    print('lifetime has been saved!')   \n",
    "    return(lifetime_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:11<00:00, 11.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lifetime has been saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30810</th>\n",
       "      <td>1</td>\n",
       "      <td>Inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>8.3086E-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4.2467E-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2.8936E-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2.2179E-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30805</th>\n",
       "      <td>30807</td>\n",
       "      <td>2.2635E+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30806</th>\n",
       "      <td>30808</td>\n",
       "      <td>2.2595E+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30807</th>\n",
       "      <td>30809</td>\n",
       "      <td>2.1400E+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30808</th>\n",
       "      <td>30810</td>\n",
       "      <td>2.2604E+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30809</th>\n",
       "      <td>30811</td>\n",
       "      <td>2.1389E+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30811 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           u             A\n",
       "30810      1    Inf       \n",
       "0          2    8.3086E-02\n",
       "1          3    4.2467E-02\n",
       "2          4    2.8936E-02\n",
       "3          5    2.2179E-02\n",
       "...      ...           ...\n",
       "30805  30807    2.2635E+00\n",
       "30806  30808    2.2595E+00\n",
       "30807  30809    2.1400E+00\n",
       "30808  30810    2.2604E+00\n",
       "30809  30811    2.1389E+00\n",
       "\n",
       "[30811 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exomol_lifetime(read_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specific Heat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel=True, fastmath=True)\n",
    "def calculate_specific_heat(E, g, T):\n",
    "    pf = np.sum(g * np.exp(-c2 * E / T))  \n",
    "    pfp = np.sum(g * np.exp(-c2 * E / T) * (c2 * E / T))\n",
    "    pfpp = np.sum(g * np.exp(-c2 * E / T) * (c2 * E / T) ** 2)\n",
    "    specificheat_func = R * (pfpp / pf - (pfp / pf) ** 2) + 2.5 * R\n",
    "    return(specificheat_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specific heat\n",
    "def exomol_specificheat_func(read_path, Ntemp, Tmax):\n",
    "\n",
    "    states_df = read_all_states(read_path)\n",
    "    E = states_df[1].values\n",
    "    g = states_df[2].values\n",
    "    cp_list = []\n",
    "    \n",
    "    for T in tqdm(range(200, Tmax+1, Ntemp)):\n",
    "        specificheat_func = calculate_specific_heat(E, g, T)\n",
    "        cp_list.append(str(format(T, '8.1f') + ' ' + format(specificheat_func, '15.4f')))\n",
    "        \n",
    "    cp_folder = save_path + '/specific_heat/'\n",
    "    if os.path.exists(cp_folder):\n",
    "        pass\n",
    "    else:\n",
    "        os.makedirs(cp_folder, exist_ok=True)  \n",
    "    cp_path = (cp_folder + isotopologue + '__' + dataset + '.cp')[0]\n",
    " \n",
    "    with open(cp_path, 'w') as cp_file:\n",
    "        for cp in cp_list:\n",
    "            cp_file.write(cp + '\\n')\n",
    "        cp_file.close()\n",
    "\n",
    "    print('Specific heat has been saved!')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4801/4801 [00:01<00:00, 2645.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specific heat has been saved!\n",
      "Running time on CPU       : 199.8381291620001 s\n",
      "Running time on system    : 1.977797031402588 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Ntemp = 1\n",
    "Tmax = int(5000.0)\n",
    "t = Timer()\n",
    "t.start()\n",
    "exomol_specificheat_func(read_path, Ntemp, Tmax)\n",
    "t.end()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Line Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel=True, fastmath=True)\n",
    "def Doppler_HWHM (v, mass, T):\n",
    "    '''Return the Doppler half-width at half-maximum (HWHM) -- alpha.'''\n",
    "    alpha = np.sqrt(2 * kB * T * np.log(2) / mass) * v / c\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel=True, fastmath=True)\n",
    "def Lorentzian_HWHM (T, P, n_air, gamma_L):\n",
    "    '''Return the Lorentzian half-width at half-maximum (HWHM) -- gamma.'''\n",
    "    gamma = gamma_L * ratio * (T_ref / T)**n_air * (P / P_ref)\n",
    "    \n",
    "    return gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel=True, fastmath=True)\n",
    "def Gaussian_FWHM (alpha):\n",
    "    f_G = 2 * alpha * np.sqrt(2 * np.log(2))\n",
    "    return(f_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel=True, fastmath=True)\n",
    "def Lorentzian_FWHM (gamma):\n",
    "    f_L = 2 * gamma\n",
    "    return(f_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel=True, fastmath=True)\n",
    "def Gaussian_profile(dv, alpha):\n",
    "    '''Return Gaussian line profile at dv with HWHM alpha.'''\n",
    "    alpha = alpha * 2\n",
    "    Gaussian_profile = np.sqrt(np.log(2) / np.pi) / alpha * np.exp(-np.log(2) * (dv / alpha)**2)\n",
    "    return Gaussian_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel=True, fastmath=True)\n",
    "def Lorentzian_profile(dv, gamma):\n",
    "    '''Return Lorentzian line profile at dv with HWHM gamma.'''\n",
    "    #gamma = gamma * 2\n",
    "    Lorentzian_profile = gamma / np.pi / (dv**2 + gamma**2)\n",
    "    return Lorentzian_profile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scipy_Voigt_profile(dv, alpha, gamma):\n",
    "    '''Return the Voigt line profile with Lorentzian component HWHM gamma and Gaussian component HWHM alpha.'''\n",
    "    from scipy.special import voigt_profile\n",
    "    return voigt_profile(dv, alpha, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scipy_wofz_Voigt_profile(dv, alpha, gamma):\n",
    "    '''Return the Voigt line profile with Lorentzian component HWHM gamma and Gaussian component HWHM alpha.'''\n",
    "    from scipy.special import wofz\n",
    "    sigma = alpha / np.sqrt(2 * np.log(2))\n",
    "    scipy_wofz_Voigt_profile = np.real(wofz((dv + 1j*gamma)/sigma/np.sqrt(2))) / sigma / np.sqrt(2*np.pi)\n",
    "    return scipy_wofz_Voigt_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel=True, fastmath=True)\n",
    "def width_Voigt_profile(f_G, f_L):\n",
    "    '''\n",
    "    Return the full width at half maximum (FWHM) of the Voigt profile which can\n",
    "    be found from the widths of the associated Gaussian and Lorentzian widths.\n",
    "\n",
    "    '''\n",
    "    width_Voigt_profile = 0.5346 * f_L + np.sqrt(0.2166 * f_L**2 + f_G**2)\n",
    "    return width_Voigt_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel=True, fastmath=True)\n",
    "def pseudo_Voigt_profile(f_G, f_L):\n",
    "    '''Return the Voigt line profile with Lorentzian component HWHM gamma and Gaussian component HWHM alpha.'''\n",
    "    pseudo_Voigt_profile = (f_G**5+2.69269*f_G**4*f_L+2.42843*f_G**3*f_L**2+4.47163*f_G**2*f_L**3+0.07842*f_G*f_L**4+f_L**5)**0.2\n",
    "    return pseudo_Voigt_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel=True, fastmath=True)\n",
    "def pseudo_Voigt_FWHM_profile(dv, alpha, gamma):\n",
    "    '''\n",
    "    Return the Voigt line profile with Lorentzian component HWHM gamma and Gaussian component HWHM alpha.\n",
    "    f is the total FWHM parameter.\n",
    "    n is a function of Lorentz (f_L), Gaussian (f_G) and total (f) full width at half maximum (FWHM) parameters.\n",
    "    \n",
    "    '''\n",
    "    f_G = 2 * alpha * np.sqrt(2 * np.log(2))\n",
    "    f_L = 2 * gamma\n",
    "    f = (f_G**5 + 2.69269*f_G**4*f_L + 2.42843*f_G**3*f_L**2 + 4.47163*f_G**2*f_L**3 + 0.07842*f_G*f_L**4 + f_L**5)**0.2\n",
    "    n = 1.36603*(f_L/f) - 0.47719*(f_L/f)**2 + 0.11116*(f_L/f)**3\n",
    "    pseudo_fwhm_Voigt_profile = n*Lorentzian_profile(dv,f/2) + (1-n)*Gaussian_profile(dv,f/2)\n",
    "    return pseudo_fwhm_Voigt_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel=True, fastmath=True)\n",
    "def pseudo_Voigt_FWHM_profile(dv, f_G, f_L):\n",
    "    '''\n",
    "    Return the Voigt line profile with Lorentzian component HWHM gamma and Gaussian component HWHM alpha.\n",
    "    f is the total FWHM parameter.\n",
    "    n is a function of Lorentz (f_L), Gaussian (f_G) and total (f) full width at half maximum (FWHM) parameters.\n",
    "    \n",
    "    '''\n",
    "    f = (f_G**5 + 2.69269*f_G**4*f_L + 2.42843*f_G**3*f_L**2 + 4.47163*f_G**2*f_L**3 + 0.07842*f_G*f_L**4 + f_L**5)**0.2\n",
    "    n = 1.36603*(f_L/f) - 0.47719*(f_L/f)**2 + 0.11116*(f_L/f)**3\n",
    "    pseudo_fwhm_Voigt_profile = n*Lorentzian_profile(dv,f/2) + (1-n)*Gaussian_profile(dv,f/2)\n",
    "    return pseudo_fwhm_Voigt_profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Cross Sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel=True, fastmath=True)\n",
    "def cal_abscoefs(v, gp, A, Epp, Q, abundance):\n",
    "    abscoef = gp * A * np.exp(- c2_T * Epp) * (1 - np.exp(- c2_T * v)) * pi_c_8 / (v ** 2) / Q * abundance   \n",
    "    return (abscoef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel=True, fastmath=True)\n",
    "def cal_emicoefs(v, gp, A, Ep, Q, abundance):\n",
    "    emicoef = gp * A * v * np.exp(- c2_T * Ep) / (4 * np.pi * Q) * abundance   \n",
    "    return (emicoef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exomol_cross_section_Gaussian(wn_grid, v, alpha, coef):\n",
    "    '''\n",
    "    Read ExoMol .states, .trans, .pf and .broad files as the input files.\n",
    "    Return the wavennumbers and cross sections with Gaussian profile.\n",
    "    \n",
    "    '''\n",
    "    xsec_g = np.zeros_like(wn_grid)\n",
    "    _xsec_g = np.zeros_like(wn_grid)\n",
    "    \n",
    "    for i in range(N_point):\n",
    "        dv = wn_grid[i] - v\n",
    "        filter_cutoff = np.abs(dv) <=cutoff\n",
    "        _dv = np.array(dv[filter_cutoff])\n",
    "        _alpha = np.array(alpha[filter_cutoff])\n",
    "        _coef = coef[filter_cutoff]\n",
    "        _xsec_g[i] = np.sum(_coef * Gaussian_profile(_dv, _alpha))        \n",
    "\n",
    "    xsec_g[0:N_point] += _xsec_g\n",
    "    return (xsec_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exomol_cross_section_Lorentzian(wn_grid, v, gamma, coef):\n",
    "    '''\n",
    "    Read ExoMol .states, .trans, .pf and .broad files as the input files.\n",
    "    Return the wavennumbers and cross sections with Lorentzian profile.\n",
    "    \n",
    "    '''\n",
    "    xsec_l = np.zeros_like(wn_grid)\n",
    "    _xsec_l = np.zeros_like(wn_grid)\n",
    "    \n",
    "    for i in range(N_point):\n",
    "        dv = wn_grid[i] - v\n",
    "        filter_cutoff = np.abs(dv) <=cutoff\n",
    "        _dv = np.array(dv[filter_cutoff])\n",
    "        _gamma = np.array(gamma[filter_cutoff])\n",
    "        _coef = coef[filter_cutoff]\n",
    "        _xsec_l[i] = np.sum(_coef * Lorentzian_profile(_dv, _gamma))        \n",
    "\n",
    "    xsec_l[0:N_point] += _xsec_l\n",
    "    return (xsec_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exomol_cross_section_scipy_Voigt(wn_grid, v, alpha, gamma, coef):\n",
    "    '''\n",
    "    Read ExoMol .states, .trans, .pf and .broad files as the input files.\n",
    "    Return the wavennumbers and cross sections with scipy Voigt profile.\n",
    "    \n",
    "    '''\n",
    "    xsec_sv = np.zeros_like(wn_grid)\n",
    "    _xsec_sv = np.zeros_like(wn_grid)\n",
    "\n",
    "    for i in range(N_point):\n",
    "        dv = wn_grid[i] - v\n",
    "        filter_cutoff = np.abs(dv) <=cutoff\n",
    "        _dv = dv[filter_cutoff]\n",
    "        _alpha = alpha[filter_cutoff]\n",
    "        _gamma = gamma[filter_cutoff]\n",
    "        _coef = coef[filter_cutoff]\n",
    "        _xsec_sv[i] = np.sum(_coef * scipy_Voigt_profile(_dv, _alpha, _gamma))\n",
    "\n",
    "    xsec_sv[0:N_point] += _xsec_sv\n",
    "    return (xsec_sv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exomol_cross_section_scipy_wofz_Voigt(wn_grid, v, alpha, gamma, coef):\n",
    "    '''\n",
    "    Read ExoMol .states, .trans, .pf and .broad files as the input files.\n",
    "    Return the wavennumbers and cross sections with wofz Voigt profile.\n",
    "\n",
    "    '''\n",
    "    xsec_swv = np.zeros_like(wn_grid)\n",
    "    _xsec_swv = np.zeros_like(wn_grid)\n",
    "\n",
    "    for i in range(N_point):\n",
    "        dv = wn_grid[i] - v\n",
    "        filter_cutoff = np.abs(dv) <=cutoff\n",
    "        _dv = dv[filter_cutoff]\n",
    "        _alpha = alpha[filter_cutoff]\n",
    "        _gamma = gamma[filter_cutoff]\n",
    "        _coef = coef[filter_cutoff]\n",
    "        _xsec_swv[i] = np.sum(_coef * scipy_wofz_Voigt_profile(_dv, _alpha, _gamma))\n",
    "\n",
    "    xsec_swv[0:N_point] += _xsec_swv\n",
    "    return (xsec_swv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exomol_cross_section_width_Voigt(wn_grid, v, alpha, gamma, coef):\n",
    "    '''\n",
    "    Read ExoMol .states, .trans, .pf and .broad files as the input files.\n",
    "    Return the wavennumbers and cross sections with width Voigt profile.\n",
    "\n",
    "    '''\n",
    "    xsec_wv = np.zeros_like(wn_grid)\n",
    "    _xsec_wv = np.zeros_like(wn_grid)\n",
    "\n",
    "    for i in range(N_point):\n",
    "        dv = wn_grid[i] - v\n",
    "        filter_cutoff = np.abs(dv) <=cutoff\n",
    "        _dv = dv[filter_cutoff]\n",
    "        _alpha = alpha[filter_cutoff]\n",
    "        _gamma = gamma[filter_cutoff]\n",
    "        f_G = Gaussian_profile(_dv, _alpha)\n",
    "        f_L = Lorentzian_profile(_dv, _gamma)\n",
    "        _coef = coef[filter_cutoff]\n",
    "        _xsec_wv[i] = np.sum(_coef * width_Voigt_profile(f_G, f_L))\n",
    "\n",
    "    xsec_wv[0:N_point] += _xsec_wv\n",
    "    return (xsec_wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exomol_cross_section_pseudo_Voigt(wn_grid, v, alpha, gamma, coef):\n",
    "    '''\n",
    "    Read ExoMol .states, .trans, .pf and .broad files as the input files.\n",
    "    Return the wavennumbers and cross sections with width Voigt profile.\n",
    "\n",
    "    '''\n",
    "    xsec_pv = np.zeros_like(wn_grid)\n",
    "    _xsec_pv = np.zeros_like(wn_grid)\n",
    "\n",
    "    for i in range(N_point):\n",
    "        dv = wn_grid[i] - v\n",
    "        filter_cutoff = np.abs(dv) <=cutoff\n",
    "        _dv = dv[filter_cutoff]\n",
    "        _alpha = alpha[filter_cutoff]\n",
    "        _gamma = gamma[filter_cutoff]\n",
    "        f_G = Gaussian_profile(_dv, _alpha)\n",
    "        f_L = Lorentzian_profile(_dv, _gamma)\n",
    "        _coef = coef[filter_cutoff]\n",
    "        _xsec_pv[i] = np.sum(_coef * pseudo_Voigt_profile(f_G, f_L))\n",
    "\n",
    "    xsec_pv[0:N_point] += _xsec_pv\n",
    "    return (xsec_pv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exomol_cross_section_pseudo_FWHM_Voigt(wn_grid, v, alpha, gamma, coef):\n",
    "    '''\n",
    "    Read ExoMol .states, .trans, .pf and .broad files as the input files.\n",
    "    Return the wavennumbers and cross sections with width Voigt profile.\n",
    "\n",
    "    '''\n",
    "    xsec_pfv = np.zeros_like(wn_grid)\n",
    "    _xsec_pfv = np.zeros_like(wn_grid)\n",
    "\n",
    "    for i in range(N_point):\n",
    "        dv = wn_grid[i] - v\n",
    "        filter_cutoff = np.abs(dv) <=cutoff\n",
    "        _dv = dv[filter_cutoff]\n",
    "        _alpha = alpha[filter_cutoff]\n",
    "        _gamma = gamma[filter_cutoff]\n",
    "        f_G = Gaussian_FWHM(_alpha)\n",
    "        f_L = Lorentzian_FWHM(_gamma)\n",
    "        _coef = coef[filter_cutoff]\n",
    "        _xsec_pfv[i] = np.sum(_coef * pseudo_Voigt_FWHM_profile(_dv, f_G, f_L))\n",
    "\n",
    "    xsec_pfv[0:N_point] += _xsec_pfv\n",
    "    return (xsec_pfv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot and Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_xsec(wn, xsec, database, profile):\n",
    "    print('{:25s} : {}'.format('Air broading is', ratio_air))\n",
    "    print('{:25s} : {}'.format('Self broading is', ratio_self))\n",
    "    print('{:25s} : {:<6}'.format('Temperature selected', T), 'K')\n",
    "    print('{:25s} : {:<6}'.format('Pressure selected', P), 'bar')\n",
    "    if (wn_wl == 'wn'):\n",
    "        print('{:25s} : {:<6}'.format('Cutoff is', cutoff), 'cm-1')\n",
    "        print('{:25s} : {:<6}'.format('Threshold is', threshold), 'cm-1/(molecule cm-2)')\n",
    "        print('{:25s} : {} {} {} {}'.format('Wavenumber range selected', min_wn, 'cm-1 -', max_wn, 'cm-1'))\n",
    "        \n",
    "        # Plot cross sections and save it as .png.\n",
    "        plt.plot(wn, xsec, label='T = '+str(T)+' K, '+profile)\n",
    "        plt.title(database+' '+molecule+' '+abs_emi+' Cross-Section with '+ profile) \n",
    "        plt.xlabel('Wavenumber, cm$^{-1}$')\n",
    "        plt.ylabel('Cross-section, cm$^{2}$/molecule')\n",
    "        plt.legend()\n",
    "        plots_foldername = saveplots+molecule+'/'\n",
    "        if os.path.exists(plots_foldername):\n",
    "            pass\n",
    "        else:\n",
    "            os.makedirs(plots_foldername, exist_ok=True)    \n",
    "        plt.savefig(plots_foldername+molecule+'__T'+str(T)+'__'+str(min_wn)+'-'+str(max_wn)+'cm-1__'\n",
    "                    +database+'__'+abs_emi+'__'+profile+'.png', dpi=500)\n",
    "        plt.show()\n",
    "        print('Cross sections plot saved.')\n",
    "\n",
    "        # Save cross sections into .xsec file.\n",
    "        xsec_df = pd.DataFrame()\n",
    "        xsec_df['wavenumber'] = wn\n",
    "        xsec_df['cross-section'] = xsec\n",
    "        xsecs_foldername = savexsecs+molecule+'/'\n",
    "        if os.path.exists(xsecs_foldername):\n",
    "            pass\n",
    "        else:\n",
    "            os.makedirs(xsecs_foldername, exist_ok=True)\n",
    "        xsec_filename = (xsecs_foldername+molecule+'__T'+str(T)+'__'+str(min_wn)+'-'+str(max_wn)+'cm-1__'\n",
    "                         +database+'__'+abs_emi+'__'+profile+'.xsec')\n",
    "        np.savetxt(xsec_filename, np.vstack((wn,xsec)).T)\n",
    "        print('Cross sections file saved.')\n",
    "        \n",
    "    elif wn_wl == 'wl':\n",
    "        wl = 10**7 / wn\n",
    "        min_wl = 10**7 / min_wn\n",
    "        max_wl = 10**7 / max_wn\n",
    "        print('{:25s} : {:<6}'.format('Cutoff is', 10**7 / cutoff), 'nm')\n",
    "        print('{:25s} : {:<6}'.format('Threshold is', 10**7 / threshold), 'nm/(molecule nm2)')\n",
    "        print('{:25s} : {} {} {} {}'.format('Wavelength range selected', min_wl, 'nm -', max_wl, 'nm'))\n",
    "\n",
    "        # Plot cross sections and save it as .png.\n",
    "        plt.plot(wl, xsec, label='T = '+str(T)+' K, '+profile)\n",
    "        plt.title(database+' '+molecule+' '+abs_emi+' Cross-Section with '+ profile) \n",
    "        plt.xlabel('Wavelength, nm')\n",
    "        plt.ylabel('Cross-section, nm$^{-2}$/molecule')\n",
    "        plt.legend()\n",
    "        plots_foldername = saveplots+molecule+'/'\n",
    "        if os.path.exists(plots_foldername):\n",
    "            pass\n",
    "        else:\n",
    "            os.makedirs(plots_foldername, exist_ok=True)    \n",
    "        plt.savefig(plots_foldername+molecule+'__T'+str(T)+'__'+str(min_wl)+'-'+str(max_wl)+'nm__'\n",
    "                    +database+'__'+abs_emi+'__'+profile+'.png', dpi=500)\n",
    "        plt.show()\n",
    "        print('Cross sections plot saved.')\n",
    "        \n",
    "        # Save cross sections into .xsec file.\n",
    "        xsec_df = pd.DataFrame()\n",
    "        xsec_df['wavelength'] = wl\n",
    "        xsec_df['cross-section'] = xsec\n",
    "        xsecs_foldername = savexsecs+molecule+'/'\n",
    "        if os.path.exists(xsecs_foldername):\n",
    "            pass\n",
    "        else:\n",
    "            os.makedirs(xsecs_foldername, exist_ok=True)\n",
    "        xsec_filename = (xsecs_foldername+molecule+'__T'+str(T)+'__'+str(min_wl)+'-'+str(max_wl)+'nm__'\n",
    "                         +database+'__'+abs_emi+'__'+profile+'.xsec')\n",
    "        np.savetxt(xsec_filename, np.vstack((wl,xsec)).T)\n",
    "        print('Cross sections file saved.')\n",
    "\n",
    "    else:\n",
    "        print('Please type in correct format: wn or wl.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def part_linelist(read_path, trans_df):\n",
    "    states_df = read_all_states(read_path)\n",
    "    Q_ref, Q = read_exomol_pf(read_path, T_ref, T)\n",
    "    broad_df = read_broad(read_path)\n",
    "    id_u = trans_df['u'].values\n",
    "    id_l = trans_df['l'].values\n",
    "    states_df.set_index([0], inplace=True, drop=False)\n",
    "    states_u_df = states_df.loc[id_u]\n",
    "    states_l_df = states_df.loc[id_l]\n",
    "    A = trans_df['A'].values\n",
    "    v = trans_df['v'].values\n",
    "    Ep = states_u_df[1].values\n",
    "    Epp = states_l_df[1].values\n",
    "    gp = states_u_df[2].values\n",
    "    linelist_df = pd.DataFrame()\n",
    "    max_broad_J = max(broad_df['Jpp'])\n",
    "    linelist_df['Jpp'] = states_l_df[3].values\n",
    "    linelist_df['Jpp'][linelist_df.Jpp > max_broad_J] = max_broad_J\n",
    "    Jpp = linelist_df['Jpp'].values\n",
    "    id_broad = linelist_df['Jpp'] - 0.5\n",
    "    gamma_L = broad_df['gamma_L'][id_broad].values\n",
    "    n_air = broad_df['n_air'][id_broad].values\n",
    "    wn_grid = np.linspace(min_wn, max_wn, N_point)\n",
    "    \n",
    "    return (wn_grid, Q, A, v, Ep, Epp, gp, Jpp, gamma_L, n_air)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hitran_linelist(hitran_df):\n",
    "    '''\n",
    "    Read HITRAN .par file as the input file.\n",
    "    Return the data for calculating wavennumbers and cross sections with line profiles.\n",
    "    \n",
    "    '''\n",
    "    wn_grid = np.linspace(min_wn, max_wn, N_point)\n",
    "    v = hitran_df['v'].values\n",
    "    S = hitran_df['S'].values\n",
    "    A = hitran_df['A'].values\n",
    "    Epp = hitran_df['Epp'].values\n",
    "    n_air = hitran_df['n_air'].values\n",
    "    gamma_air = hitran_df['gamma_air'].values\n",
    "    gamma_self = hitran_df['gamma_self'].values\n",
    "    \n",
    "    \n",
    "    return (wn_grid, v, S, A, Epp, n_air, gamma_air, gamma_self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(df):\n",
    "    if database == 'ExoMol':\n",
    "        #states_df = read_all_states(read_path)\n",
    "        #Q_ref, Q = read_pf(read_path, T_ref, T)\n",
    "        #broad_df = read_broad(read_path)\n",
    "        wn_grid, Q, A, v, Ep, Epp, gp, Jpp, gamma_L, n_air = part_linelist(read_path, df)\n",
    "\n",
    "    elif database == 'HITRAN':\n",
    "        hitran_df = read_hitran_parfile (par_filepath, df)\n",
    "        wn_grid, v, S, A, Epp, n_air, gamma_air, gamma_self = hitran_linelist(hitran_df)\n",
    "        \n",
    "    else:\n",
    "        print('Please add the name of the database ExoMol or HITRAN into the input file.')\n",
    "    \n",
    "    if abs_emi == 'Absorption':\n",
    "        coef = cal_abscoefs(v, gp, A, Epp, Q, abundance)\n",
    "    else:\n",
    "        coef = cal_emicoefs(v, gp, A, Ep, Q, abundance)\n",
    "    \n",
    "    if profile == 'Gaussian':\n",
    "        alpha = Doppler_HWHM (v, mass, T)\n",
    "        xsec_g = exomol_cross_section_Gaussian(wn_grid, v, alpha, coef)\n",
    "        plot_xsec(wn_grid, xsec_g, database, profile)\n",
    "    elif profile == 'Lorentzian':\n",
    "        gamma = Lorentzian_HWHM (T, P, n_air, gamma_L)\n",
    "        xsec_l = exomol_cross_section_Lorentzian(wn_grid, v, gamma, coef)\n",
    "        plot_xsec(wn_grid, xsec_l, database, profile)\n",
    "    else:\n",
    "        alpha = Doppler_HWHM (v, mass, T)\n",
    "        gamma = Lorentzian_HWHM (T, P, n_air, gamma_L)\n",
    "    if profile == 'SciPyVoigt':\n",
    "        xsec_sv = exomol_cross_section_scipy_Voigt(wn_grid, v, alpha, gamma, coef)\n",
    "        plot_xsec(wn_grid, xsec_sv, database, profile)\n",
    "    elif profile == 'SciPyWofzVoigt':\n",
    "        xsec_swv = exomol_cross_section_scipy_wofz_Voigt(wn_grid, v, alpha, gamma, coef)\n",
    "        plot_xsec(wn_grid, xsec_swv, database, profile)\n",
    "    elif profile == 'WidthVoigt':\n",
    "        xsec_wv = exomol_cross_section_width_Voigt(wn_grid, v, alpha, gamma, coef)\n",
    "        plot_xsec(wn_grid, xsec_wv, database, profile)\n",
    "    elif profile == 'PseudoVoigt':\n",
    "        xsec_pv = exomol_cross_section_pseudo_Voigt(wn_grid, v, alpha, gamma, coef)        \n",
    "        plot_xsec(wn_grid, xsec_pv, database, profile)\n",
    "    elif profile == 'PseudoFWHMVoigt':\n",
    "        xsec_pfv = exomol_cross_section_pseudo_FWHM_Voigt(wn_grid, v, alpha, gamma, coef)\n",
    "        plot_xsec(wn_grid, xsec_pfv, database, profile)\n",
    "    else:\n",
    "        print('Please choose line profile from the list.')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exomol_exocross(read_path):\n",
    "\n",
    "    # Initialise the iterator object.\n",
    "    trans_col_name = ['u', 'l', 'A', 'v']\n",
    "    #trans_filepaths = get_transfiles(read_path)\n",
    "    trans_filepaths = glob.glob((read_path + molecule + '/' + isotopologue + '/' + dataset + '/' + '*trans.bz2')[0])\n",
    "    if len(trans_filepaths) == 1:\n",
    "        transfile_df = pd.read_csv(trans_filepaths[0], compression='bz2', sep='\\s+', header=None, \n",
    "                                names=trans_col_name, chunksize=100_000_000, encoding='utf-8')\n",
    "\n",
    "    else:\n",
    "        for trans_filename in tqdm(trans_filepaths):\n",
    "            lower = int(trans_filename.split('__')[2].split('.')[0].split('-')[0])\n",
    "            upper = int(trans_filename.split('__')[2].split('.')[0].split('-')[1]) \n",
    "            if (lower <= int(min_wn) <= upper):\n",
    "                lowerfile = pd.read_csv(trans_filename, compression='bz2', sep='\\s+', header=None, \n",
    "                                        names=trans_col_name, chunksize=100_000_000, encoding='utf-8')       \n",
    "                #for lower_chunk in lowerfile:\n",
    "                #    lower_chunk = lower_chunk[lower_chunk['v'].between(min_wn - cutoff, max_wn + cutoff)]     \n",
    "\n",
    "            elif (lower <= int(max_wn) <= upper):\n",
    "                upperfile = pd.read_csv(trans_filename, compression='bz2', sep='\\s+', header=None, \n",
    "                                        names=trans_col_name, chunksize=100_000_000, encoding='utf-8')       \n",
    "                #for upper_chunk in upperfile:\n",
    "                #    upper_chunk = upper_chunk[upper_chunk['v'].between(min_wn - cutoff, max_wn + cutoff)]     \n",
    "        \n",
    "            elif (lower >= int(min_wn) and upper <= int(max_wn)):\n",
    "                insiderfile = pd.read_csv(trans_filename, compression='bz2', sep='\\s+', header=None, \n",
    "                                        names=trans_col_name, chunksize=100_000_000, encoding='utf-8')     \n",
    "            transfile_df = lowerfile.append(insiderfile).append(upperfile)         \n",
    "            \n",
    "    # Depends on how many cores you want to utilise.\n",
    "    # Reserve 64 cores for our script.\n",
    "    max_processors = 4       \n",
    "    pool = multiprocessing.Pool(processes=max_processors)\n",
    "    f_list = []\n",
    "    for trans_df in transfile_df:\n",
    "        trans_df = trans_df[trans_df['v'].between(min_wn - cutoff, max_wn + cutoff)] \n",
    "        f = pool.apply_async(get_results, [trans_df])\n",
    "        if len(pool._cache) > max_processors * 200:\n",
    "            f.wait()\n",
    "        f_list.append(f)\n",
    "        if len(f_list) >= max_processors:\n",
    "            for f in f_list:\n",
    "                f.get()\n",
    "                del f_list[:]\n",
    "    pool.close()\n",
    "    print('Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if database == 'ExoMol':\n",
    "    get_exomol_exocross(read_path)\n",
    "elif database == 'HITRAN':\n",
    "    wn_grid, v, S, A, Epp, n_air, gamma_air, gamma_self = hitran_linelist(df)\n",
    "else:\n",
    "    raise Exception('Please add the name of the database ExoMol or HITRAN into the input file.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n",
    "\n",
    "## Plot At The Same T With Different Line Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T=500\n",
    "wn_grid, Q, A, v, Ep, Epp, gp, Jpp, gamma_L, n_air = part_linelist(read_path, trans_df)\n",
    "coef = cal_abscoefs(v, gp, A, Epp, Q, abundance)\n",
    "#coef = cal_emicoefs(v, gp, A, Ep, Q, abundance)\n",
    "alpha = Doppler_HWHM (v, mass, T)\n",
    "gamma = Lorentzian_HWHM (T, P, n_air, gamma_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xsec_g = exomol_cross_section_Gaussian(wn_grid, v, alpha, coef)\n",
    "xsec_l = exomol_cross_section_Lorentzian(wn_grid, v, gamma, coef)\n",
    "xsec_sv = exomol_cross_section_scipy_Voigt(wn_grid, v, alpha, gamma, coef)\n",
    "xsec_swv = exomol_cross_section_scipy_wofz_Voigt(wn_grid, v, alpha, gamma, coef)\n",
    "xsec_wv = exomol_cross_section_width_Voigt(wn_grid, v, alpha, gamma, coef)\n",
    "xsec_pv = exomol_cross_section_pseudo_Voigt(wn_grid, v, alpha, gamma, coef)        \n",
    "xsec_pfv = exomol_cross_section_pseudo_FWHM_Voigt(wn_grid, v, alpha, gamma, coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_xsec(wn_grid, xsec_g, database, 'Gaussian')\n",
    "plot_xsec(wn_grid, xsec_l, database, 'Lorentzian')\n",
    "plot_xsec(wn_grid, xsec_sv, database, 'SciPyVoigt')\n",
    "plot_xsec(wn_grid, xsec_swv, database, 'SciPyWofzVoigt')\n",
    "plot_xsec(wn_grid, xsec_wv, database, 'WidthVoigt')\n",
    "plot_xsec(wn_grid, xsec_pv, database, 'PseudoVoigt')\n",
    "plot_xsec(wn_grid, xsec_pfv, database, 'PseudoFWHMVoigt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn = wn_grid\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(wn, xsec_g, label='Gaussian profile')\n",
    "ax.plot(wn, xsec_l, label='Lorentzian profile')\n",
    "ax.plot(wn, xsec_sv, label='SciPy Voigt profile')\n",
    "ax.plot(wn, xsec_swv, label='SciPy Wofz Voigt profile')\n",
    "ax.plot(wn, xsec_wv, label='Width Voigt profile')\n",
    "ax.plot(wn, xsec_pv, label='Pseudo Voigt profile')\n",
    "ax.plot(wn, xsec_pfv, label='Pseudo FWHM Voigt profile')\n",
    "ax.set_xlabel('Wavenumber, cm$^{-1}$')\n",
    "ax.set_ylabel('Cross-section, cm$^{2}$/molecule')\n",
    "ax.set_title(abs_emi+' Cross-Section ExoMol at T = '+str(T)+' K') \n",
    "ax.legend() \n",
    "plots_foldername = saveplots+molecule+'/'\n",
    "if os.path.exists(plots_foldername):\n",
    "    pass\n",
    "else:\n",
    "    os.makedirs(plots_foldername, exist_ok=True)    \n",
    "plt.savefig(plots_foldername+molecule+'__T'+str(T)+'__'+str(min_wn)+'-'+str(max_wn)+'cm-1__'\n",
    "            +database+'__'+abs_emi+'.png', dpi=500)\n",
    "plt.show()\n",
    "print('Cross sections plot saved.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot At Different T With The Same Line Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = 'SciPyVoigt'\n",
    "wn = wn_grid\n",
    "plt.figure(figsize=(12,8), dpi=500)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "T = 800\n",
    "coef = cal_abscoefs(v, gp, A, Epp, Q, abundance)\n",
    "#coef = cal_emicoefs(v, gp, A, Ep, Q, abundance)\n",
    "alpha = Doppler_HWHM (v, mass, T)\n",
    "gamma = Lorentzian_HWHM (T, P, n_air, gamma_L)\n",
    "xsec_sv = exomol_cross_section_scipy_Voigt(wn_grid, v, alpha, gamma, coef)\n",
    "ax.plot(wn, xsec_sv, linewidth=1, label='T = 800 K')\n",
    "\n",
    "T = 600\n",
    "coef = cal_abscoefs(v, gp, A, Epp, Q, abundance)\n",
    "#coef = cal_emicoefs(v, gp, A, Ep, Q, abundance)\n",
    "alpha = Doppler_HWHM (v, mass, T)\n",
    "gamma = Lorentzian_HWHM (T, P, n_air, gamma_L)\n",
    "xsec_sv = exomol_cross_section_scipy_Voigt(wn_grid, v, alpha, gamma, coef)\n",
    "ax.plot(wn, xsec_sv, linewidth=1, label='T = 600 K')\n",
    "\n",
    "T = 400\n",
    "coef = cal_abscoefs(v, gp, A, Epp, Q, abundance)\n",
    "#coef = cal_emicoefs(v, gp, A, Ep, Q, abundance)\n",
    "alpha = Doppler_HWHM (v, mass, T)\n",
    "gamma = Lorentzian_HWHM (T, P, n_air, gamma_L)\n",
    "xsec_sv = exomol_cross_section_scipy_Voigt(wn_grid, v, alpha, gamma, coef)\n",
    "ax.plot(wn, xsec_sv, linewidth=1, label='T = 400 K')\n",
    "\n",
    "T = 200\n",
    "coef = cal_abscoefs(v, gp, A, Epp, Q, abundance)\n",
    "#coef = cal_emicoefs(v, gp, A, Ep, Q, abundance)\n",
    "alpha = Doppler_HWHM (v, mass, T)\n",
    "gamma = Lorentzian_HWHM (T, P, n_air, gamma_L)\n",
    "xsec_sv = exomol_cross_section_scipy_Voigt(wn_grid, v, alpha, gamma, coef)\n",
    "ax.plot(wn, xsec_sv, linewidth=1, label='T = 200 K')\n",
    "\n",
    "T = 100\n",
    "coef = cal_abscoefs(v, gp, A, Epp, Q, abundance)\n",
    "#coef = cal_emicoefs(v, gp, A, Ep, Q, abundance)\n",
    "alpha = Doppler_HWHM (v, mass, T)\n",
    "gamma = Lorentzian_HWHM (T, P, n_air, gamma_L)\n",
    "xsec_sv = exomol_cross_section_scipy_Voigt(wn_grid, v, alpha, gamma, coef)\n",
    "ax.plot(wn, xsec_sv, linewidth=1, label='T = 100 K')\n",
    "\n",
    "T = 50\n",
    "coef = cal_abscoefs(v, gp, A, Epp, Q, abundance)\n",
    "#coef = cal_emicoefs(v, gp, A, Ep, Q, abundance)\n",
    "alpha = Doppler_HWHM (v, mass, T)\n",
    "gamma = Lorentzian_HWHM (T, P, n_air, gamma_L)\n",
    "xsec_sv = exomol_cross_section_scipy_Voigt(wn_grid, v, alpha, gamma, coef)\n",
    "ax.plot(wn, xsec_sv, linewidth=1, label='T =   50 K')\n",
    "\n",
    "ax.set_xlabel('Wavenumber, cm$^{-1}$')\n",
    "ax.set_ylabel('Cross-section, cm$^{2}$/molecule')\n",
    "ax.set_title(database + ' Database ' + molecule + ' ' + abs_emi +' Cross-Section With ' + profile)  \n",
    "ax.legend() \n",
    "plots_foldername = saveplots+molecule+'/'\n",
    "if os.path.exists(plots_foldername):\n",
    "    pass\n",
    "else:\n",
    "    os.makedirs(plots_foldername, exist_ok=True)    \n",
    "plt.savefig(plots_foldername+molecule+'__'+str(min_wn)+'-'+str(max_wn)+'cm-1__'\n",
    "            +database+'__'+abs_emi+'__'+profile+'.png', dpi=500)\n",
    "plt.show()\n",
    "print('Cross sections plot saved.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('exomol')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "722cf535e3d158a42a418157a233af576121476252bfbc7c5af47c8831a1fc54"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
